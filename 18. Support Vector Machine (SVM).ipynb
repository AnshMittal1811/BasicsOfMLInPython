{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE STUDY 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM - Email Spam Classifier\n",
    "\n",
    "\n",
    "In this section, we'll build a linear SVM classifier to classify emails into spam and ham. The dataset, taken from the UCI ML repository, contains about 4600 emails labelled as **spam** or **ham**. \n",
    "\n",
    "The dataset can be downloaded here: https://archive.ics.uci.edu/ml/datasets/spambase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "Let's first load the data and understand the attributes meanings, shape of the dataset etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import warnings # supress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0     1     2    3     4     5     6     7     8     9   ...    48  \\\n",
      "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n",
      "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
      "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
      "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
      "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
      "\n",
      "      49   50     51     52     53     54   55    56  57  \n",
      "0  0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
      "1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
      "2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
      "3  0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
      "4  0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "email_rec = pd.read_csv(\"Datasets/Spam.txt\",  sep = ',', header= None )\n",
    "print(email_rec.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of now, the columns are named as integers. Let's manually name the columns appropriately (column names are available at the UCI website here: https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
      "0            0.00               0.64           0.64           0.0   \n",
      "1            0.21               0.28           0.50           0.0   \n",
      "2            0.06               0.00           0.71           0.0   \n",
      "3            0.00               0.00           0.00           0.0   \n",
      "4            0.00               0.00           0.00           0.0   \n",
      "\n",
      "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
      "0           0.32            0.00              0.00                0.00   \n",
      "1           0.14            0.28              0.21                0.07   \n",
      "2           1.23            0.19              0.19                0.12   \n",
      "3           0.63            0.00              0.31                0.63   \n",
      "4           0.63            0.00              0.31                0.63   \n",
      "\n",
      "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
      "0             0.00            0.00  ...         0.00        0.000   \n",
      "1             0.00            0.94  ...         0.00        0.132   \n",
      "2             0.64            0.25  ...         0.01        0.143   \n",
      "3             0.31            0.63  ...         0.00        0.137   \n",
      "4             0.31            0.63  ...         0.00        0.135   \n",
      "\n",
      "   char_freq_[  char_freq_!  char_freq_$  char_freq_hash  \\\n",
      "0          0.0        0.778        0.000           0.000   \n",
      "1          0.0        0.372        0.180           0.048   \n",
      "2          0.0        0.276        0.184           0.010   \n",
      "3          0.0        0.137        0.000           0.000   \n",
      "4          0.0        0.135        0.000           0.000   \n",
      "\n",
      "   capital_run_length_average  capital_run_length_longest  \\\n",
      "0                       3.756                          61   \n",
      "1                       5.114                         101   \n",
      "2                       9.821                         485   \n",
      "3                       3.537                          40   \n",
      "4                       3.537                          40   \n",
      "\n",
      "   capital_run_length_total  spam  \n",
      "0                       278     1  \n",
      "1                      1028     1  \n",
      "2                      2259     1  \n",
      "3                       191     1  \n",
      "4                       191     1  \n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# renaming the columns\n",
    "email_rec.columns  = [\"word_freq_make\", \"word_freq_address\", \"word_freq_all\", \"word_freq_3d\", \n",
    "                      \"word_freq_our\", \"word_freq_over\", \"word_freq_remove\", \"word_freq_internet\", \n",
    "                      \"word_freq_order\", \"word_freq_mail\", \"word_freq_receive\", \"word_freq_will\", \n",
    "                      \"word_freq_people\", \"word_freq_report\", \"word_freq_addresses\", \"word_freq_free\", \n",
    "                      \"word_freq_business\", \"word_freq_email\", \"word_freq_you\", \"word_freq_credit\", \n",
    "                      \"word_freq_your\", \"word_freq_font\", \"word_freq_000\", \"word_freq_money\", \"word_freq_hp\", \n",
    "                      \"word_freq_hpl\", \"word_freq_george\", \"word_freq_650\", \"word_freq_lab\", \"word_freq_labs\", \n",
    "                      \"word_freq_telnet\", \"word_freq_857\", \"word_freq_data\", \"word_freq_415\", \"word_freq_85\", \n",
    "                      \"word_freq_technology\", \"word_freq_1999\", \"word_freq_parts\", \"word_freq_pm\", \"word_freq_direct\",\n",
    "                      \"word_freq_cs\", \"word_freq_meeting\", \"word_freq_original\", \"word_freq_project\", \"word_freq_re\", \n",
    "                      \"word_freq_edu\", \"word_freq_table\", \"word_freq_conference\", \"char_freq_;\", \"char_freq_(\", \n",
    "                      \"char_freq_[\", \"char_freq_!\", \"char_freq_$\", \"char_freq_hash\", \"capital_run_length_average\", \n",
    "                      \"capital_run_length_longest\", \"capital_run_length_total\", \"spam\"]\n",
    "print(email_rec.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4601, 58)\n"
     ]
    }
   ],
   "source": [
    "print(email_rec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 58 columns):\n",
      "word_freq_make                4601 non-null float64\n",
      "word_freq_address             4601 non-null float64\n",
      "word_freq_all                 4601 non-null float64\n",
      "word_freq_3d                  4601 non-null float64\n",
      "word_freq_our                 4601 non-null float64\n",
      "word_freq_over                4601 non-null float64\n",
      "word_freq_remove              4601 non-null float64\n",
      "word_freq_internet            4601 non-null float64\n",
      "word_freq_order               4601 non-null float64\n",
      "word_freq_mail                4601 non-null float64\n",
      "word_freq_receive             4601 non-null float64\n",
      "word_freq_will                4601 non-null float64\n",
      "word_freq_people              4601 non-null float64\n",
      "word_freq_report              4601 non-null float64\n",
      "word_freq_addresses           4601 non-null float64\n",
      "word_freq_free                4601 non-null float64\n",
      "word_freq_business            4601 non-null float64\n",
      "word_freq_email               4601 non-null float64\n",
      "word_freq_you                 4601 non-null float64\n",
      "word_freq_credit              4601 non-null float64\n",
      "word_freq_your                4601 non-null float64\n",
      "word_freq_font                4601 non-null float64\n",
      "word_freq_000                 4601 non-null float64\n",
      "word_freq_money               4601 non-null float64\n",
      "word_freq_hp                  4601 non-null float64\n",
      "word_freq_hpl                 4601 non-null float64\n",
      "word_freq_george              4601 non-null float64\n",
      "word_freq_650                 4601 non-null float64\n",
      "word_freq_lab                 4601 non-null float64\n",
      "word_freq_labs                4601 non-null float64\n",
      "word_freq_telnet              4601 non-null float64\n",
      "word_freq_857                 4601 non-null float64\n",
      "word_freq_data                4601 non-null float64\n",
      "word_freq_415                 4601 non-null float64\n",
      "word_freq_85                  4601 non-null float64\n",
      "word_freq_technology          4601 non-null float64\n",
      "word_freq_1999                4601 non-null float64\n",
      "word_freq_parts               4601 non-null float64\n",
      "word_freq_pm                  4601 non-null float64\n",
      "word_freq_direct              4601 non-null float64\n",
      "word_freq_cs                  4601 non-null float64\n",
      "word_freq_meeting             4601 non-null float64\n",
      "word_freq_original            4601 non-null float64\n",
      "word_freq_project             4601 non-null float64\n",
      "word_freq_re                  4601 non-null float64\n",
      "word_freq_edu                 4601 non-null float64\n",
      "word_freq_table               4601 non-null float64\n",
      "word_freq_conference          4601 non-null float64\n",
      "char_freq_;                   4601 non-null float64\n",
      "char_freq_(                   4601 non-null float64\n",
      "char_freq_[                   4601 non-null float64\n",
      "char_freq_!                   4601 non-null float64\n",
      "char_freq_$                   4601 non-null float64\n",
      "char_freq_hash                4601 non-null float64\n",
      "capital_run_length_average    4601 non-null float64\n",
      "capital_run_length_longest    4601 non-null int64\n",
      "capital_run_length_total      4601 non-null int64\n",
      "spam                          4601 non-null int64\n",
      "dtypes: float64(55), int64(3)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "# ensure that data type are correct\n",
    "email_rec.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_freq_make                0\n",
       "word_freq_address             0\n",
       "word_freq_all                 0\n",
       "word_freq_3d                  0\n",
       "word_freq_our                 0\n",
       "word_freq_over                0\n",
       "word_freq_remove              0\n",
       "word_freq_internet            0\n",
       "word_freq_order               0\n",
       "word_freq_mail                0\n",
       "word_freq_receive             0\n",
       "word_freq_will                0\n",
       "word_freq_people              0\n",
       "word_freq_report              0\n",
       "word_freq_addresses           0\n",
       "word_freq_free                0\n",
       "word_freq_business            0\n",
       "word_freq_email               0\n",
       "word_freq_you                 0\n",
       "word_freq_credit              0\n",
       "word_freq_your                0\n",
       "word_freq_font                0\n",
       "word_freq_000                 0\n",
       "word_freq_money               0\n",
       "word_freq_hp                  0\n",
       "word_freq_hpl                 0\n",
       "word_freq_george              0\n",
       "word_freq_650                 0\n",
       "word_freq_lab                 0\n",
       "word_freq_labs                0\n",
       "word_freq_telnet              0\n",
       "word_freq_857                 0\n",
       "word_freq_data                0\n",
       "word_freq_415                 0\n",
       "word_freq_85                  0\n",
       "word_freq_technology          0\n",
       "word_freq_1999                0\n",
       "word_freq_parts               0\n",
       "word_freq_pm                  0\n",
       "word_freq_direct              0\n",
       "word_freq_cs                  0\n",
       "word_freq_meeting             0\n",
       "word_freq_original            0\n",
       "word_freq_project             0\n",
       "word_freq_re                  0\n",
       "word_freq_edu                 0\n",
       "word_freq_table               0\n",
       "word_freq_conference          0\n",
       "char_freq_;                   0\n",
       "char_freq_(                   0\n",
       "char_freq_[                   0\n",
       "char_freq_!                   0\n",
       "char_freq_$                   0\n",
       "char_freq_hash                0\n",
       "capital_run_length_average    0\n",
       "capital_run_length_longest    0\n",
       "capital_run_length_total      0\n",
       "spam                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are no missing values in the dataset \n",
    "email_rec.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at the fraction of spam and ham emails in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4601.000000\n",
       "mean        0.394045\n",
       "std         0.488698\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         1.000000\n",
       "max         1.000000\n",
       "Name: spam, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at fraction of spam emails \n",
    "# 39.4% spams\n",
    "email_rec['spam'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Let's now conduct some prelimininary data preparation steps, i.e. rescaling the variables, splitting into train and test etc. To understand why rescaling is required, let's print the summary stats of all columns - you'll notice that the columns at the end (capital_run_length_longest, capital_run_length_total etc.) have much higher values (means = 52, 283 etc.) than most other columns which represent fraction of word occurrences (no. of times word appears in email/total no. of words in email)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_hash</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "      <td>0.394045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305358</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
       "mean         0.104553           0.213015       0.280656      0.065425   \n",
       "std          0.305358           1.290575       0.504143      1.395151   \n",
       "min          0.000000           0.000000       0.000000      0.000000   \n",
       "25%          0.000000           0.000000       0.000000      0.000000   \n",
       "50%          0.000000           0.000000       0.000000      0.000000   \n",
       "75%          0.000000           0.000000       0.420000      0.000000   \n",
       "max          4.540000          14.280000       5.100000     42.810000   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
       "mean        0.312223        0.095901          0.114208            0.105295   \n",
       "std         0.672513        0.273824          0.391441            0.401071   \n",
       "min         0.000000        0.000000          0.000000            0.000000   \n",
       "25%         0.000000        0.000000          0.000000            0.000000   \n",
       "50%         0.000000        0.000000          0.000000            0.000000   \n",
       "75%         0.380000        0.000000          0.000000            0.000000   \n",
       "max        10.000000        5.880000          7.270000           11.110000   \n",
       "\n",
       "       word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "count      4601.000000     4601.000000  ...  4601.000000  4601.000000   \n",
       "mean          0.090067        0.239413  ...     0.038575     0.139030   \n",
       "std           0.278616        0.644755  ...     0.243471     0.270355   \n",
       "min           0.000000        0.000000  ...     0.000000     0.000000   \n",
       "25%           0.000000        0.000000  ...     0.000000     0.000000   \n",
       "50%           0.000000        0.000000  ...     0.000000     0.065000   \n",
       "75%           0.000000        0.160000  ...     0.000000     0.188000   \n",
       "max           5.260000       18.180000  ...     4.385000     9.752000   \n",
       "\n",
       "       char_freq_[  char_freq_!  char_freq_$  char_freq_hash  \\\n",
       "count  4601.000000  4601.000000  4601.000000     4601.000000   \n",
       "mean      0.016976     0.269071     0.075811        0.044238   \n",
       "std       0.109394     0.815672     0.245882        0.429342   \n",
       "min       0.000000     0.000000     0.000000        0.000000   \n",
       "25%       0.000000     0.000000     0.000000        0.000000   \n",
       "50%       0.000000     0.000000     0.000000        0.000000   \n",
       "75%       0.000000     0.315000     0.052000        0.000000   \n",
       "max       4.081000    32.478000     6.003000       19.829000   \n",
       "\n",
       "       capital_run_length_average  capital_run_length_longest  \\\n",
       "count                 4601.000000                 4601.000000   \n",
       "mean                     5.191515                   52.172789   \n",
       "std                     31.729449                  194.891310   \n",
       "min                      1.000000                    1.000000   \n",
       "25%                      1.588000                    6.000000   \n",
       "50%                      2.276000                   15.000000   \n",
       "75%                      3.706000                   43.000000   \n",
       "max                   1102.500000                 9989.000000   \n",
       "\n",
       "       capital_run_length_total         spam  \n",
       "count               4601.000000  4601.000000  \n",
       "mean                 283.289285     0.394045  \n",
       "std                  606.347851     0.488698  \n",
       "min                    1.000000     0.000000  \n",
       "25%                   35.000000     0.000000  \n",
       "50%                   95.000000     0.000000  \n",
       "75%                  266.000000     1.000000  \n",
       "max                15841.000000     1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_rec.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = email_rec.drop(\"spam\", axis = 1)\n",
    "y = email_rec.spam.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the features\n",
    "# note that the scale function standardises each column, i.e.\n",
    "# x = x-mean(x)/std(x)\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "X = scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3978260869565217\n",
      "0.38522809558291093\n"
     ]
    }
   ],
   "source": [
    "# confirm that splitting also has similar distribution of spam and ham \n",
    "# emails\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building\n",
    "\n",
    "Let's build a linear SVM mode now. The ```SVC()``` class does that in sklearn. We highly recommend reading the documentation at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SVC in module sklearn.svm.classes:\n",
      "\n",
      "class SVC(sklearn.svm.base.BaseSVC)\n",
      " |  C-Support Vector Classification.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time complexity\n",
      " |  is more than quadratic with the number of samples which makes it hard\n",
      " |  to scale to dataset with more than a couple of 10000 samples.\n",
      " |  \n",
      " |  The multiclass support is handled according to a one-vs-one scheme.\n",
      " |  \n",
      " |  For details on the precise mathematical formulation of the provided\n",
      " |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      " |  other, see the corresponding section in the narrative documentation:\n",
      " |  :ref:`svm_kernels`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  C : float, optional (default=1.0)\n",
      " |      Penalty parameter C of the error term.\n",
      " |  \n",
      " |  kernel : string, optional (default='rbf')\n",
      " |      Specifies the kernel type to be used in the algorithm.\n",
      " |      It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      " |      a callable.\n",
      " |      If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |      used to pre-compute the kernel matrix from data matrices; that matrix\n",
      " |      should be an array of shape ``(n_samples, n_samples)``.\n",
      " |  \n",
      " |  degree : int, optional (default=3)\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : float, optional (default='auto')\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      Current default is 'auto' which uses 1 / n_features,\n",
      " |      if ``gamma='scale'`` is passed then it uses 1 / (n_features * X.std())\n",
      " |      as value of gamma. The current default of gamma, 'auto', will change\n",
      " |      to 'scale' in version 0.22. 'auto_deprecated', a deprecated version of\n",
      " |      'auto' is used as a default indicating that no explicit value of gamma\n",
      " |      was passed.\n",
      " |  \n",
      " |  coef0 : float, optional (default=0.0)\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  shrinking : boolean, optional (default=True)\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |  \n",
      " |  probability : boolean, optional (default=False)\n",
      " |      Whether to enable probability estimates. This must be enabled prior\n",
      " |      to calling `fit`, and will slow down that method.\n",
      " |  \n",
      " |  tol : float, optional (default=1e-3)\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  cache_size : float, optional\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  class_weight : {dict, 'balanced'}, optional\n",
      " |      Set the parameter C of class i to class_weight[i]*C for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |  verbose : bool, default: False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, optional (default=-1)\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  decision_function_shape : 'ovo', 'ovr', default='ovr'\n",
      " |      Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      " |      (n_samples, n_classes) as all other classifiers, or the original\n",
      " |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
      " |      (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n",
      " |      ('ovo') is always used as multi-class strategy.\n",
      " |  \n",
      " |      .. versionchanged:: 0.19\n",
      " |          decision_function_shape is 'ovr' by default.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *decision_function_shape='ovr'* is recommended.\n",
      " |  \n",
      " |      .. versionchanged:: 0.17\n",
      " |         Deprecated *decision_function_shape='ovo' and None*.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      The seed of the pseudo random number generator used when shuffling\n",
      " |      the data for probability estimates. If int, random_state is the\n",
      " |      seed used by the random number generator; If RandomState instance,\n",
      " |      random_state is the random number generator; If None, the random\n",
      " |      number generator is the RandomState instance used by `np.random`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  support_ : array-like, shape = [n_SV]\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : array-like, shape = [n_SV, n_features]\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  n_support_ : array-like, dtype=int32, shape = [n_class]\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  dual_coef_ : array, shape = [n_class-1, n_SV]\n",
      " |      Coefficients of the support vector in the decision function.\n",
      " |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      " |      The layout of the coefficients in the multiclass case is somewhat\n",
      " |      non-trivial. See the section about multi-class classification in the\n",
      " |      SVM section of the User Guide for details.\n",
      " |  \n",
      " |  coef_ : array, shape = [n_class * (n_class-1) / 2, n_features]\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is a readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  intercept_ : array, shape = [n_class * (n_class-1) / 2]\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  fit_status_ : int\n",
      " |      0 if correctly fitted, 1 otherwise (will raise warning)\n",
      " |  \n",
      " |  probA_ : array, shape = [n_class * (n_class-1) / 2]\n",
      " |  probB_ : array, shape = [n_class * (n_class-1) / 2]\n",
      " |      If probability=True, the parameters learned in Platt scaling to\n",
      " |      produce probability estimates from decision values. If\n",
      " |      probability=False, an empty array. Platt scaling uses the logistic\n",
      " |      function\n",
      " |      ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
      " |      where ``probA_`` and ``probB_`` are learned from the dataset. For more\n",
      " |      information on the multiclass case and training procedure see section\n",
      " |      8 of LIBSVM: A Library for Support Vector Machines (in References)\n",
      " |      for more.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      " |  >>> y = np.array([1, 1, 2, 2])\n",
      " |  >>> from sklearn.svm import SVC\n",
      " |  >>> clf = SVC(gamma='auto')\n",
      " |  >>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n",
      " |  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      " |      decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      " |      max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      " |      tol=0.001, verbose=False)\n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  SVR\n",
      " |      Support Vector Machine for Regression implemented using libsvm.\n",
      " |  \n",
      " |  LinearSVC\n",
      " |      Scalable Linear Support Vector Machine for classification\n",
      " |      implemented using liblinear. Check the See also section of\n",
      " |      LinearSVC for more comparison element.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  **References:**\n",
      " |  `LIBSVM: A Library for Support Vector Machines\n",
      " |  <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`__\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVC\n",
      " |      sklearn.svm.base.BaseSVC\n",
      " |      abc.NewBase\n",
      " |      sklearn.svm.base.BaseLibSVM\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, C=1.0, kernel='rbf', degree=3, gamma='auto_deprecated', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm.base.BaseSVC:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Evaluates the decision function for the samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : array-like, shape (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Returns the decision function of the sample for each class\n",
      " |          in the model.\n",
      " |          If decision_function_shape='ovr', the shape is (n_samples,\n",
      " |          n_classes).\n",
      " |      \n",
      " |      Notes\n",
      " |      ------\n",
      " |      If decision_function_shape='ovo', the function values are proportional\n",
      " |      to the distance of the samples X to the separating hyperplane. If the\n",
      " |      exact distances are required, divide the function values by the norm of\n",
      " |      the weight vector (``coef_``). See also `this question\n",
      " |      <https://stats.stackexchange.com/questions/14876/\n",
      " |      interpreting-distance-from-hyperplane-in-svm>`_ for further details.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 or -1 is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : array, shape (n_samples,)\n",
      " |          Class labels for samples in X.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.svm.base.BaseSVC:\n",
      " |  \n",
      " |  predict_log_proba\n",
      " |      Compute log probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape (n_samples, n_classes)\n",
      " |          Returns the log-probabilities of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  predict_proba\n",
      " |      Compute probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm.base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Training vectors, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression)\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,)\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |      \n",
      " |      Notes\n",
      " |      ------\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.svm.base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building\n",
    "\n",
    "# instantiate an object of class SVC()\n",
    "# note that we are using cost C=1\n",
    "model = SVC(C = 1)\n",
    "\n",
    "# fit\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[811,  38],\n",
       "       [ 61, 471]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model using confusion matrix \n",
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9283128167994207\n",
      "precision 0.925343811394892\n",
      "recall 0.8853383458646616\n"
     ]
    }
   ],
   "source": [
    "# print other metrics\n",
    "\n",
    "# accuracy\n",
    "print(\"accuracy\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# precision\n",
    "print(\"precision\", metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# recall/sensitivity\n",
    "print(\"recall\", metrics.recall_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificity 0.9552414605418139\n"
     ]
    }
   ],
   "source": [
    "# specificity (% of hams correctly classified)\n",
    "print(\"specificity\", 811/(811+38))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM we have built so far gives decently good results - an accuracy of 92%, sensitivity/recall (TNR) of 88%. \n",
    "\n",
    "#### Interpretation of Results\n",
    "\n",
    "In the confusion matrix, the elements at (0, 0) and (1,1) correspond to the more frequently occurring class, i.e. ham emails. Thus, it implies that:\n",
    "- 92% of all emails are classified correctly\n",
    "- 88.5% of spams are identified correctly (sensitivity/recall)\n",
    "- Specificity, or % of hams classified correctly, is 95%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function confusion_matrix in module sklearn.metrics.classification:\n",
      "\n",
      "confusion_matrix(y_true, y_pred, labels=None, sample_weight=None)\n",
      "    Compute confusion matrix to evaluate the accuracy of a classification\n",
      "    \n",
      "    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\n",
      "    is equal to the number of observations known to be in group :math:`i` but\n",
      "    predicted to be in group :math:`j`.\n",
      "    \n",
      "    Thus in binary classification, the count of true negatives is\n",
      "    :math:`C_{0,0}`, false negatives is :math:`C_{1,0}`, true positives is\n",
      "    :math:`C_{1,1}` and false positives is :math:`C_{0,1}`.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <confusion_matrix>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : array, shape = [n_samples]\n",
      "        Ground truth (correct) target values.\n",
      "    \n",
      "    y_pred : array, shape = [n_samples]\n",
      "        Estimated targets as returned by a classifier.\n",
      "    \n",
      "    labels : array, shape = [n_classes], optional\n",
      "        List of labels to index the matrix. This may be used to reorder\n",
      "        or select a subset of labels.\n",
      "        If none is given, those that appear at least once\n",
      "        in ``y_true`` or ``y_pred`` are used in sorted order.\n",
      "    \n",
      "    sample_weight : array-like of shape = [n_samples], optional\n",
      "        Sample weights.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    C : array, shape = [n_classes, n_classes]\n",
      "        Confusion matrix\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Wikipedia entry for the Confusion matrix\n",
      "           <https://en.wikipedia.org/wiki/Confusion_matrix>`_\n",
      "           (Wikipedia and other references may use a different\n",
      "           convention for axes)\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.metrics import confusion_matrix\n",
      "    >>> y_true = [2, 0, 2, 2, 0, 1]\n",
      "    >>> y_pred = [0, 0, 2, 2, 0, 2]\n",
      "    >>> confusion_matrix(y_true, y_pred)\n",
      "    array([[2, 0, 0],\n",
      "           [0, 0, 1],\n",
      "           [1, 0, 2]])\n",
      "    \n",
      "    >>> y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
      "    >>> y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
      "    >>> confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])\n",
      "    array([[2, 0, 0],\n",
      "           [0, 0, 1],\n",
      "           [1, 0, 2]])\n",
      "    \n",
      "    In the binary case, we can extract true positives, etc as follows:\n",
      "    \n",
      "    >>> tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
      "    >>> (tn, fp, fn, tp)\n",
      "    (0, 2, 1, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Fold Cross Validation\n",
    "\n",
    "Let's first run a simple k-fold cross validation to get a sense of the **average metrics** as computed over multiple *folds*. the easiest way to do cross-validation is to use the ```cross_val_score()``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 4)\n",
    "\n",
    "# instantiating a model with cost=1\n",
    "model = SVC(C = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the cross-validation scores \n",
    "# note that the argument cv takes the 'folds' object, and\n",
    "# we have specified 'accuracy' as the metric\n",
    "\n",
    "cv_results = cross_val_score(model, \n",
    "                             X_train, \n",
    "                             y_train, \n",
    "                             cv = folds, \n",
    "                             scoring = 'accuracy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91770186 0.93944099 0.91925466 0.93012422 0.94254658]\n",
      "mean accuracy = 0.9298136645962731\n"
     ]
    }
   ],
   "source": [
    "# print 5 accuracies obtained from the 5 folds\n",
    "print(cv_results)\n",
    "print(\"mean accuracy = {}\".format(cv_results.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search to Find Optimal Hyperparameter C\n",
    "\n",
    "K-fold CV helps us compute average metrics over multiple folds, and that is the best indication of the 'test accuracy/other metric scores' we can have. \n",
    "\n",
    "But we want to use CV to compute the optimal values of hyperparameters (in this case, the cost C is a hyperparameter). This is done using the ```GridSearchCV()``` method, which computes metrics (such as accuracy, recall etc.) \n",
    "\n",
    "In this case, we have only one hyperparameter, though you can have multiple, such as C and gamma in non-linear SVMs. In that case, you need to search through a *grid* of multiple values of C and gamma to find the optimal combination, and hence the name GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify range of parameters (C) as a list\n",
    "params = {\"C\": [0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "model  = SVC()\n",
    "\n",
    "# set up grid search scheme\n",
    "# note that we are still using the 5 fold CV scheme we set up earlier\n",
    "model_cv = GridSearchCV(estimator = model, param_grid = params, \n",
    "                        scoring= 'accuracy', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                       return_train_score=True)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   10.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=4, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.1, 1, 10, 100, 1000]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model - it will fit 5 folds across all values of C\n",
    "model_cv.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.348069</td>\n",
       "      <td>0.030322</td>\n",
       "      <td>0.058044</td>\n",
       "      <td>0.005367</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.895963</td>\n",
       "      <td>0.900621</td>\n",
       "      <td>0.906832</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905280</td>\n",
       "      <td>0.008505</td>\n",
       "      <td>5</td>\n",
       "      <td>0.912267</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>0.912267</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>0.906056</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.002355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.203046</td>\n",
       "      <td>0.016210</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.917702</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.010130</td>\n",
       "      <td>2</td>\n",
       "      <td>0.951863</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.950699</td>\n",
       "      <td>0.946040</td>\n",
       "      <td>0.943711</td>\n",
       "      <td>0.947593</td>\n",
       "      <td>0.003135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.160760</td>\n",
       "      <td>0.006114</td>\n",
       "      <td>0.029522</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931056</td>\n",
       "      <td>0.011809</td>\n",
       "      <td>1</td>\n",
       "      <td>0.973991</td>\n",
       "      <td>0.970497</td>\n",
       "      <td>0.973602</td>\n",
       "      <td>0.968944</td>\n",
       "      <td>0.970885</td>\n",
       "      <td>0.971584</td>\n",
       "      <td>0.001924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.211225</td>\n",
       "      <td>0.027235</td>\n",
       "      <td>0.025532</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.008098</td>\n",
       "      <td>3</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.989907</td>\n",
       "      <td>0.988354</td>\n",
       "      <td>0.988354</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.000650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.277455</td>\n",
       "      <td>0.032814</td>\n",
       "      <td>0.022540</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'C': 1000}</td>\n",
       "      <td>0.908385</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920497</td>\n",
       "      <td>0.007569</td>\n",
       "      <td>4</td>\n",
       "      <td>0.996118</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.994177</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.994332</td>\n",
       "      <td>0.000905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.348069      0.030322         0.058044        0.005367     0.1   \n",
       "1       0.203046      0.016210         0.034507        0.002410       1   \n",
       "2       0.160760      0.006114         0.029522        0.001954      10   \n",
       "3       0.211225      0.027235         0.025532        0.002571     100   \n",
       "4       0.277455      0.032814         0.022540        0.002146    1000   \n",
       "\n",
       "        params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0   {'C': 0.1}           0.895963           0.900621           0.906832   \n",
       "1     {'C': 1}           0.917702           0.939441           0.919255   \n",
       "2    {'C': 10}           0.909938           0.944099           0.933230   \n",
       "3   {'C': 100}           0.914596           0.925466           0.936335   \n",
       "4  {'C': 1000}           0.908385           0.931677           0.923913   \n",
       "\n",
       "   split3_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.902174  ...         0.905280        0.008505                5   \n",
       "1           0.930124  ...         0.929814        0.010130                2   \n",
       "2           0.928571  ...         0.931056        0.011809                1   \n",
       "3           0.930124  ...         0.928571        0.008098                3   \n",
       "4           0.919255  ...         0.920497        0.007569                4   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.912267            0.911491            0.912267   \n",
       "1            0.951863            0.945652            0.950699   \n",
       "2            0.973991            0.970497            0.973602   \n",
       "3            0.989519            0.989519            0.989907   \n",
       "4            0.996118            0.993789            0.994177   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.911491            0.906056          0.910714         0.002355  \n",
       "1            0.946040            0.943711          0.947593         0.003135  \n",
       "2            0.968944            0.970885          0.971584         0.001924  \n",
       "3            0.988354            0.988354          0.989130         0.000650  \n",
       "4            0.993789            0.993789          0.994332         0.000905  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results of grid search CV\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better sense of how training and test accuracy varies with C, let's plot the tranining and test accuracies against C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAF6CAYAAAAeZ/GvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xd4lFXexvHvSSMJoSWhSehFuiABQUBABQUVpEgHwUV0Leu6qyv2vvoK7rrWFV0LKF1FEVFAQSwgBAREepVQQ0JLb+f94wkhQAIBMnkmk/tzXbnIzDyZ+UFI7jndWGsRERER3+XndgEiIiLiWQp7ERERH6ewFxER8XEKexERER+nsBcREfFxCnsREREfp7AXERHxcQp7ERERH6ewFxER8XEBbhdQVCIjI22dOnXcLkNERKTYrFy58pC1tvK5rvOZsK9Tpw4xMTFulyEiIlJsjDG7CnOduvFFRER8nMJeRETExynsRUREfJzPjNnnJyMjg9jYWFJTU90uRc4hODiYqKgoAgMD3S5FRMTn+HTYx8bGUq5cOerUqYMxxu1ypADWWuLj44mNjaVu3bpulyMi4nN8uhs/NTWViIgIBb2XM8YQERGhHhgREQ/x6bAHFPQlhL5PIiKe4/NhLyIiUtop7D3oyJEjvPnmmxf89a+88grJyclFWJGIiJRGCnsP8oWwz8zMdPX1RUTk4vn0bPy8np7zO+v3HivS52x6SXmevKlZgY+PGzeObdu20apVK7p378748eMZP348M2bMIC0tjb59+/L000+TlJTEwIEDiY2NJSsri8cff5wDBw6wd+9eunXrRmRkJIsWLTrluZ955hnmzJlDSkoKV155JW+//TbGGLZu3cqdd95JXFwc/v7+zJw5k/r16/PSSy8xefJk/Pz86NmzJy+++CJdu3ZlwoQJREdHc+jQIaKjo9m5cycffPABc+fOJTU1laSkJL744gv69OnD4cOHycjI4LnnnqNPnz4ATJo0iQkTJmCMoWXLlrz55pu0bNmSzZs3ExgYyLFjx2jZsiVbtmzRsjoREZeUmrB3w4svvsi6detYvXo1APPnz2fLli0sX74cay29e/dmyZIlxMXFcckllzB37lwAjh49SoUKFfjXv/7FokWLiIyMPOO577nnHp544gkARowYwZdffslNN93EsGHDGDduHH379iU1NZXs7GzmzZvH7Nmz+eWXXwgNDSUhIeGctS9dupS1a9cSHh5OZmYmn332GeXLl+fQoUO0b9+e3r17s379ep5//nl++uknIiMjSUhIoFy5cnTt2pW5c+dy8803M23aNPr376+gFxFJjIMyYRAYUuwvXWrC/mwt8OIyf/585s+fT+vWrQFITExky5YtdO7cmQceeICHHnqIG2+8kc6dO5/zuRYtWsRLL71EcnIyCQkJNGvWjK5du7Jnzx769u0LOBvVACxcuJDRo0cTGhoKQHh4+Dmfv3v37rnXWWt55JFHWLJkCX5+fuzZs4cDBw7w3XffMWDAgNw3IyeuHzNmDC+99BI333wz77//Pu+88855/kuJiJRgKYfh4EY4uB7iNsLBDc7nyfEwdCY06lHsJZWasPcG1loefvhh7rjjjjMeW7lyJV999RUPP/wwPXr0yG215yc1NZW77rqLmJgYatasyVNPPUVqairW2gJfN7+lbQEBAWRnZ+c+Z15ly5bN/fzjjz8mLi6OlStXEhgYSJ06dXJfL7/n7dixIzt37uT7778nKyuL5s2bF/h3EREpsdISIW4TxG04GegHN8LxvSevCSoHVZpA4xugSlOo3MiVUhX2HlSuXDmOHz+ee/u6667j8ccfZ9iwYYSFhbFnzx4CAwPJzMwkPDyc4cOHExYWxgcffHDK15/ejX8imCMjI0lMTGTWrFkMGDCA8uXLExUVxezZs7n55ptJS0sjKyuLHj168MwzzzB06NDcbvzw8HDq1KnDypUradeuHbNmzSrw73H06FGqVKlCYGAgixYtYtcu50TFa665hr59+3L//fcTERGR+7wAI0eOZMiQITz++ONF+U8qIlL8MlIhfkueQM8J9yN5TpcNCIbKl0K9Lk64V27i/FkhCrxgHxGFvQdFRETQsWNHmjdvTs+ePRk/fjwbNmygQ4cOAISFhfHRRx+xdetWHnzwQfz8/AgMDOStt94CYOzYsfTs2ZPq1aufMkGvYsWK3H777bRo0YI6derQtm3b3McmT57MHXfcwRNPPEFgYCAzZ87k+uuvZ/Xq1URHRxMUFESvXr345z//yQMPPMDAgQOZPHkyV199dYF/j2HDhnHTTTcRHR1Nq1ataNy4MQDNmjXj0UcfpUuXLvj7+9O6devcNyrDhg3jscceY8iQIUX9zyoi4hlZGZCw/dRAP7gBEraBdXpB8QuEyIYQFQ2tRziBXqUJVKoDfv6uln82pqCu35ImOjraxsTEnHLfhg0baNKkiUsVlW6zZs3i888/Z/LkyYX+Gn2/RKRYZGfDkZ2ndr0f3ACHNkN2hnON8YPweqe20qs0hYj64O89E46NMSuttdHnuk4teyly9957L/PmzeOrr75yuxQRKc2shWN7Tm2lH1zvhHpGnj1MKtZyAr1hdyfQqzSGyEauzJr3FIW9FLnXXnvN7RJEpDSxFpLiTg30E7Pg0/LsrxJWzWmhtxntBHqVps44e5ly7tVeTBT2IiJScuRd1nZwQ06o5yxrOyGkElRpBi0Hnux+r9wYQs+97NhXKexFRMT7nFjWlttKzwn34/tOXnP6srYT4+thVbxiBrw3UdiLiIh7MlKdMfS8gX5wPRz54+Q1ucvaunrlsraSQGEvIiKed8aytpxZ8Pkua2sLrUeWmGVtJYHC3oOOHDnClClTuOuuu877a3v16sWUKVOoWLGiByoTEfGQ813W1qyv1y5r8yUKew86ccRtfmGflZWFv3/B71S9ddmatRZrLX5+Oh1ZpFQ7ZVnb+pOT5uI2QWbKyesq1HLC3IeXtZUEpSfs542D/b8V7XNWawE9Xyzw4dOPuL3hhht4+umnqV69OqtXr2b9+vXcfPPN7N69m9TUVO677z7Gjh0LQJ06dYiJiSExMZGePXvSqVMnfv75Z2rUqMHnn39OSMipPyhz5szhueeeIz09nYiICD7++GOqVq1KYmIi9957LzExMRhjePLJJ+nfvz9ff/01jzzyCFlZWURGRvLtt9/y1FNPERYWxgMPPABA8+bN+fLLLwHo2bMn3bp1Y+nSpcyePZsXX3yRFStWkJKSwoABA3j66acBWLFiBffddx9JSUmUKVOGb7/9ll69evHaa6/RqlUrwNk7/6233qJly5ZF+/0QkaKXu6xt/Zmz4PNb1hZ9W6lb1lYSlJ6wd8HpR9wuXryY5cuXs27dOurWrQvAe++9R3h4OCkpKbRt25b+/fsTERFxyvNs2bKFqVOn8s477zBw4EA++eQThg8ffso1nTp1YtmyZRhjePfdd3nppZd4+eWXefbZZ6lQoQK//ea80Tl8+DBxcXHcfvvtLFmyhLp16xbqyNtNmzbx/vvv8+abbwLw/PPPEx4eTlZWFtdccw1r166lcePGDBo0iOnTp9O2bVuOHTtGSEgIY8aM4YMPPuCVV15h8+bNpKWlKehFvJGWtfms0hP2Z2mBF6d27drlBj3Aq6++ymeffQbA7t272bJlyxlhX7du3dxWcZs2bdi5c+cZzxsbG8ugQYPYt28f6enpua+xcOFCpk2blntdpUqVmDNnDldddVXuNYU58rZ27dq0b98+9/aMGTOYOHEimZmZ7Nu3j/Xr12OMoXr16rl79ZcvXx6AW265hWeffZbx48fz3nvvMWrUqHO+noh4UN5lbQc3nDy17YxlbY21rM1HlJ6w9xJ5j45dvHgxCxcuZOnSpYSGhtK1a9czjpoFKFOmTO7n/v7+pKSknHHNvffey9/+9jd69+7N4sWLeeqpp4D8j7ctzJG3cOqxt3nr3rFjBxMmTGDFihVUqlSJUaNGnfXI29DQULp3787nn3/OjBkzOP0MAxHxkBPL2vIGupa1lUoKew86/Yjb0x09epRKlSoRGhrKxo0bWbZs2QW/1tGjR6lRowYAH374Ye79PXr04PXXX+eVV14BnG78Dh06cPfdd7Njx47cbvwTR96eGKNftWoVO3bsyPe1jh07RtmyZalQoQIHDhxg3rx5dO3alcaNG7N3715WrFhB27ZtOX78OCEhIQQEBDBmzBhuuukmOnfuXKieBBG5QKnH4Md/wYY5zlK33GVtAc7EOC1rK5UU9h50+hG3N9xwwymPX3/99fz3v/+lZcuWXHrppad0k5+vp556iltuuYUaNWrQvn373KB+7LHHuPvuu2nevDn+/v48+eST9OvXj4kTJ9KvXz+ys7OpUqUKCxYsoH///kyaNIlWrVrRtm1bGjVqlO9rXXbZZbRu3ZpmzZpRr149OnbsCEBQUBDTp0/n3nvvJSUlhZCQEBYuXEhYWBht2rShfPnyjB49+oL/jiJyFtnZsPpj+PYZSDoIDXtAs34nQz28PgQEuV2luERH3Eqx2Lt3L127dmXjxo0FLtvT90vkAu1aCl8/BPvWQFQ7Z45SjTZuVyXFoLBH3GqxtHjcpEmTuOKKK3j++ee1Pl+kKB3ZDTNHw/vXQ9Ih6Pcu/Gm+gl7OoG588biRI0cycuRIt8sQ8R3pSfDTf5wPgC7joONfIKjs2b9OSi2fD/uCZoiLd/GV4SQRj7IWfpsJC56E43uheX+49mmoWNPtysTL+XTYBwcHEx8fT0REhALfi1lriY+PJzg42O1SRLzXnpXOTqCxy6H6ZTDgPajdwe2qpITw6bCPiooiNjaWuLg4t0uRcwgODiYqKsrtMkS8z7F9zgz7NVOgbBXo/Tq0Ggaa/yLnwafDPjAw8JTd6kRESoyMVFj2Bix52TktruNfofPfIbi825VJCeTTYS8iUuJYCxu+gPmPw5Fd0PhG6PGscySsyAVS2IuIeIv9v8HXD8POH5z96Ed+7mxjK3KRFPYiIm5LOgTfPQerPoTginDDy3D5KPDXr2gpGvqfJCLilsx0WPEOLP4/SE+EdndA14ecY2RFipDCXkTEDZvnwzcPQ/xWqH8NXP+Cc/qciAco7EVEilPcJvjmEdi6ECIawNAZzqE12gtEPEhhLyJSHFIOO931yydCUBhc909oe7tOopNiobAXEfGkrExY+T4s+iekHoHLb4WrH4OykW5XJqWIwl5ExFO2L3aW0h1cD3U6O+Py1Vq4XZWUQgp7EZGilrDd2RRn45dQsRYMnAxNbtK4vLhGYS8iUlTSjsOSCbDsTfALhGuegPZ3Q6AOeRJ3KexFRC5Wdjas/tg5sCbpIFw21An68tXdrkwEUNiLiFycP5bBvIdg32qIagdDpkFUG7erEjmFwl5E5EIc2Q0Ln4R1n0C5S6Dfu9BigMblxSsp7EVEzkd6Evz0H/jpVcBCl4eg430QVNbtykQKpLAXESkMa51W/IIn4NgeaNYPuj/tzLYX8XIKexGRc9mz0lkvv/sXqH4Z9H8Xal/pdlUihaawFxEpyPH9zgz71R9D2crQ+3VoNRT8/N2uTOS8KOxFRE6XkQrL3oAf/gWZac6YfOcHILi825WJXBA/Tz65MeZ6Y8wmY8xWY8y4fB6vbYz51hiz1hiz2BgTleexl4wxvxtjNhhjXjVGU1xFxMOshQ1z4I12Tou+bhe4+xfo/oyCXko0j7XsjTH+wBtAdyAWWGGM+cJauz7PZROASdbaD40xVwMvACOMMVcCHYGWOdf9CHQBFnuqXhEp5favg6/Hwc4foHITGDEb6ndzuyqRIuHJbvx2wFZr7XYAY8w0oA+QN+ybAvfnfL4ImJ3zuQWCgSDAAIHAAQ/WKiKlVdIh+O45WPUhBFeAXhOgzWjw1yin+A5P/m+uAezOczsWuOK0a9YA/YH/AH2BcsaYCGvtUmPMImAfTti/bq3dcPoLGGPGAmMBatXS8hcROQ+Z6bDiHeeM+fREaDfWWTMfGu52ZSJFzpNj9vmNsdvTbj8AdDHG/IrTTb8HyDTGNACaAFE4bxquNsZcdcaTWTvRWhttrY2uXLly0VYvIr5r83x460r45hGIioY//ww9/09BLz7Lky37WKBmnttRwN68F1hr9wL9AIwxYUB/a+3RnBb7MmttYs5j84D2wBIP1isivi5usxPwWxdARAMYOgMa9tAWt+LzPNmyXwE0NMbUNcYEAYOBL/JeYIyJNMacqOFh4L2cz//AafEHGGMCcVr9Z3Tji4gUSsphmDcO3urgbIzT43n481JodJ2CXkoFj7XsrbWZxph7gG8Af+A9a+3vxphngBhr7RdAV+AFY4zFabXfnfPls4Crgd9wuv6/ttbO8VStIuKjsjKdiXffPecEfptbodtjEKZhPyldjLWnD6OXTNHR0TYmJsbtMkTEW2z/3tni9uDvULsTXP8CVG957q8TKUGMMSuttdHnuk5rS0TEtyTsgPmPwcYvnUNqBk6CJr3VXS+lmsJeRHxD2nH44WVY+gb4BcLVj0OHeyAw2O3KRFynsBeRki07G9ZMcba3TTwAlw2Ba56E8tXdrkzEayjsRaTk+mMZzHsI9q2GqLYweCpEtXG7KhGvo7AXkZLnyG5Y+CSs+wTKXQL93oEWt2hcXqQACnsRKTnSk+Gn/zgfWLjqH9DprxBU1u3KRLyawl5EvJ+1Tit+wZNwLBaa9XWOna2oMzFECkNhLyLebc8qZ7387mVQrSX0fwdqX+l2VSIlisJeRLzT8QPODPvVH0PZSOj9GrQaBn7+blcmUuIo7EXEu2SmwbI3YckE5/Mr74WrHoTg8m5XJlJiKexFxDtY6+x6N/8xOLwTLr0BejwLEfXdrkykxFPYi4j79q+Dr8fBzh+gchMYMRvqd3O7KhGfobAXEfckxcOi52DlBxBcAXpNgDajwV+/mkSKkn6iRKT4ZWXA8nfg+xchLRHa3g5dx0FouNuVifgkhb2IFK8tC+CbR+DQZqh/NVz3AlRp7HZVIj5NYS8ixSNusxPyWxdAeH0YMh0aXactbkWKgcJeRDwr5Qh8/3+wfCIEhkKP56HdWAgIcrsykVJDYS8inpGd5Uy8W/Q8JCdAm1uh22MQVtntykRKHYW9iBS9HUucLW4PrIPaneD6F6B6S7erEim1FPYiUnQSdsCCx2HDHOeQmls+hKZ9NC4v4jKFvYhcvLTj8MPLsPQN8AuEqx+DDvdAYIjblYkICnsRuRjWwpppsPBJSDwALQfDtU9C+UvcrkxE8lDYi8iFSU+GOX+B32ZCVFsYPAWiot2uSkTyobAXkfOXsB2mj4ADvztd9p3+Dn5+blclIgVQ2IvI+dk8Hz4dA8YPhs+CBte6XZGInIPCXkQKJzsblrwEi1+Eas1h0EdQqY7bVYlIISjsReTcUo7AZ3fA5q/hsiFw4781016kBFHYi8jZHfgdpg2Do7udI2jbjtG6eZESRmEvIgX7bRZ8cS+UKQ+jvoJaV7hdkYhcAIW9iJwpKwMWPAnL3oBaHZyd8MpVdbsqEblACnsROVXiQZg5Cnb9BFfcCT2eA/9At6sSkYugsBeRk3avgBkjnAl5/d6BlgPdrkhEioDCXkScbW9j/gfzxkGFGjBmobO8TkR8gsJepLTLSIG5f4fVH0PDHtBvIoRUcrsqESlCCnuR0uzwLqfbft8a6DIOujykbW9FfJDCXqS02vYdzLrN2RlvyHS49Hq3KxIRD1HYi5Q21sKP/4bvnoXKjZ1tbyPqu12ViHiQwl6kNEk9BrP/DBu/hOb9ofdrEFTW7apExMMU9iKlRdwmZ9vbhO1w3QvQ/s/a9laklFDYi5QG6z+H2Xc5h9fc+gXU6eR2RSJSjBT2Ir4sKxO+ewZ++g9EtYWBk6D8JW5XJSLFTGEv4quSDjmz7Xd8D9F/gutfgIAyblclIi5Q2Iv4oj2rYPoISIqDPm9C62FuVyQiLlLYi/iaVZOdHfHCqsKfvoFLWrtdkYi4TGEv4isy02DeP2DlB1CvK/R/D8pGuFyUiHgDhb2ILzgaCzNGwp6V0OlvcPVj4OfvdlUi4iUU9iIl3Y4lMHO007If9BE0ucntikTEyyjsRUoqa2Hp67DgSWe720EfQ+VGblclIl5IYS9SEqUlwhf3wO+fQZPecPObUKac21WJiJdS2IuUNIe2wvThcGgTXPs0dLxP296KyFkp7EVKko1fwWd3gF8AjPjMmXUvInIOCnuRkiA7Cxa/AEvGQ/VWMGgyVKzldlUiUkIo7EW8XXICfDIGtn0LrYdDr5chMNjtqkSkBFHYi3izfWud8fnj++DGV6DNKI3Pi8h5U9iLeKs102DOfRASDqPnQVS02xWJSAmlsBfxNpnpMP9RWD4R6nSGAe9DWGW3qxKREkxhL+JNju2DmbfC7l+gwz3O0jp//ZiKyMXRbxERb7FrqRP0aYkw4D1o3t/tikTER/h58smNMdcbYzYZY7YaY8bl83htY8y3xpi1xpjFxpioPI/VMsbMN8ZsMMasN8bU8WStIq6xFn55Gz68EYLCYMxCBb2IFCmPhb0xxh94A+gJNAWGGGOannbZBGCStbYl8AzwQp7HJgHjrbVNgHbAQU/VKuKa9GT4dKxzNG3DHjB2EVQ9/cdEROTieLIbvx2w1Vq7HcAYMw3oA6zPc01T4P6czxcBs3OubQoEWGsXAFhrEz1Yp4g7EnbA9BFwYB10eww6/x38PNrZJiKllCd/s9QAdue5HZtzX15rgBP9lX2BcsaYCKARcMQY86kx5ldjzPicnoJTGGPGGmNijDExcXFxHvgriHjIlgUwsQsc3Q3DZkGXBxX0IuIxnvztkt/OH/a02w8AXYwxvwJdgD1AJk6PQ+ecx9sC9YBRZzyZtROttdHW2ujKlbU0SUqA7Gz4/iX4+BZnu9uxi6HhtW5XJSI+zpPd+LFAzTy3o4C9eS+w1u4F+gEYY8KA/tbao8aYWODXPEMAs4H2wP88WK+IZ6Ucgc/uhM3zoOVguPHfEBTqdlUiUgp4MuxXAA2NMXVxWuyDgaF5LzDGRAIJ1tps4GHgvTxfW8kYU9laGwdcDcR4sFYRzzqwHqYPgyN/QM/x0O52bXsrIsXGY9341tpM4B7gG2ADMMNa+7sx5hljTO+cy7oCm4wxm4GqwPM5X5uF04X/rTHmN5whgXc8VauIR/02C969BtKTYNRcuGKsgl5EipWx9vRh9JIpOjraxsSo8S9eJCsDFjwJy96Amu1h4IdQrprbVYmIDzHGrLTWnvPgDO2gJ+IJiQdh5mjY9SO0uwN6PAcBQW5XJSKllMJepKjtXgEzRkLKYeg7ES4b5HZFIlLKKexFioq1sPJ9+OofUP4SGLMAqrVwuyoREYW9SJHISIG5D8Dqj6DBtdDvHQgNd7sqERFAYS9y8Y78AdOHw741cNU/oOs48Dtjw0cREdco7EUuxrbvYNafIDsThkyDS3u6XZGIyBkU9iIXwlr48d/w3bMQeSkM/hgi6rtdlYhIvhT2Iucr9Rh8fhdsmAPN+kHv16BMmNtViYgU6Jw76Blj7jHGVCqOYkS8XtxmZze8jV/Bdf+EAe8p6EXE6xWmZV8NWGGMWYWzd/031le23RM5H+u/gNl/hsAQGPk51O3sdkUiIoVyzpa9tfYxoCHOiXOjgC3GmH8aYzRAKaVDVqaz7e2MEVC5MYz9XkEvIiVKocbsrbXWGLMf2I9z3nwlYJYxZoG19h+eLFDEVUnxMGs07Pge2oyGnv8HAWXcrkpE5LycM+yNMX8BbgUOAe8CD1prM4wxfsAWQGEvvmnPKmfb28SD0Pt1uHyE2xWJiFyQwrTsI4F+1tpdee+01mYbY270TFkiLls1Geb+HcKqwG1fQ43L3a5IROSCFSbsvwISTtwwxpQDmlprf7HWbvBYZSJuyEyDeQ85e9zX7QID3oeyEW5XJSJyUc45QQ94C0jMczsp5z4R33J0D7zfywn6jn+F4Z8q6EXEJxSmZW/yLrXL6b7XZjziW3b84EzEy0iBgZOhaW+3KxIRKTKFadlvN8b8xRgTmPNxH7Dd04WJFAtr4efXYVIfCKkEt3+noBcRn1OYsL8TuBLYA8QCVwBjPVmUSLFIS4RZt8H8R50DbMZ8C5UvdbsqEZEid87ueGvtQWBwMdQiUnzit8G0YXBoE1z7lDNGb4zbVYmIeERh1tkHA38CmgHBJ+631t7mwbpEPGfTPPh0LPgFwPBPoP7VblckIuJRhenGn4yzP/51wPdAFHDck0WJeER2Fnz3PEwdDOF14Y7vFfQiUioUZlZ9A2vtLcaYPtbaD40xU4BvPF2YSJFKTnBa81sXQKvhcMME50AbEZFSoDBhn5Hz5xFjTHOc/fHreKwikaK2by1MHw7H9sKN/3b2uNf4vIiUIoUJ+4k559k/BnwBhAGPe7QqkaKyZjrM+QuEhMPoeVCzrdsViYgUu7OGfc5hN8estYeBJUC9YqlK5GJlpsP8x2D521C7E9zyvrPPvYhIKXTWCXrW2mzgnmKqRaRoHN8PH97kBH2He2DkbAW9iJRqhenGX2CMeQCYjrMvPgDW2oSCv0TEJX8sc46lTTsO/f8HLQa4XZGIiOsKE/Yn1tPfnec+i7r0xZtYC8vfgW8ehoq1YMRnULWZ21WJiHiFwuygV7c4ChG5YOnJ8OVfYe10aHQ99H0bQiq6XZWIiNcozA56I/O731o7qejLETlPCTtg+gg4sA66PQqdHwC/wuwVJSJSehSmGz/vWqVg4BpgFaCwF3dtWQCfjAEsDJsJDbu7XZGIiFcqTDf+vXlvG2Mq4GyhK+KO7Gz44WVY9LwzLj9oMoRrComISEEK07I/XTLQsKgLESmU1KPw6R2weR60GAg3/QeCQt2uSkTEqxVmzH4Ozux7cNblNwVmeLIokXzFbXYOsTmyC3q+BO3GattbEZFCKEzLfkKezzOBXdbaWA/VI5K/xDj4qD9kpsCtc6D2lW5XJCJSYhQm7P8A9llrUwGMMSHGmDrW2p0erUzkhMx0mDECkg46+9vXuNztikRESpTCrFGaCWTnuZ2Vc5+I51kLc++HP5ZCnzcU9CIiF6AwYR9grU0/cSPn8yD5umPxAAAgAElEQVTPlSSSx7K34NePnPXz2vpWROSCFCbs44wxvU/cMMb0AQ55riSRHFsXwvxHofGNzoY5IiJyQQozZn8n8LEx5vWc27FAvrvqiRSZQ1tg5m1Qpamz/a12xRMRuWCF2VRnG9DeGBMGGGvtcc+XJaVaymGYMgj8A2HIVCgT5nZFIiIl2jmbS8aYfxpjKlprE621x40xlYwxzxVHcVIKZWXCzFFw5A8Y9JFzgp2IiFyUwvSN9rTWHjlxw1p7GOjluZKkVJv/KGxfDDf+C2p3cLsaERGfUJiw9zfGlDlxwxgTApQ5y/UiF2blB/DLf6H93XC5poWIiBSVwkzQ+wj41hjzfs7t0cCHnitJSqWdP8Lcv0P9a6D7M25XIyLiUwozQe8lY8xa4FrAAF8DtT1dmJQih3c6Z9JXqgsD3gP/CzmfSUREClLY9Uz7cXbR649znv0Gj1UkpUvacZg6BGwWDJ0OIRXdrkhExOcU2IQyxjQCBgNDgHhgOs7Su27FVJv4uuxs+HQsxG2C4bMgor7bFYmI+KSz9ZduBH4AbrLWbgUwxtxfLFVJ6fDds7DpK+e42vpXu12NiIjPOls3fn+c7vtFxph3jDHX4IzZi1y8tTPgx39Bm1HOufQiIuIxBYa9tfYza+0goDGwGLgfqGqMecsY06OY6hNfFLsSPr8HaneEnuPB6D2kiIgnnXOCnrU2yVr7sbX2RiAKWA2M83hl4puO7YVpQ6FcVRg4GQJ0gKKIiKed1+ki1toEa+3b1loNsMr5S092gj49EYZMh7IRblckIlIqaEGzFA9r4Yt7YO9qGDwFqjZ1uyIRkVJD54ZK8fhhAqz7BK55AhrraAURkeKksBfP2zAHvnsOWgyETlq9KSJS3Dwa9saY640xm4wxW40xZ0zqM8bUNsZ8a4xZa4xZbIyJOu3x8saYPcaY1z1Zp3jQ/t/g0zugRhvo/Zpm3ouIuMBjYW+M8QfeAHoCTYEhxpjTB2onAJOstS2BZ4AXTnv8WeB7T9UoHpYY52yFG1zBGacPDHa7IhGRUsmTLft2wFZr7XZrbTowDehz2jVNgW9zPl+U93FjTBugKjDfgzWKp2SmwYwRkBQHgz+GctXcrkhEpNTyZNjXAHbnuR2bc19ea3B26gPoC5QzxkQYY/yAl4EHPVifeIq1MPdv8MdSuPlNqHG52xWJiJRqngz7/AZn7Wm3HwC6GGN+BboAe4BM4C7gK2vtbs7CGDPWGBNjjImJi4sripqlKCx7C379CK56EJr3P/f1IiLiUZ5cZx8L1MxzOwrYm/cCa+1eoB+AMSYM6G+tPWqM6QB0NsbcBYQBQcaYRGvtuNO+fiIwESA6Ovr0NxLihq0LYf6j0PhG6PqI29WIiAieDfsVQENjTF2cFvtgYGjeC4wxkUCCtTYbeBh4D8BaOyzPNaOA6NODXrxQ3GaYeRtUaQp93wY/rewUEfEGHvttbK3NBO4BvgE2ADOstb8bY54xxvTOuawrsMkYsxlnMt7znqpHPCzlMEwdDP6BMGQqlAlzuyIREclhrPWN3u/o6GgbExPjdhmlU1YmfNwfdv4Eo76EWu3drkhEpFQwxqy01kaf6zrtjS8X75tHYPti6P26gl5ExAtpUFUuTsz7sPxtaH83XD7C7WpERCQfCnu5cDt/hK8egAbXQvdn3K5GREQKoLCXC5OwA6aPgEp1of//wF8jQiIi3kphL+cv9Ziz573NhqHTIaSi2xWJiMhZqDkm5yc7Cz4dC4c2w/BPIKK+2xWJiMg5KOzl/Hz3LGyeBz3HQ/1ublcjIiKFoG58Kbw10+HHf0Ob0dDudrerERGRQlLYS+HExsAX90LtTtBrPJj8zjkSERFvpLCXczu6B6YNdc6kHzjJ2RJXRERKDI3Zy9mlJztBn54EIz+HshFuVyQiIudJYS8FsxY+vxv2rXEOt6nSxO2KRETkAqgbXwq2ZAL8/ilc+yRc2tPtakRE5AIp7CV/67+ARc9By0HQ8a9uVyMiIhdBYS9n2rcWPrsDakTDTa9q5r2ISAmnsJdTJcY5E/KCK8LgjyEw2O2KRETkImmCnpyUmQbTh0PSIbhtnrPUTkRESjyFvTishS//BruXwYD34ZLWblckIiJFRN344lj2Jqz+CK76BzTv53Y1IiJShBT2AlsWwPzHoMlN0PVht6sREZEiprAv7eI2w6zboEoz6Ps2+Om/hIiIr9Fv9tIsOQGmDoKAMjBkCgSVdbsiERHxAE3QK62yMmDmKDiyG0Z9CRVruV2RiIh4iMK+tPrmEdjxPfR5E2q1d7sa8ULWWtIys0nNyCIlI4vk9CxS0p3PU9Kd26kZzkdYcADhoUGEhwURXjaI8NAgAvzVcSjiLRT2pVHMe7B8InS4B1oPc7sauUBZ2TY3eE+EcHJ65sn7Mk4Gct5wTs4T2LnBnZFFanoWyRmZpKRnk5LzPNn2wuurEBJIRNmc8D/tIyIsiPCyZU55PDjQv+j+cUTkFAr70mbHD/DVg9DgWuj+jNvV+Ky8reLTw/VkCzknWDOycsP1lEDOJ5RT8jxfemb2edcVHOhHSKA/oUEBzudB/oQGBlAhJJDq5YMJCfJ3PgL9CQ3yJzjw5Ocn7g8JOvWxMoH+JKZmEp+URkJSOglJ6cQnpnM4OZ34pHQSEtPZFZ/Mqj+OcDg5nawC3kGUDfKnUtmgPG8AyuS8KTjZWxAedvLxsDIBGG3lLFIoCvvSJGEHzBgJ4fVgwHvgV3pbUlnZNrcVnJqendOiPTNQ8wvek4Gc04rOONkSzvsc59sq9vczhOaEad5gDQn0p2JoIMEnQjfQn5CggJw//XI/Dz3ta3ID+UQ4B/jj5+fJcCx3ziuysy3HUjNOvinI+fPEG4SEpDTik9KJS0xj0/7jxCelk1bAm5ogf79TegoqheZ8Xjbvm4IyufdVCAn08N9fxHsp7EuL1GMwdQjYbBgyDYIruF3ReUtMy2TVrsO5IXsihAtqPZ+t+zo968JaxaG5IZsTrIH+VMxpFYcG+RMc5J8b2MH5BnCAE9CBAWcEelCA749x+/kZKoYGUTE0iHqVz329tZbk9Kw8bwzSzug1OPHYrvhkEpLSSUzLzP+1DblvCE4OJZw5nHDizUGlskEEat6B+AiFfWmQnQWf3g6HNsOITyGivtsVnbfNB44zdlIMO+OT8308wM8U2KKtGBqY0/r1y+m+znNdnnDO+/UhgXnCulhaxZIfYwxlywRQtkwANcNDC/U1aZlZHE7KOGNY4cSbgsM5923af5yEpHSOpGRgC+iFKR8cQERYmQKHEpw3BmVy79O8A/FWCvvS4NtnYPPX0GsC1OvqdjXn7Zvf9/O36asJCQrg7RFtqFkp9JRx49Agf7XAJFeZAH+qVfCnWoXCndiYmZXNkZSMfOcanBhWSEhKZ3dCMmt2HyEhKZ3MAsZoQgL9T+s1ODmccKK3IO9QQznNO5BiorD3dWumw0+vQJvR0HaM29Wcl+xsyyvfbuHVb7dwWc2KvD28TaF/gYsUVoC/H5FhZYgMKwNVz329tZZjqZk5vQZp+fYaxOe8cdhyIJH4pDRSMwqed1CpbOApbwYiyp7+RuHk6oUKIYH4q4dJLoDC3pftXgFf3At1OkOv8VCCWhDHUzO4f/oaFm44wIA2UTx3c3N1kYpXMMZQISSQCiGB1I0s3K6TyemZBc41SMgZbohPSif2cDLxSekcTy143kHF0HzeDOT8WenEsELZIKLCQygfHFiUf3UpwRT2vuroHpg21DmT/pYPwb/k/NBvj0vk9pzx+ad7N2Nkh9rq6pQSLTQogNDwws87SM/Mdt4Y5L4pSDul1+DEn1sOJpKQ5LyJOH3egZ+BFlEV6dQggo4NIrm8ViW9YS7FFPa+KD0Zpg2BjGS49QsoG+F2RYX23cYD3Dd1NYEBfnz0pyvoUL/k1C5SVIIC/KhaPpiq5Qs3bJWVbTmaknHKsMLG/cf5aesh/vv9dt5YtI3gQD/a1gmnY4NIOjWIpGn18pp0WooYW9A01BImOjraxsTEuF2G+6yFWaPh99nOErtLr3e7okKx1vLm4m1MmL+JptXL8/aINkRVKlwrSEQKdjw1g+U7Evhpazw/bT3EpgPHAagUGsiV9SNzw79WhH7eSiJjzEprbfS5rlPL3tcsGQ+/fwbXPl1igj4pLZMHZ63hq9/206fVJbzYryUhQepuFCkK5YIDuaZJVa5p4sw+PHgslZ+3xfPj1kP8tPUQc3/bB0BUpRA6NXDC/8r6EUSElXGzbCliatn7kvWfOzvktRwMff9bIibk7YpPYuyklWw5eJyHezZhTOe6Gp8XKSbWWrYfSuLnrYf4ceshft4Wnzs5sGn18nRq6AR/u7rhhAapbeiNCtuyV9j7in1r4b3roGozuPVLCPT+JWo/bInjnim/AvD60NZ0bliILdVExGMys7JZt/cYP209xI9bDrFy12HSs7IJ9DdcXquS0/JvGEnLGhV0qqGXUNiXJokHYWI3wMLti6BcIRYLu8hayzs/bOfFeRtpVLUcE0dEa7xQxAulpGcRsysht8v/973HsBbKlQnginoRdGoQQaeGkdSvHKYeOZdozL60yEyD6cMhOR5u+9rrgz4lPYtxn67l89V76dWiGuMHXEbZMvpvKOKNQoL86dywcm6vW0JSOkvzjPcv3HAAgKrly9CxQSQdcyb8afMr76PfsiWZtfDl/bD7F7jlA7ikldsVnVXs4WTumLyS9fuO8eB1l3JX1/pqDYiUIOFlg7ihZXVuaFkdgN0JyU6X/9ZDLN4Ux6er9gDQoEpY7mS/K+qFa3MfL6Bu/JLs59dh/qPQ5SHo9ojb1ZzV0m3x3D1lFRlZ2bw6uDXdGldxuyQRKULZ2ZYN+53x/p+2xvPLjnhSM7Lx9zO0jKqQG/6ta1WkTIBW2xQVjdn7ui0LYMpAaHyjs0Oen3dOlrHW8uHPO3l27gbqRpZl4og21Ksc5nZZIuJhaZlZ/PrHkdyW/5rdR8i2zmFB7eqG54Z/42rltLnPRVDY+7K4TfDutVCpNtz2DQQVbn/u4paakcVjs9cxa2Us1zapyr8HXUY5deeJlErHUjNYti0+d43/1oOJgDM0cGX9iNzwL+yWwuLQBD1flZwAUwZBQBkYPNVrg37f0RTunLySNbFHue+ahtx3TUO9excpxcoHB9KjWTV6NKsGwP6jqTld/k7L/8u1zuY+tcJDc3f1u7J+BJXKBrlZts9Qy74kycqAj/rDH0udtfS1rnC7onzF7Ezgzo9WkZKeyb8GteK6nB9uEZH8WGvZFpfIj1sO8ePWeJZtjycxLRNjoNkl5XPDP7p2uHbXPI268X3R3AdgxTvQ501oPcztavI15Zc/ePKLddSoGMLEkdE0qlrO7ZJEpITJzMpmTezR3Fb/r38cJiPLEuTvR5valejU0Onyb1GjAv6lvMdQYe9rVvwP5v4NOtwD1z3vdjVnSM/M5qk5vzPllz/o0qgyrw5uTYVQjc+LyMVLTs/MOczHaflv2HcMgPLBAXSo7xzh27FBJPUiy5a65bwas/clO36Aef+ABt2h+zNuV3OGg8dTueujVcTsOsyfu9bngR6Xlvp32yJSdEKDAuh6aRW6Xuos2T2UmMbP2+L5eeshfthyiG9+dzb3qV4h+OR4f4MIqpTT5j4nqGXv7RJ2wDvdoGwVGLMAgiu4XdEpVu8+wp2TV3I0JYPxt7TkxpaXuF2SiJQi1lr+SEjO3dXv523xHEnOAKBR1bDc8L+iXgRhPrhbp7rxfUHqMfhfdzi+H27/DiLqu13RKWbG7ObR2euoUq4ME0dE0/SS8m6XJCKlXHa2Zf2+Y7nhv3xHAmmZ2QT4GVrVrJjb5d+qZkWCArxzf5LzobAv6bKzYNpQZ/OcEZ9BvS5uV5QrIyub5+du4IOfd9KxQQSvD7lcy2NExCulZmSxatfh3PD/bc9Rsi2EBvlzRd1wp+XfMJJLq5YrkeP9GrMv6b59GjZ/Db0meFXQxyemcfeUVSzbnsCYTnUZ17OxjroUEa8VHOjPlQ0iubJBJABHkzNYuj0+d43/ok0bAIgMC+LK+pG5x/jWqBjiZtlFTmHvjdZMg5/+A9G3Qbvb3a4m17o9R7lj8koOJabx70GX0bd1lNsliYiclwqhgVzfvBrXN3f2/9hzJMUZ68+Z6f/Fmr0A1I0sS8cGzs5+HepFlvjVRerG9za7V8AHvaDmFU73vb93/Af7fPUeHvpkLeGhQbw9IpoWUd41UVBE5GJZa9l8IDG3y3/Z9niS07MwBlrUqJA72a9N7UoEB3rH5j4asy+JjsbCxG4QFAq3L4LQcLcrIjMrm5e+2cTEJdtpVzecN4ddTmRYGbfLEhHxuIysbNbsPpIb/r/+cYTMbEuZAD/a1gnnypyWf7NL3NvcR2Ff0qQnw/vXQ/x2Z4ldlSZuV8SR5HTunforP2w5xMgOtXn8xqYEanxeREqpxLRMlu+I58ctzpj/pgPHAagQEsiVeTb3qRMRWmyT/TRBrySxFmb/GfathaHTvSLoN+4/xthJK9l/NJX/69+CQW1ruV2SiIirwsoEcHXjqlzduCrgbCi2dFs8P25xWv7z1u0HoEbFEDo2cML/yvqRVC7nfm+oR8PeGHM98B/AH3jXWvviaY/XBt4DKgMJwHBrbawxphXwFlAeyAKet9ZO92Strvr+JVg/29kdr9F1blfDV7/t44GZawgrE8C0O9pzea1KbpckIuJ1qpQLpk+rGvRpVQNrLTsOJeXM8o/n63X7mRETC0DjauVyx/vb1Q2nrAub+3isG98Y4w9sBroDscAKYIi1dn2ea2YCX1prPzTGXA2MttaOMMY0Aqy1dosx5hJgJdDEWnukoNcrsd346z+HGSOh5WDo+19wcZ1nVrblXws28caibbSuVZG3h7ehSnltNykicr6ysi3r9hzNHe+P2XmY9KxsXh/aukh3GvWGbvx2wFZr7facgqYBfYD1ea5pCtyf8/kiYDaAtXbziQustXuNMQdxWv8Fhn2JtG8tfHYnRLWFm/7jatAfTcng/umr+W7jQQZF1+SZm5tRJsA7ZpuKiJQ0/n6Gy2pW5LKaFbm7WwNSM7KI2XnYtZVMnpxtVQPYned2bM59ea0B+ud83hcoZ4yJyHuBMaYdEARsO/0FjDFjjTExxpiYuLi4Iiu8WCQehKlDIKQSDPoYAt1rQW89eJy+b/zEks1xPHtzc17s30JBLyJShIID/enUMJIKIe4sp/Zk2OfXTD19zOABoIsx5legC7AHyMx9AmOqA5Nxuvezz3gyaydaa6OttdGVK1cuuso9LTMNpg2D5HgYMhXKVXWtlAXrD3DzGz9zLDWDKbe3Z0T72iVyy0gRESmYJ7vxY4GaeW5HAXvzXmCt3Qv0AzDGhAH9rbVHc26XB+YCj1lrl3mwzuJlLcz5K8Quh1s+gOqXuVJGdrbl9UVb+deCzbSoUYG3R7ThEh/bHlJERByeDPsVQENjTF2cFvtgYGjeC4wxkUBCTqv9YZyZ+RhjgoDPgEnW2pkerLH4LX0d1kyBLuOgWV9XSkhMy+TvM1bzze8H6Ne6Bv/s18JrdoMSEZGi57Gwt9ZmGmPuAb7BWXr3nrX2d2PMM0CMtfYLoCvwgjHGAkuAu3O+fCBwFRBhjBmVc98oa+1qT9VbLDbPh/mPQ9M+0OUhV0rYeSiJ2yfFsP1QEk/c2JTRHeuo215ExMdpB73icnCjczZ9pdpw2zcQVLbYS1i86SB/mfor/n6G14deTsecU6BERKRk8oald3JCcgJMHQwBwTB4arEHvbWW/36/nZe+2UjjauWZOKINNcNDi7UGERFxj8Le07IyYOatcGwPjJoLFWue+2uKUHJ6Jg/OWsvctfu4sWV1XhrQktAgfdtFREoT/db3tK/HwY4lcPNbULNdsb707oRkbp8Uw6YDxxnXszF3XFVP4/MiIqWQwt6TVrzrfFx5L7Qaeu7ri9BPWw9x95RVZGdb3h/Vlq6XVinW1xcREe+hsPeUHUvgq39Awx5w7dPF9rLWWt77aSf//GoD9SuXZeKIaOpEFv9kQBER8R4Ke09I2O4cbhPRAPr/D/yKZw17akYWj3z6G5/+uofrmlXl5YGtCHPhdCUREfEuSoKilnoMpgx2Ph8yFYLLF8vL7j2Swh2TV/LbnqP8vXsj7u7WAD8/jc+LiIjCvmhlZ8EnYyB+K4z4DCLqF8vL/rI9nrs+XkVaZjbvjozm2qbu7bUvIiLeR2FflBY+BVu+gRtehnpdPP5y1lo+WraLp+esp1Z4KBNHRtOgSpjHX1dEREoWhX1RWT0Vfn4Vov8Ebcd4/OXSMrN4YvbvTI/ZzdWNq/DK4FaUD3bn6EQREfFuCvuisHs5zPkL1OkMPf/P4y934Fgqd360kl//OMI93Rrwt+6NND4vIiIFUthfrKOxztn05WvAwEng79nW9ao/DnPn5JUkpmXy5rDL6dWiukdfT0RESj6F/cVIT4KpQyAjBW6dA6HhHn256Sv+4PHZv1OtQjCT/tSOxtWKZ6a/iIiUbAr7C5WdDbP/DPt/g6EzoEpjj71UemY2z365nsnLdtG5YSSvDWlNxdAgj72eiIj4FoX9hVryEqz/HLo/C416eOxlDiWmcddHq1i+M4E7rqrHg9ddSoC/n8deT0REfI/C/kL8PhsWvwCXDXH2vfeQ32KPMnZyDIeT0/nP4Fb0aVXDY68lIiK+S2F/vvatgc/uhKh2cOMr4KFT5D5dFcvDn/5GZFgZZt15Jc1rVPDI64iIiO9T2J+P4wdg6lBnIt6gjyAwuMhfIjMrmxfmbeR/P+6gfb1w3hh6ORFhZYr8dUREpPRQ2BdWZhpMHw4pCXDb11Cu6LekTUhK554pq/h5WzyjO9bhkV5NCNT4vIiIXCSFfWFYC3Pug9jlcMuHUP2yIn+J9XuPMXZyDAePpzF+QEtuia5Z5K8hIiKlk8K+MH5+DdZMha4PQ7Obi/zp56zZy4Oz1lAxJIgZd3SgVc2KRf4aIiJSeinsz2XzfFjwBDS9Ga76R5E+dVa2Zfw3m/jv99uIrl2JN4dfTpVyRT8PQERESjeF/dkc3AizboNqLeDmt8Cv6MbPjyZncO+0X1myOY5hV9TiyZuaERSg8XkRESl6CvuCJCfA1MEQGAJDpkJQaJE99eYDx7l9Ugx7j6Twz74tGHpFrSJ7bhERkdMp7POTlQEzRsKxPTDqK6gQVWRP/fW6/fx9xmpCggKYent7out4dj99ERERhX1+Uo44Hze9CjXbFslTZmdbXvl2C69+u4XLalbk7eFtqFZB4/MiIuJ5Cvv8hFWGsYuK7Lja46kZ3D99NQs3HGRAmyieu7k5wYH+RfLcIiIi56KwL0gRBf22uETGTophZ3wyT/duxsgOtTEe2mJXREQkPwp7D/pu4wHum7qawAA/PvrTFXSoH+F2SSIiUgop7D3AWsubi7cxYf4mmlYvz9sj2hBVqehm84uIiJwPhX0RS0rL5MFZa/jqt/30aXUJL/ZrSUiQxudFRMQ9CvsitCs+ibGTVrLl4HEe7dWEMZ3ranxeRERcp7AvIj9sieOeKb8C8OFt7ejcsLLLFYmIiDgU9hfJWss7P2znxXkbaVS1HBNHRFMrQuPzIiLiPRT2FyElPYtxn67l89V76dWiGuMHXEbZMvonFRER76JkukCxh5O5Y/JK1u87xoPXXcpdXetrfF5ERLySwv4CLN0Wz91TVpGRlc17t7alW+MqbpckIiJSIIX9ebDW8uHPO3l27gbqRpZl4og21Ksc5nZZIiIiZ6WwL6TUjCwem72OWStjubZJVf496DLKBRfNlroiIiKepLAvhH1HU7hz8krWxB7lvmsact81DfHz0/i8iIiUDAr7c4jZmcCdH60iJT2Tt0e04bpm1dwuSURE5Lwo7M/i41928dQXv1OjYghTbr+CRlXLuV2SiIjIeVPY5yM9M5snv/idqcv/oEujyrw6uDUVQjU+LyIiJZPCPh+JaZks2RzHn7vW54Eel+Kv8XkRESnBFPb5CC8bxNd/7azZ9iIi4hP83C7AWynoRUTEVyjsRUREfJzCXkRExMcp7EVERHycwl5ERMTHKexFRER8nMJeRETExynsRUREfJzCXkRExMcp7EVERHycwl5ERMTHKexFRER8nMJeRETExxlrrds1FAljTByw67S7KwBH87k8v/vzuy8SOFQkBZ6fguoujucp7Nec67rz+bc/n/vd+p7kV0txPY+nvydne0w/Kxf/NcXxs+JN3xPQz8rZ7ivq70tta23lc15lrfXZD2BiYe8v4L4Yb6q7OJ6nsF9zruvO59/+fO5363vi5vfF09+T8/2+6GeleL4vJfV74ub3RT8rBX/4ejf+nPO4v6Br3VBUtVzI8/x/e/fuImcZhmH8ulG0sBRUTCxUVFy0EA+FjQoiESSKigdslBCIoGCp4j+QTgLiqihrZZDgIUjEQgkiWHhA0BjEKILBIqCdIB54LGZDsutOsjNhvvfz+64fTLHvnG723ncf3ll2ZrP3Od3tZvnez7PeQqteFt3Jqa5zr5z5fbrYK33qBNwrm32ezgzmZfxFSPJ5Vd3QOodOsJN+spf+sZN+atXL0E/2Z+rl1gH0H3bST/bSP3bST0168WQvSdLAebKXJGngHPaSJA2cw16SpIFz2EuSNHAO+zkkuSzJq0n2tc4ydknOS/J6kleSPNI6j9wffZXkntV98m6SO1rnESS5Oslykn1JHl/kc41u2Cd5LcmxJN+sW9+W5LskR5I8farHqKofq2rHYpOO14wd3Qvsq6qdwPbOw47ELJ24P7ozYy/vrO6TR4EHG8QdhRk7OVxVu4AHgIX+7/3ohj2wAmw7eSHJWcALwJ3AEvBwkqUk1yZ5b93lgu4jj84Km+wI2Ar8vHqzfzrMODYrbL4TdWeF2Xt5bvV6LcYKM3SSZCXSliIAAAIiSURBVDvwCfDhIkONbthX1cfAb+uWbwKOrJ5I/gT2AndX1ddVdde6y7HOQ4/MLB0BR5kMfBjhz3NXZuxEHZmll0zsBt6vqi+7zjoWs+6VqtpfVTcDC/0zpL8cJ7Zw4nQIkwGyZdqNk5yfZBm4Lskziw4nYHpHbwH3JXmRHr0P9Uhs2In7o7lpe+VJ4Hbg/iS7WgQbsWl75dYke5K8BBxYZICzF/ng/yPZYG3qWwtW1a+Am6VbG3ZUVb8Dj3UdRsD0TtwfbU3rZQ+wp+swAqZ3chA42EUAT/YTR4FLTvp6K/BLoyzamB31j530k730T/NOHPYTnwFXJLk0yTnAQ8D+xpm0lh31j530k730T/NORjfsk7wBfApcleRokh1V9TfwBPABcBh4s6oOtcw5ZnbUP3bST/bSP33txE+9kyRp4EZ3spckaWwc9pIkDZzDXpKkgXPYS5I0cA57SZIGzmEvSdLAOewlzS3JRUn2JvkhybdJDiS5snUuSWs57CXNJUmAt4GDVXV5VS0BzwIXtk0maT0/CEfSvG4D/qqq5eMLVfVVwzySpvBkL2le1wBftA4h6fQc9pIkDZzDXtK8DgHXtw4h6fQc9pLm9RFwbpKdxxeS3JjkloaZJG3AT72TNLckFwPPMznh/wH8BDxVVd+3zCVpLYe9JEkD58v4kiQNnMNekqSBc9hLkjRwDntJkgbOYS9J0sA57CVJGjiHvSRJA/cvsnrY3bGt//UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of C versus train and test scores\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(cv_results['param_C'], cv_results['mean_test_score'])\n",
    "plt.plot(cv_results['param_C'], cv_results['mean_train_score'])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the training accuracy monotonically increases with C, the test accuracy gradually reduces. Thus, we can conclude that higher values of C tend to **overfit** the model. This is because a high C value aims to classify all training examples correctly (since C is the *cost of misclassification* - if you impose a high cost on the model, it will avoid misclassifying any points by overfitting the data). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's finally look at the optimal C values found by GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The highest test accuracy is 0.931055900621118 at C = 10\n"
     ]
    }
   ],
   "source": [
    "best_score = model_cv.best_score_\n",
    "best_C = model_cv.best_params_['C']\n",
    "\n",
    "print(\" The highest test accuracy is {0} at C = {1}\".format(best_score, best_C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify range of parameters (C) as a list\n",
    "params1 = {\"C\": [i for i in range(1,100)]}\n",
    "\n",
    "model1  = SVC()\n",
    "\n",
    "# set up grid search scheme\n",
    "# note that we are still using the 5 fold CV scheme we set up earlier\n",
    "model_cv1 = GridSearchCV(estimator = model1, param_grid = params1, \n",
    "                        scoring= 'accuracy', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                       return_train_score=True)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 99 candidates, totalling 495 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 495 out of 495 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=4, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model - it will fit 5 folds across all values of C\n",
    "model_cv1.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.242744</td>\n",
       "      <td>0.006867</td>\n",
       "      <td>0.035105</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.917702</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.010130</td>\n",
       "      <td>67</td>\n",
       "      <td>0.951863</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.950699</td>\n",
       "      <td>0.946040</td>\n",
       "      <td>0.943711</td>\n",
       "      <td>0.947593</td>\n",
       "      <td>0.003135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.220011</td>\n",
       "      <td>0.020658</td>\n",
       "      <td>0.031914</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>2</td>\n",
       "      <td>{'C': 2}</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931988</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>16</td>\n",
       "      <td>0.959239</td>\n",
       "      <td>0.954193</td>\n",
       "      <td>0.959239</td>\n",
       "      <td>0.956910</td>\n",
       "      <td>0.952640</td>\n",
       "      <td>0.956444</td>\n",
       "      <td>0.002660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.170536</td>\n",
       "      <td>0.009827</td>\n",
       "      <td>0.031715</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>3</td>\n",
       "      <td>{'C': 3}</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931366</td>\n",
       "      <td>0.010458</td>\n",
       "      <td>29</td>\n",
       "      <td>0.962345</td>\n",
       "      <td>0.959627</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.960016</td>\n",
       "      <td>0.956910</td>\n",
       "      <td>0.960637</td>\n",
       "      <td>0.002511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.195275</td>\n",
       "      <td>0.024790</td>\n",
       "      <td>0.031914</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>4</td>\n",
       "      <td>{'C': 4}</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>0.011620</td>\n",
       "      <td>25</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.962345</td>\n",
       "      <td>0.960792</td>\n",
       "      <td>0.963820</td>\n",
       "      <td>0.002215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.196867</td>\n",
       "      <td>0.031455</td>\n",
       "      <td>0.028723</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>5</td>\n",
       "      <td>{'C': 5}</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.948758</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>0.012917</td>\n",
       "      <td>25</td>\n",
       "      <td>0.966615</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.968168</td>\n",
       "      <td>0.963509</td>\n",
       "      <td>0.962733</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>0.002163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.171732</td>\n",
       "      <td>0.018526</td>\n",
       "      <td>0.030317</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>6</td>\n",
       "      <td>{'C': 6}</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.948758</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932609</td>\n",
       "      <td>0.013051</td>\n",
       "      <td>4</td>\n",
       "      <td>0.969332</td>\n",
       "      <td>0.967780</td>\n",
       "      <td>0.969332</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.965450</td>\n",
       "      <td>0.967236</td>\n",
       "      <td>0.002048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.162957</td>\n",
       "      <td>0.010367</td>\n",
       "      <td>0.028324</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>7</td>\n",
       "      <td>{'C': 7}</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931366</td>\n",
       "      <td>0.012203</td>\n",
       "      <td>29</td>\n",
       "      <td>0.971661</td>\n",
       "      <td>0.968168</td>\n",
       "      <td>0.970885</td>\n",
       "      <td>0.965450</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.968711</td>\n",
       "      <td>0.002285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.163954</td>\n",
       "      <td>0.008665</td>\n",
       "      <td>0.029920</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>8</td>\n",
       "      <td>{'C': 8}</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931056</td>\n",
       "      <td>0.012132</td>\n",
       "      <td>31</td>\n",
       "      <td>0.972438</td>\n",
       "      <td>0.969332</td>\n",
       "      <td>0.971661</td>\n",
       "      <td>0.965450</td>\n",
       "      <td>0.969720</td>\n",
       "      <td>0.969720</td>\n",
       "      <td>0.002431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.167147</td>\n",
       "      <td>0.024088</td>\n",
       "      <td>0.029122</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>9</td>\n",
       "      <td>{'C': 9}</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.942547</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.011428</td>\n",
       "      <td>67</td>\n",
       "      <td>0.972438</td>\n",
       "      <td>0.969720</td>\n",
       "      <td>0.972826</td>\n",
       "      <td>0.967780</td>\n",
       "      <td>0.970497</td>\n",
       "      <td>0.970652</td>\n",
       "      <td>0.001847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.208441</td>\n",
       "      <td>0.018007</td>\n",
       "      <td>0.027726</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931056</td>\n",
       "      <td>0.011809</td>\n",
       "      <td>31</td>\n",
       "      <td>0.973991</td>\n",
       "      <td>0.970497</td>\n",
       "      <td>0.973602</td>\n",
       "      <td>0.968944</td>\n",
       "      <td>0.970885</td>\n",
       "      <td>0.971584</td>\n",
       "      <td>0.001924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.189878</td>\n",
       "      <td>0.019578</td>\n",
       "      <td>0.028725</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>11</td>\n",
       "      <td>{'C': 11}</td>\n",
       "      <td>0.906832</td>\n",
       "      <td>0.942547</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.012321</td>\n",
       "      <td>67</td>\n",
       "      <td>0.977484</td>\n",
       "      <td>0.971273</td>\n",
       "      <td>0.973602</td>\n",
       "      <td>0.968556</td>\n",
       "      <td>0.971661</td>\n",
       "      <td>0.972516</td>\n",
       "      <td>0.002961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.171132</td>\n",
       "      <td>0.007817</td>\n",
       "      <td>0.029722</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>12</td>\n",
       "      <td>{'C': 12}</td>\n",
       "      <td>0.908385</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930745</td>\n",
       "      <td>0.011603</td>\n",
       "      <td>37</td>\n",
       "      <td>0.976708</td>\n",
       "      <td>0.972050</td>\n",
       "      <td>0.973991</td>\n",
       "      <td>0.970109</td>\n",
       "      <td>0.972438</td>\n",
       "      <td>0.973059</td>\n",
       "      <td>0.002204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.205249</td>\n",
       "      <td>0.020704</td>\n",
       "      <td>0.029321</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>13</td>\n",
       "      <td>{'C': 13}</td>\n",
       "      <td>0.906832</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>58</td>\n",
       "      <td>0.976708</td>\n",
       "      <td>0.972826</td>\n",
       "      <td>0.973602</td>\n",
       "      <td>0.971273</td>\n",
       "      <td>0.972438</td>\n",
       "      <td>0.973370</td>\n",
       "      <td>0.001831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.214024</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>0.028123</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>14</td>\n",
       "      <td>{'C': 14}</td>\n",
       "      <td>0.906832</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929193</td>\n",
       "      <td>0.011809</td>\n",
       "      <td>89</td>\n",
       "      <td>0.977873</td>\n",
       "      <td>0.972826</td>\n",
       "      <td>0.974379</td>\n",
       "      <td>0.971273</td>\n",
       "      <td>0.973991</td>\n",
       "      <td>0.974068</td>\n",
       "      <td>0.002188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.206037</td>\n",
       "      <td>0.028242</td>\n",
       "      <td>0.029525</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>15</td>\n",
       "      <td>{'C': 15}</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929503</td>\n",
       "      <td>0.010421</td>\n",
       "      <td>85</td>\n",
       "      <td>0.977873</td>\n",
       "      <td>0.972438</td>\n",
       "      <td>0.974767</td>\n",
       "      <td>0.971661</td>\n",
       "      <td>0.973991</td>\n",
       "      <td>0.974146</td>\n",
       "      <td>0.002163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.164160</td>\n",
       "      <td>0.006899</td>\n",
       "      <td>0.028523</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>16</td>\n",
       "      <td>{'C': 16}</td>\n",
       "      <td>0.908385</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.011470</td>\n",
       "      <td>67</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.972826</td>\n",
       "      <td>0.976708</td>\n",
       "      <td>0.972826</td>\n",
       "      <td>0.974767</td>\n",
       "      <td>0.975078</td>\n",
       "      <td>0.002146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.161369</td>\n",
       "      <td>0.013191</td>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>17</td>\n",
       "      <td>{'C': 17}</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929503</td>\n",
       "      <td>0.010421</td>\n",
       "      <td>85</td>\n",
       "      <td>0.977873</td>\n",
       "      <td>0.974767</td>\n",
       "      <td>0.977096</td>\n",
       "      <td>0.973991</td>\n",
       "      <td>0.975155</td>\n",
       "      <td>0.975776</td>\n",
       "      <td>0.001465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.162754</td>\n",
       "      <td>0.006475</td>\n",
       "      <td>0.025332</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>18</td>\n",
       "      <td>{'C': 18}</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929503</td>\n",
       "      <td>0.010421</td>\n",
       "      <td>85</td>\n",
       "      <td>0.979037</td>\n",
       "      <td>0.975543</td>\n",
       "      <td>0.977096</td>\n",
       "      <td>0.975155</td>\n",
       "      <td>0.975932</td>\n",
       "      <td>0.976553</td>\n",
       "      <td>0.001402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.169141</td>\n",
       "      <td>0.013701</td>\n",
       "      <td>0.026728</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>19</td>\n",
       "      <td>{'C': 19}</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>0.010713</td>\n",
       "      <td>58</td>\n",
       "      <td>0.979425</td>\n",
       "      <td>0.976708</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.975543</td>\n",
       "      <td>0.976708</td>\n",
       "      <td>0.977329</td>\n",
       "      <td>0.001358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.207443</td>\n",
       "      <td>0.012504</td>\n",
       "      <td>0.028524</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>20</td>\n",
       "      <td>{'C': 20}</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>58</td>\n",
       "      <td>0.979037</td>\n",
       "      <td>0.977096</td>\n",
       "      <td>0.979425</td>\n",
       "      <td>0.975543</td>\n",
       "      <td>0.976708</td>\n",
       "      <td>0.977562</td>\n",
       "      <td>0.001461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.210637</td>\n",
       "      <td>0.020366</td>\n",
       "      <td>0.028324</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>21</td>\n",
       "      <td>{'C': 21}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.009389</td>\n",
       "      <td>45</td>\n",
       "      <td>0.979425</td>\n",
       "      <td>0.977096</td>\n",
       "      <td>0.979425</td>\n",
       "      <td>0.976708</td>\n",
       "      <td>0.977484</td>\n",
       "      <td>0.978028</td>\n",
       "      <td>0.001167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.172937</td>\n",
       "      <td>0.012434</td>\n",
       "      <td>0.028324</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>22</td>\n",
       "      <td>{'C': 22}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.010082</td>\n",
       "      <td>45</td>\n",
       "      <td>0.979425</td>\n",
       "      <td>0.977484</td>\n",
       "      <td>0.979814</td>\n",
       "      <td>0.977096</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978416</td>\n",
       "      <td>0.001059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.169746</td>\n",
       "      <td>0.010914</td>\n",
       "      <td>0.026329</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>23</td>\n",
       "      <td>{'C': 23}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>58</td>\n",
       "      <td>0.979814</td>\n",
       "      <td>0.977873</td>\n",
       "      <td>0.979425</td>\n",
       "      <td>0.977096</td>\n",
       "      <td>0.979037</td>\n",
       "      <td>0.978649</td>\n",
       "      <td>0.001012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.165956</td>\n",
       "      <td>0.008775</td>\n",
       "      <td>0.028323</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>24</td>\n",
       "      <td>{'C': 24}</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>0.010892</td>\n",
       "      <td>58</td>\n",
       "      <td>0.980202</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.979425</td>\n",
       "      <td>0.977096</td>\n",
       "      <td>0.980202</td>\n",
       "      <td>0.979037</td>\n",
       "      <td>0.001203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.182305</td>\n",
       "      <td>0.010780</td>\n",
       "      <td>0.026728</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>25</td>\n",
       "      <td>{'C': 25}</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.011428</td>\n",
       "      <td>67</td>\n",
       "      <td>0.980590</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.980978</td>\n",
       "      <td>0.977096</td>\n",
       "      <td>0.980202</td>\n",
       "      <td>0.979425</td>\n",
       "      <td>0.001493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.166941</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.027327</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>26</td>\n",
       "      <td>{'C': 26}</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929503</td>\n",
       "      <td>0.010830</td>\n",
       "      <td>85</td>\n",
       "      <td>0.980978</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.980978</td>\n",
       "      <td>0.977484</td>\n",
       "      <td>0.980590</td>\n",
       "      <td>0.979658</td>\n",
       "      <td>0.001485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.182105</td>\n",
       "      <td>0.010660</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>27</td>\n",
       "      <td>{'C': 27}</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>45</td>\n",
       "      <td>0.981366</td>\n",
       "      <td>0.978649</td>\n",
       "      <td>0.981366</td>\n",
       "      <td>0.977484</td>\n",
       "      <td>0.980590</td>\n",
       "      <td>0.979891</td>\n",
       "      <td>0.001561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.174320</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>0.026330</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>28</td>\n",
       "      <td>{'C': 28}</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>45</td>\n",
       "      <td>0.981366</td>\n",
       "      <td>0.978649</td>\n",
       "      <td>0.980978</td>\n",
       "      <td>0.978649</td>\n",
       "      <td>0.980590</td>\n",
       "      <td>0.980047</td>\n",
       "      <td>0.001167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.177712</td>\n",
       "      <td>0.005548</td>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>29</td>\n",
       "      <td>{'C': 29}</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.010272</td>\n",
       "      <td>67</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.978649</td>\n",
       "      <td>0.980978</td>\n",
       "      <td>0.979425</td>\n",
       "      <td>0.980978</td>\n",
       "      <td>0.980435</td>\n",
       "      <td>0.001242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.169949</td>\n",
       "      <td>0.014009</td>\n",
       "      <td>0.027123</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>30</td>\n",
       "      <td>{'C': 30}</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>45</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.979037</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.979814</td>\n",
       "      <td>0.981366</td>\n",
       "      <td>0.980978</td>\n",
       "      <td>0.001345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.185503</td>\n",
       "      <td>0.016363</td>\n",
       "      <td>0.024135</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>70</td>\n",
       "      <td>{'C': 70}</td>\n",
       "      <td>0.908385</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.942547</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.012242</td>\n",
       "      <td>45</td>\n",
       "      <td>0.987578</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.986413</td>\n",
       "      <td>0.986801</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.000549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.185697</td>\n",
       "      <td>0.013109</td>\n",
       "      <td>0.025133</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>71</td>\n",
       "      <td>{'C': 71}</td>\n",
       "      <td>0.908385</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.012242</td>\n",
       "      <td>45</td>\n",
       "      <td>0.987578</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.986413</td>\n",
       "      <td>0.986801</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.000549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.190489</td>\n",
       "      <td>0.018227</td>\n",
       "      <td>0.025133</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>72</td>\n",
       "      <td>{'C': 72}</td>\n",
       "      <td>0.908385</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.012242</td>\n",
       "      <td>45</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.986413</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.987345</td>\n",
       "      <td>0.000581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.214820</td>\n",
       "      <td>0.032129</td>\n",
       "      <td>0.025333</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>73</td>\n",
       "      <td>{'C': 73}</td>\n",
       "      <td>0.908385</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.012242</td>\n",
       "      <td>45</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.986413</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.987345</td>\n",
       "      <td>0.000581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.206052</td>\n",
       "      <td>0.026267</td>\n",
       "      <td>0.025328</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>74</td>\n",
       "      <td>{'C': 74}</td>\n",
       "      <td>0.908385</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.012242</td>\n",
       "      <td>45</td>\n",
       "      <td>0.988354</td>\n",
       "      <td>0.988354</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.986413</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.000753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.232179</td>\n",
       "      <td>0.026511</td>\n",
       "      <td>0.026530</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>75</td>\n",
       "      <td>{'C': 75}</td>\n",
       "      <td>0.908385</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>0.011988</td>\n",
       "      <td>58</td>\n",
       "      <td>0.988354</td>\n",
       "      <td>0.988742</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.986413</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.987578</td>\n",
       "      <td>0.000851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.191488</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.024534</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>76</td>\n",
       "      <td>{'C': 76}</td>\n",
       "      <td>0.908385</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.011760</td>\n",
       "      <td>67</td>\n",
       "      <td>0.988354</td>\n",
       "      <td>0.988742</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.986413</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.987578</td>\n",
       "      <td>0.000851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.196873</td>\n",
       "      <td>0.027449</td>\n",
       "      <td>0.024135</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>77</td>\n",
       "      <td>{'C': 77}</td>\n",
       "      <td>0.908385</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929193</td>\n",
       "      <td>0.011394</td>\n",
       "      <td>89</td>\n",
       "      <td>0.988742</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.987578</td>\n",
       "      <td>0.986413</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.987811</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.217219</td>\n",
       "      <td>0.039838</td>\n",
       "      <td>0.025334</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>78</td>\n",
       "      <td>{'C': 78}</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>67</td>\n",
       "      <td>0.988742</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.987578</td>\n",
       "      <td>0.986413</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.987811</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.231580</td>\n",
       "      <td>0.027936</td>\n",
       "      <td>0.025133</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>79</td>\n",
       "      <td>{'C': 79}</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.010865</td>\n",
       "      <td>67</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.987578</td>\n",
       "      <td>0.986413</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.987888</td>\n",
       "      <td>0.001081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.186901</td>\n",
       "      <td>0.013106</td>\n",
       "      <td>0.024533</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>80</td>\n",
       "      <td>{'C': 80}</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>67</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.987578</td>\n",
       "      <td>0.986413</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.987888</td>\n",
       "      <td>0.001081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.179514</td>\n",
       "      <td>0.016508</td>\n",
       "      <td>0.023936</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>81</td>\n",
       "      <td>{'C': 81}</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>67</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.987578</td>\n",
       "      <td>0.986413</td>\n",
       "      <td>0.986801</td>\n",
       "      <td>0.987811</td>\n",
       "      <td>0.001141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.183497</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.023936</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>82</td>\n",
       "      <td>{'C': 82}</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.010130</td>\n",
       "      <td>67</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.987578</td>\n",
       "      <td>0.986801</td>\n",
       "      <td>0.986801</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.001152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.186488</td>\n",
       "      <td>0.011405</td>\n",
       "      <td>0.024336</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>83</td>\n",
       "      <td>{'C': 83}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>67</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.987578</td>\n",
       "      <td>0.986801</td>\n",
       "      <td>0.986801</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.001152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.194872</td>\n",
       "      <td>0.006514</td>\n",
       "      <td>0.024933</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>84</td>\n",
       "      <td>{'C': 84}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>67</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.988354</td>\n",
       "      <td>0.986801</td>\n",
       "      <td>0.986801</td>\n",
       "      <td>0.988121</td>\n",
       "      <td>0.001141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.186095</td>\n",
       "      <td>0.016797</td>\n",
       "      <td>0.024735</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>85</td>\n",
       "      <td>{'C': 85}</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929193</td>\n",
       "      <td>0.010140</td>\n",
       "      <td>89</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.988354</td>\n",
       "      <td>0.986801</td>\n",
       "      <td>0.986801</td>\n",
       "      <td>0.988121</td>\n",
       "      <td>0.001141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.188496</td>\n",
       "      <td>0.014304</td>\n",
       "      <td>0.024740</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>86</td>\n",
       "      <td>{'C': 86}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>67</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.988742</td>\n",
       "      <td>0.986801</td>\n",
       "      <td>0.986801</td>\n",
       "      <td>0.988199</td>\n",
       "      <td>0.001167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.193070</td>\n",
       "      <td>0.025097</td>\n",
       "      <td>0.024542</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>87</td>\n",
       "      <td>{'C': 87}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>67</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.988742</td>\n",
       "      <td>0.986801</td>\n",
       "      <td>0.986801</td>\n",
       "      <td>0.988199</td>\n",
       "      <td>0.001167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.194872</td>\n",
       "      <td>0.015321</td>\n",
       "      <td>0.022945</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>88</td>\n",
       "      <td>{'C': 88}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>67</td>\n",
       "      <td>0.988742</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.988742</td>\n",
       "      <td>0.986801</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.988199</td>\n",
       "      <td>0.001030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.184899</td>\n",
       "      <td>0.016051</td>\n",
       "      <td>0.023338</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>89</td>\n",
       "      <td>{'C': 89}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>0.009572</td>\n",
       "      <td>58</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.988742</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.988354</td>\n",
       "      <td>0.000982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.188695</td>\n",
       "      <td>0.015837</td>\n",
       "      <td>0.023937</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>90</td>\n",
       "      <td>{'C': 90}</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>0.008947</td>\n",
       "      <td>58</td>\n",
       "      <td>0.988742</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.987578</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.988509</td>\n",
       "      <td>0.000970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.184898</td>\n",
       "      <td>0.013523</td>\n",
       "      <td>0.025332</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>91</td>\n",
       "      <td>{'C': 91}</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.008640</td>\n",
       "      <td>67</td>\n",
       "      <td>0.988742</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.989907</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.987578</td>\n",
       "      <td>0.988742</td>\n",
       "      <td>0.000885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.186489</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.023936</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>92</td>\n",
       "      <td>{'C': 92}</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929193</td>\n",
       "      <td>0.008075</td>\n",
       "      <td>89</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.989907</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.987578</td>\n",
       "      <td>0.988820</td>\n",
       "      <td>0.000899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.187889</td>\n",
       "      <td>0.016122</td>\n",
       "      <td>0.023743</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>93</td>\n",
       "      <td>{'C': 93}</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>93</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.989907</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.988898</td>\n",
       "      <td>0.000799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.195471</td>\n",
       "      <td>0.013228</td>\n",
       "      <td>0.022739</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>94</td>\n",
       "      <td>{'C': 94}</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>93</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.989907</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.988975</td>\n",
       "      <td>0.000836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.189280</td>\n",
       "      <td>0.013242</td>\n",
       "      <td>0.025532</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>95</td>\n",
       "      <td>{'C': 95}</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>93</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.989907</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.988975</td>\n",
       "      <td>0.000836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.205045</td>\n",
       "      <td>0.031637</td>\n",
       "      <td>0.023537</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>96</td>\n",
       "      <td>{'C': 96}</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.007918</td>\n",
       "      <td>96</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.989907</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.988975</td>\n",
       "      <td>0.000836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.261898</td>\n",
       "      <td>0.031536</td>\n",
       "      <td>0.027328</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>97</td>\n",
       "      <td>{'C': 97}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927640</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>99</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.989907</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.988975</td>\n",
       "      <td>0.000836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.224202</td>\n",
       "      <td>0.032420</td>\n",
       "      <td>0.025331</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>98</td>\n",
       "      <td>{'C': 98}</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928261</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>98</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.989907</td>\n",
       "      <td>0.988354</td>\n",
       "      <td>0.987966</td>\n",
       "      <td>0.989053</td>\n",
       "      <td>0.000753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.187099</td>\n",
       "      <td>0.016189</td>\n",
       "      <td>0.024335</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>99</td>\n",
       "      <td>{'C': 99}</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.008098</td>\n",
       "      <td>96</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.989907</td>\n",
       "      <td>0.988354</td>\n",
       "      <td>0.988354</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.000650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.242744      0.006867         0.035105        0.002130       1   \n",
       "1        0.220011      0.020658         0.031914        0.001411       2   \n",
       "2        0.170536      0.009827         0.031715        0.002985       3   \n",
       "3        0.195275      0.024790         0.031914        0.002274       4   \n",
       "4        0.196867      0.031455         0.028723        0.001829       5   \n",
       "5        0.171732      0.018526         0.030317        0.002646       6   \n",
       "6        0.162957      0.010367         0.028324        0.002570       7   \n",
       "7        0.163954      0.008665         0.029920        0.002092       8   \n",
       "8        0.167147      0.024088         0.029122        0.001163       9   \n",
       "9        0.208441      0.018007         0.027726        0.002986      10   \n",
       "10       0.189878      0.019578         0.028725        0.003054      11   \n",
       "11       0.171132      0.007817         0.029722        0.002780      12   \n",
       "12       0.205249      0.020704         0.029321        0.002239      13   \n",
       "13       0.214024      0.013452         0.028123        0.002705      14   \n",
       "14       0.206037      0.028242         0.029525        0.002560      15   \n",
       "15       0.164160      0.006899         0.028523        0.001740      16   \n",
       "16       0.161369      0.013191         0.027127        0.002309      17   \n",
       "17       0.162754      0.006475         0.025332        0.000489      18   \n",
       "18       0.169141      0.013701         0.026728        0.001162      19   \n",
       "19       0.207443      0.012504         0.028524        0.001742      20   \n",
       "20       0.210637      0.020366         0.028324        0.002793      21   \n",
       "21       0.172937      0.012434         0.028324        0.002054      22   \n",
       "22       0.169746      0.010914         0.026329        0.002492      23   \n",
       "23       0.165956      0.008775         0.028323        0.002569      24   \n",
       "24       0.182305      0.010780         0.026728        0.001934      25   \n",
       "25       0.166941      0.005361         0.027327        0.002410      26   \n",
       "26       0.182105      0.010660         0.027128        0.002035      27   \n",
       "27       0.174320      0.015870         0.026330        0.002327      28   \n",
       "28       0.177712      0.005548         0.027127        0.000399      29   \n",
       "29       0.169949      0.014009         0.027123        0.000981      30   \n",
       "..            ...           ...              ...             ...     ...   \n",
       "69       0.185503      0.016363         0.024135        0.001163      70   \n",
       "70       0.185697      0.013109         0.025133        0.002309      71   \n",
       "71       0.190489      0.018227         0.025133        0.000977      72   \n",
       "72       0.214820      0.032129         0.025333        0.001354      73   \n",
       "73       0.206052      0.026267         0.025328        0.001845      74   \n",
       "74       0.232179      0.026511         0.026530        0.001352      75   \n",
       "75       0.191488      0.015385         0.024534        0.001196      76   \n",
       "76       0.196873      0.027449         0.024135        0.001934      77   \n",
       "77       0.217219      0.039838         0.025334        0.002791      78   \n",
       "78       0.231580      0.027936         0.025133        0.002394      79   \n",
       "79       0.186901      0.013106         0.024533        0.001621      80   \n",
       "80       0.179514      0.016508         0.023936        0.002274      81   \n",
       "81       0.183497      0.013000         0.023936        0.001784      82   \n",
       "82       0.186488      0.011405         0.024336        0.001740      83   \n",
       "83       0.194872      0.006514         0.024933        0.001093      84   \n",
       "84       0.186095      0.016797         0.024735        0.000399      85   \n",
       "85       0.188496      0.014304         0.024740        0.001944      86   \n",
       "86       0.193070      0.025097         0.024542        0.002322      87   \n",
       "87       0.194872      0.015321         0.022945        0.001673      88   \n",
       "88       0.184899      0.016051         0.023338        0.001851      89   \n",
       "89       0.188695      0.015837         0.023937        0.001996      90   \n",
       "90       0.184898      0.013523         0.025332        0.001494      91   \n",
       "91       0.186489      0.014368         0.023936        0.000631      92   \n",
       "92       0.187889      0.016122         0.023743        0.000757      93   \n",
       "93       0.195471      0.013228         0.022739        0.000977      94   \n",
       "94       0.189280      0.013242         0.025532        0.001353      95   \n",
       "95       0.205045      0.031637         0.023537        0.001739      96   \n",
       "96       0.261898      0.031536         0.027328        0.003065      97   \n",
       "97       0.224202      0.032420         0.025331        0.001195      98   \n",
       "98       0.187099      0.016189         0.024335        0.000798      99   \n",
       "\n",
       "       params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0    {'C': 1}           0.917702           0.939441           0.919255   \n",
       "1    {'C': 2}           0.914596           0.945652           0.927019   \n",
       "2    {'C': 3}           0.914596           0.944099           0.925466   \n",
       "3    {'C': 4}           0.911491           0.945652           0.928571   \n",
       "4    {'C': 5}           0.909938           0.948758           0.931677   \n",
       "5    {'C': 6}           0.909938           0.948758           0.933230   \n",
       "6    {'C': 7}           0.909938           0.944099           0.934783   \n",
       "7    {'C': 8}           0.909938           0.944099           0.933230   \n",
       "8    {'C': 9}           0.909938           0.942547           0.933230   \n",
       "9   {'C': 10}           0.909938           0.944099           0.933230   \n",
       "10  {'C': 11}           0.906832           0.942547           0.931677   \n",
       "11  {'C': 12}           0.908385           0.940994           0.934783   \n",
       "12  {'C': 13}           0.906832           0.939441           0.934783   \n",
       "13  {'C': 14}           0.906832           0.939441           0.933230   \n",
       "14  {'C': 15}           0.909938           0.939441           0.933230   \n",
       "15  {'C': 16}           0.908385           0.939441           0.933230   \n",
       "16  {'C': 17}           0.909938           0.939441           0.933230   \n",
       "17  {'C': 18}           0.909938           0.939441           0.933230   \n",
       "18  {'C': 19}           0.909938           0.939441           0.936335   \n",
       "19  {'C': 20}           0.911491           0.939441           0.936335   \n",
       "20  {'C': 21}           0.913043           0.939441           0.936335   \n",
       "21  {'C': 22}           0.913043           0.939441           0.939441   \n",
       "22  {'C': 23}           0.913043           0.939441           0.939441   \n",
       "23  {'C': 24}           0.911491           0.937888           0.939441   \n",
       "24  {'C': 25}           0.909938           0.937888           0.939441   \n",
       "25  {'C': 26}           0.909938           0.936335           0.937888   \n",
       "26  {'C': 27}           0.911491           0.939441           0.936335   \n",
       "27  {'C': 28}           0.911491           0.937888           0.936335   \n",
       "28  {'C': 29}           0.911491           0.937888           0.936335   \n",
       "29  {'C': 30}           0.911491           0.939441           0.936335   \n",
       "..        ...                ...                ...                ...   \n",
       "69  {'C': 70}           0.908385           0.928571           0.942547   \n",
       "70  {'C': 71}           0.908385           0.928571           0.940994   \n",
       "71  {'C': 72}           0.908385           0.928571           0.940994   \n",
       "72  {'C': 73}           0.908385           0.928571           0.940994   \n",
       "73  {'C': 74}           0.908385           0.928571           0.940994   \n",
       "74  {'C': 75}           0.908385           0.928571           0.939441   \n",
       "75  {'C': 76}           0.908385           0.928571           0.937888   \n",
       "76  {'C': 77}           0.908385           0.928571           0.937888   \n",
       "77  {'C': 78}           0.909938           0.930124           0.937888   \n",
       "78  {'C': 79}           0.909938           0.928571           0.937888   \n",
       "79  {'C': 80}           0.909938           0.928571           0.937888   \n",
       "80  {'C': 81}           0.909938           0.928571           0.937888   \n",
       "81  {'C': 82}           0.911491           0.927019           0.937888   \n",
       "82  {'C': 83}           0.913043           0.927019           0.937888   \n",
       "83  {'C': 84}           0.913043           0.927019           0.937888   \n",
       "84  {'C': 85}           0.911491           0.925466           0.937888   \n",
       "85  {'C': 86}           0.913043           0.927019           0.937888   \n",
       "86  {'C': 87}           0.913043           0.927019           0.937888   \n",
       "87  {'C': 88}           0.913043           0.927019           0.937888   \n",
       "88  {'C': 89}           0.913043           0.927019           0.937888   \n",
       "89  {'C': 90}           0.914596           0.927019           0.937888   \n",
       "90  {'C': 91}           0.914596           0.927019           0.937888   \n",
       "91  {'C': 92}           0.914596           0.927019           0.936335   \n",
       "92  {'C': 93}           0.914596           0.925466           0.936335   \n",
       "93  {'C': 94}           0.914596           0.925466           0.936335   \n",
       "94  {'C': 95}           0.914596           0.925466           0.936335   \n",
       "95  {'C': 96}           0.914596           0.925466           0.936335   \n",
       "96  {'C': 97}           0.913043           0.923913           0.936335   \n",
       "97  {'C': 98}           0.914596           0.923913           0.936335   \n",
       "98  {'C': 99}           0.914596           0.925466           0.936335   \n",
       "\n",
       "    split3_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0            0.930124  ...         0.929814        0.010130               67   \n",
       "1            0.933230  ...         0.931988        0.010686               16   \n",
       "2            0.933230  ...         0.931366        0.010458               29   \n",
       "3            0.933230  ...         0.931677        0.011620               25   \n",
       "4            0.928571  ...         0.931677        0.012917               25   \n",
       "5            0.930124  ...         0.932609        0.013051                4   \n",
       "6            0.927019  ...         0.931366        0.012203               29   \n",
       "7            0.927019  ...         0.931056        0.012132               31   \n",
       "8            0.925466  ...         0.929814        0.011428               67   \n",
       "9            0.928571  ...         0.931056        0.011809               31   \n",
       "10           0.930124  ...         0.929814        0.012321               67   \n",
       "11           0.931677  ...         0.930745        0.011603               37   \n",
       "12           0.930124  ...         0.930124        0.012148               58   \n",
       "13           0.928571  ...         0.929193        0.011809               89   \n",
       "14           0.928571  ...         0.929503        0.010421               85   \n",
       "15           0.928571  ...         0.929814        0.011470               67   \n",
       "16           0.928571  ...         0.929503        0.010421               85   \n",
       "17           0.928571  ...         0.929503        0.010421               85   \n",
       "18           0.928571  ...         0.930124        0.010713               58   \n",
       "19           0.928571  ...         0.930124        0.009967               58   \n",
       "20           0.928571  ...         0.930435        0.009389               45   \n",
       "21           0.925466  ...         0.930435        0.010082               45   \n",
       "22           0.925466  ...         0.930124        0.009967               58   \n",
       "23           0.923913  ...         0.930124        0.010892               58   \n",
       "24           0.923913  ...         0.929814        0.011428               67   \n",
       "25           0.925466  ...         0.929503        0.010830               85   \n",
       "26           0.927019  ...         0.930435        0.010412               45   \n",
       "27           0.927019  ...         0.930435        0.010412               45   \n",
       "28           0.925466  ...         0.929814        0.010272               67   \n",
       "29           0.927019  ...         0.930435        0.010412               45   \n",
       "..                ...  ...              ...             ...              ...   \n",
       "69           0.931677  ...         0.930435        0.012242               45   \n",
       "70           0.931677  ...         0.930435        0.012242               45   \n",
       "71           0.931677  ...         0.930435        0.012242               45   \n",
       "72           0.931677  ...         0.930435        0.012242               45   \n",
       "73           0.931677  ...         0.930435        0.012242               45   \n",
       "74           0.931677  ...         0.930124        0.011988               58   \n",
       "75           0.931677  ...         0.929814        0.011760               67   \n",
       "76           0.930124  ...         0.929193        0.011394               89   \n",
       "77           0.930124  ...         0.929814        0.010821               67   \n",
       "78           0.931677  ...         0.929814        0.010865               67   \n",
       "79           0.933230  ...         0.929814        0.010641               67   \n",
       "80           0.933230  ...         0.929814        0.010641               67   \n",
       "81           0.933230  ...         0.929814        0.010130               67   \n",
       "82           0.931677  ...         0.929814        0.009491               67   \n",
       "83           0.931677  ...         0.929814        0.009491               67   \n",
       "84           0.931677  ...         0.929193        0.010140               89   \n",
       "85           0.931677  ...         0.929814        0.009491               67   \n",
       "86           0.931677  ...         0.929814        0.009491               67   \n",
       "87           0.931677  ...         0.929814        0.009491               67   \n",
       "88           0.933230  ...         0.930124        0.009572               58   \n",
       "89           0.931677  ...         0.930124        0.008947               58   \n",
       "90           0.931677  ...         0.929814        0.008640               67   \n",
       "91           0.931677  ...         0.929193        0.008075               89   \n",
       "92           0.931677  ...         0.928882        0.008181               93   \n",
       "93           0.931677  ...         0.928882        0.008181               93   \n",
       "94           0.931677  ...         0.928882        0.008181               93   \n",
       "95           0.931677  ...         0.928571        0.007918               96   \n",
       "96           0.930124  ...         0.927640        0.008482               99   \n",
       "97           0.930124  ...         0.928261        0.008240               98   \n",
       "98           0.930124  ...         0.928571        0.008098               96   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0             0.951863            0.945652            0.950699   \n",
       "1             0.959239            0.954193            0.959239   \n",
       "2             0.962345            0.959627            0.964286   \n",
       "3             0.964286            0.964286            0.967391   \n",
       "4             0.966615            0.967391            0.968168   \n",
       "5             0.969332            0.967780            0.969332   \n",
       "6             0.971661            0.968168            0.970885   \n",
       "7             0.972438            0.969332            0.971661   \n",
       "8             0.972438            0.969720            0.972826   \n",
       "9             0.973991            0.970497            0.973602   \n",
       "10            0.977484            0.971273            0.973602   \n",
       "11            0.976708            0.972050            0.973991   \n",
       "12            0.976708            0.972826            0.973602   \n",
       "13            0.977873            0.972826            0.974379   \n",
       "14            0.977873            0.972438            0.974767   \n",
       "15            0.978261            0.972826            0.976708   \n",
       "16            0.977873            0.974767            0.977096   \n",
       "17            0.979037            0.975543            0.977096   \n",
       "18            0.979425            0.976708            0.978261   \n",
       "19            0.979037            0.977096            0.979425   \n",
       "20            0.979425            0.977096            0.979425   \n",
       "21            0.979425            0.977484            0.979814   \n",
       "22            0.979814            0.977873            0.979425   \n",
       "23            0.980202            0.978261            0.979425   \n",
       "24            0.980590            0.978261            0.980978   \n",
       "25            0.980978            0.978261            0.980978   \n",
       "26            0.981366            0.978649            0.981366   \n",
       "27            0.981366            0.978649            0.980978   \n",
       "28            0.982143            0.978649            0.980978   \n",
       "29            0.982143            0.979037            0.982531   \n",
       "..                 ...                 ...                 ...   \n",
       "69            0.987578            0.987966            0.987189   \n",
       "70            0.987578            0.987966            0.987189   \n",
       "71            0.987966            0.987966            0.987189   \n",
       "72            0.987966            0.987966            0.987189   \n",
       "73            0.988354            0.988354            0.987189   \n",
       "74            0.988354            0.988742            0.987189   \n",
       "75            0.988354            0.988742            0.987189   \n",
       "76            0.988742            0.989130            0.987578   \n",
       "77            0.988742            0.989130            0.987578   \n",
       "78            0.989130            0.989130            0.987578   \n",
       "79            0.989130            0.989130            0.987578   \n",
       "80            0.989130            0.989130            0.987578   \n",
       "81            0.989130            0.989519            0.987578   \n",
       "82            0.989130            0.989519            0.987578   \n",
       "83            0.989130            0.989519            0.988354   \n",
       "84            0.989130            0.989519            0.988354   \n",
       "85            0.989130            0.989519            0.988742   \n",
       "86            0.989130            0.989519            0.988742   \n",
       "87            0.988742            0.989519            0.988742   \n",
       "88            0.989130            0.989519            0.988742   \n",
       "89            0.988742            0.989519            0.989519   \n",
       "90            0.988742            0.989519            0.989907   \n",
       "91            0.989130            0.989519            0.989907   \n",
       "92            0.989130            0.989519            0.989907   \n",
       "93            0.989519            0.989519            0.989907   \n",
       "94            0.989519            0.989519            0.989907   \n",
       "95            0.989519            0.989519            0.989907   \n",
       "96            0.989519            0.989519            0.989907   \n",
       "97            0.989519            0.989519            0.989907   \n",
       "98            0.989519            0.989519            0.989907   \n",
       "\n",
       "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0             0.946040            0.943711          0.947593         0.003135  \n",
       "1             0.956910            0.952640          0.956444         0.002660  \n",
       "2             0.960016            0.956910          0.960637         0.002511  \n",
       "3             0.962345            0.960792          0.963820         0.002215  \n",
       "4             0.963509            0.962733          0.965683         0.002163  \n",
       "5             0.964286            0.965450          0.967236         0.002048  \n",
       "6             0.965450            0.967391          0.968711         0.002285  \n",
       "7             0.965450            0.969720          0.969720         0.002431  \n",
       "8             0.967780            0.970497          0.970652         0.001847  \n",
       "9             0.968944            0.970885          0.971584         0.001924  \n",
       "10            0.968556            0.971661          0.972516         0.002961  \n",
       "11            0.970109            0.972438          0.973059         0.002204  \n",
       "12            0.971273            0.972438          0.973370         0.001831  \n",
       "13            0.971273            0.973991          0.974068         0.002188  \n",
       "14            0.971661            0.973991          0.974146         0.002163  \n",
       "15            0.972826            0.974767          0.975078         0.002146  \n",
       "16            0.973991            0.975155          0.975776         0.001465  \n",
       "17            0.975155            0.975932          0.976553         0.001402  \n",
       "18            0.975543            0.976708          0.977329         0.001358  \n",
       "19            0.975543            0.976708          0.977562         0.001461  \n",
       "20            0.976708            0.977484          0.978028         0.001167  \n",
       "21            0.977096            0.978261          0.978416         0.001059  \n",
       "22            0.977096            0.979037          0.978649         0.001012  \n",
       "23            0.977096            0.980202          0.979037         0.001203  \n",
       "24            0.977096            0.980202          0.979425         0.001493  \n",
       "25            0.977484            0.980590          0.979658         0.001485  \n",
       "26            0.977484            0.980590          0.979891         0.001561  \n",
       "27            0.978649            0.980590          0.980047         0.001167  \n",
       "28            0.979425            0.980978          0.980435         0.001242  \n",
       "29            0.979814            0.981366          0.980978         0.001345  \n",
       "..                 ...                 ...               ...              ...  \n",
       "69            0.986413            0.986801          0.987189         0.000549  \n",
       "70            0.986413            0.986801          0.987189         0.000549  \n",
       "71            0.986413            0.987189          0.987345         0.000581  \n",
       "72            0.986413            0.987189          0.987345         0.000581  \n",
       "73            0.986413            0.987189          0.987500         0.000753  \n",
       "74            0.986413            0.987189          0.987578         0.000851  \n",
       "75            0.986413            0.987189          0.987578         0.000851  \n",
       "76            0.986413            0.987189          0.987811         0.001000  \n",
       "77            0.986413            0.987189          0.987811         0.001000  \n",
       "78            0.986413            0.987189          0.987888         0.001081  \n",
       "79            0.986413            0.987189          0.987888         0.001081  \n",
       "80            0.986413            0.986801          0.987811         0.001141  \n",
       "81            0.986801            0.986801          0.987966         0.001152  \n",
       "82            0.986801            0.986801          0.987966         0.001152  \n",
       "83            0.986801            0.986801          0.988121         0.001141  \n",
       "84            0.986801            0.986801          0.988121         0.001141  \n",
       "85            0.986801            0.986801          0.988199         0.001167  \n",
       "86            0.986801            0.986801          0.988199         0.001167  \n",
       "87            0.986801            0.987189          0.988199         0.001030  \n",
       "88            0.987189            0.987189          0.988354         0.000982  \n",
       "89            0.987578            0.987189          0.988509         0.000970  \n",
       "90            0.987966            0.987578          0.988742         0.000885  \n",
       "91            0.987966            0.987578          0.988820         0.000899  \n",
       "92            0.987966            0.987966          0.988898         0.000799  \n",
       "93            0.987966            0.987966          0.988975         0.000836  \n",
       "94            0.987966            0.987966          0.988975         0.000836  \n",
       "95            0.987966            0.987966          0.988975         0.000836  \n",
       "96            0.987966            0.987966          0.988975         0.000836  \n",
       "97            0.988354            0.987966          0.989053         0.000753  \n",
       "98            0.988354            0.988354          0.989130         0.000650  \n",
       "\n",
       "[99 rows x 21 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results of grid search CV\n",
    "cv_results1= pd.DataFrame(model_cv1.cv_results_)\n",
    "cv_results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of C versus train and test scores\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(cv_results1['param_C'], cv_results1['mean_test_score'])\n",
    "plt.plot(cv_results1['param_C'], cv_results1['mean_train_score'])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The highest test accuracy is 0.9329192546583851 at C = 43\n"
     ]
    }
   ],
   "source": [
    "best_score1 = model_cv1.best_score_\n",
    "best_C1 = model_cv1.best_params_['C']\n",
    "\n",
    "print(\" The highest test accuracy is {0} at C = {1}\".format(best_score1, best_C1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the metrics corresponding to C=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with the best value of C\n",
    "model = SVC(C=best_C)\n",
    "\n",
    "# fit\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9304851556842868\n",
      "precision 0.9241245136186771\n",
      "recall 0.8928571428571429\n"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "# print other metrics\n",
    "\n",
    "# accuracy\n",
    "print(\"accuracy\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# precision\n",
    "print(\"precision\", metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# recall/sensitivity\n",
    "print(\"recall\", metrics.recall_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For C = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with the best value of C\n",
    "model1 = SVC(C=best_C1)\n",
    "\n",
    "# fit\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9217958001448225\n",
      "precision 0.9140625\n",
      "recall 0.8796992481203008\n"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "# print other metrics\n",
    "\n",
    "# accuracy\n",
    "print(\"accuracy\", metrics.accuracy_score(y_test, y_pred1))\n",
    "\n",
    "# precision\n",
    "print(\"precision\", metrics.precision_score(y_test, y_pred1))\n",
    "\n",
    "# recall/sensitivity\n",
    "print(\"recall\", metrics.recall_score(y_test, y_pred1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimising for Other Evaluation Metrics\n",
    "\n",
    "In this case, we had optimised (tuned) the model based on overall accuracy, though that may not always be the best metric to optimise. For example, if you are concerned more about catching all spams (positives), you may want to maximise TPR or sensitivity/recall. If, on the other hand, you want to avoid classifying hams as spams (so that any important mails don't get into the spam box), you would maximise the TNR or specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      " The highest accuracy score is 0.931055900621118 at C = {'C': 10}\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      " The highest precision score is 0.936509856470386 at C = {'C': 0.1}\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      " The highest recall score is 0.8994650196111064 at C = {'C': 10}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# specify params\n",
    "params = {\"C\": [0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "# specify scores/metrics in an iterable\n",
    "scores = ['accuracy', 'precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for {}\".format(score))\n",
    "    \n",
    "    # set up GridSearch for score metric\n",
    "    clf = GridSearchCV(SVC(), \n",
    "                       params, \n",
    "                       cv=folds,\n",
    "                       scoring=score,\n",
    "                       return_train_score=True)\n",
    "    # fit\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\" The highest {0} score is {1} at C = {2}\".format(score, clf.best_score_, clf.best_params_))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for recall\n",
      " The highest accuracy score is 0.9026685183998959 at C = {'C': 45}\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      " The highest precision score is 0.9026685183998959 at C = {'C': 45}\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      " The highest recall score is 0.9026685183998959 at C = {'C': 45}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# specify params\n",
    "params1 = {\"C\": [i for i in range(1,101)]}\n",
    "\n",
    "# specify scores/metrics in an iterable\n",
    "scores = ['accuracy', 'precision', 'recall']\n",
    "\n",
    "for score1 in scores:\n",
    "    print(\"# Tuning hyper-parameters for {}\".format(score))\n",
    "    \n",
    "    # set up GridSearch for score metric\n",
    "    clf1 = GridSearchCV(SVC(), \n",
    "                       params1, \n",
    "                       cv=folds,\n",
    "                       scoring=score,\n",
    "                       return_train_score=True)\n",
    "    # fit\n",
    "    clf1.fit(X_train, y_train)\n",
    "\n",
    "    print(\" The highest {0} score is {1} at C = {2}\".format(score1, clf1.best_score_, clf1.best_params_))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, you can see that the optimal value of the hyperparameter varies significantly with the choice of evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE STUDY 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear SVM - Email Spam Classifier\n",
    "\n",
    "\n",
    "In this section, we'll build a non-linear SVM classifier to classify emails and compare the performance with the linear SVM model.\n",
    "\n",
    "The dataset can be downloaded here: https://archive.ics.uci.edu/ml/datasets/spambase\n",
    "\n",
    "To reiterate, the performance of the linear model was as follows:\n",
    "- accuracy 0.93\n",
    "- precision 0.92\n",
    "- recall 0.89"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will build a non-linear model (using non-linear kernels) and then find the optimal hyperparameters (the choice of kernel, C, gamma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_rec2 = pd.read_csv(\"Datasets/Spam.txt\",  sep = ',', header= None )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Renaming the column names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
      "0            0.00               0.64           0.64           0.0   \n",
      "1            0.21               0.28           0.50           0.0   \n",
      "2            0.06               0.00           0.71           0.0   \n",
      "3            0.00               0.00           0.00           0.0   \n",
      "4            0.00               0.00           0.00           0.0   \n",
      "\n",
      "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
      "0           0.32            0.00              0.00                0.00   \n",
      "1           0.14            0.28              0.21                0.07   \n",
      "2           1.23            0.19              0.19                0.12   \n",
      "3           0.63            0.00              0.31                0.63   \n",
      "4           0.63            0.00              0.31                0.63   \n",
      "\n",
      "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
      "0             0.00            0.00  ...         0.00        0.000   \n",
      "1             0.00            0.94  ...         0.00        0.132   \n",
      "2             0.64            0.25  ...         0.01        0.143   \n",
      "3             0.31            0.63  ...         0.00        0.137   \n",
      "4             0.31            0.63  ...         0.00        0.135   \n",
      "\n",
      "   char_freq_[  char_freq_!  char_freq_$  char_freq_hash  \\\n",
      "0          0.0        0.778        0.000           0.000   \n",
      "1          0.0        0.372        0.180           0.048   \n",
      "2          0.0        0.276        0.184           0.010   \n",
      "3          0.0        0.137        0.000           0.000   \n",
      "4          0.0        0.135        0.000           0.000   \n",
      "\n",
      "   capital_run_length_average  capital_run_length_longest  \\\n",
      "0                       3.756                          61   \n",
      "1                       5.114                         101   \n",
      "2                       9.821                         485   \n",
      "3                       3.537                          40   \n",
      "4                       3.537                          40   \n",
      "\n",
      "   capital_run_length_total  spam  \n",
      "0                       278     1  \n",
      "1                      1028     1  \n",
      "2                      2259     1  \n",
      "3                       191     1  \n",
      "4                       191     1  \n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# renaming the columns\n",
    "email_rec2.columns  = [\"word_freq_make\", \"word_freq_address\", \"word_freq_all\", \"word_freq_3d\", \n",
    "                      \"word_freq_our\", \"word_freq_over\", \"word_freq_remove\", \"word_freq_internet\", \n",
    "                      \"word_freq_order\", \"word_freq_mail\", \"word_freq_receive\", \"word_freq_will\", \n",
    "                      \"word_freq_people\", \"word_freq_report\", \"word_freq_addresses\", \"word_freq_free\", \n",
    "                      \"word_freq_business\", \"word_freq_email\", \"word_freq_you\", \"word_freq_credit\", \n",
    "                      \"word_freq_your\", \"word_freq_font\", \"word_freq_000\", \"word_freq_money\", \"word_freq_hp\", \n",
    "                      \"word_freq_hpl\", \"word_freq_george\", \"word_freq_650\", \"word_freq_lab\", \"word_freq_labs\", \n",
    "                      \"word_freq_telnet\", \"word_freq_857\", \"word_freq_data\", \"word_freq_415\", \"word_freq_85\", \n",
    "                      \"word_freq_technology\", \"word_freq_1999\", \"word_freq_parts\", \"word_freq_pm\", \"word_freq_direct\",\n",
    "                      \"word_freq_cs\", \"word_freq_meeting\", \"word_freq_original\", \"word_freq_project\", \"word_freq_re\", \n",
    "                      \"word_freq_edu\", \"word_freq_table\", \"word_freq_conference\", \"char_freq_;\", \"char_freq_(\", \n",
    "                      \"char_freq_[\", \"char_freq_!\", \"char_freq_$\", \"char_freq_hash\", \"capital_run_length_average\", \n",
    "                      \"capital_run_length_longest\", \"capital_run_length_total\", \"spam\"]\n",
    "print(email_rec2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into X and y\n",
    "X = email_rec2.drop(\"spam\", axis = 1)\n",
    "y = email_rec2.spam.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the features\n",
    "X_scaled = scale(X)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using rbf kernel, C=1, default value of gamma\n",
    "\n",
    "model3 = SVC(C = 1, kernel='rbf')\n",
    "model3.fit(X_train, y_train)\n",
    "y_pred3 = model3.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[811,  38],\n",
       "       [ 61, 471]], dtype=int64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix(y_true=y_test, y_pred=y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9283128167994207\n",
      "precision 0.925343811394892\n",
      "recall 0.8853383458646616\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "print(\"accuracy\", metrics.accuracy_score(y_test, y_pred3))\n",
    "\n",
    "# precision\n",
    "print(\"precision\", metrics.precision_score(y_test, y_pred3))\n",
    "\n",
    "# recall/sensitivity\n",
    "print(\"recall\", metrics.recall_score(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning \n",
    "\n",
    "Now, we have multiple hyperparameters to optimise - \n",
    "- The choice of kernel (linear, rbf etc.)\n",
    "- C\n",
    "- gamma\n",
    "\n",
    "We'll use the ```GridSearchCV()``` method to tune the hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search to Find Optimal Hyperparameters\n",
    "\n",
    "Let's first use the RBF kernel to find the optimal C and gamma (we can consider the kernel as a hyperparameter as well, though training the model will take an exorbitant amount of time). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   20.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=4, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'gamma': [0.01, 0.001, 0.0001], 'C': [1, 10, 100, 1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 4)\n",
    "\n",
    "# specify range of hyperparameters\n",
    "# Set the parameters by cross-validation\n",
    "hyper_params2 = [ {'gamma': [1e-2, 1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "\n",
    "# specify model\n",
    "model3 = SVC(kernel=\"rbf\")\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv3 = GridSearchCV(estimator = model3, \n",
    "                        param_grid = hyper_params2, \n",
    "                        scoring= 'accuracy', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv3.fit(X_train, y_train)                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.161764</td>\n",
       "      <td>0.012859</td>\n",
       "      <td>0.029911</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.917702</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.922360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>5</td>\n",
       "      <td>0.943323</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.945264</td>\n",
       "      <td>0.937112</td>\n",
       "      <td>0.939829</td>\n",
       "      <td>0.941304</td>\n",
       "      <td>0.002814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.214621</td>\n",
       "      <td>0.004288</td>\n",
       "      <td>0.044281</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001}</td>\n",
       "      <td>0.886646</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.899068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.904037</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>10</td>\n",
       "      <td>0.910326</td>\n",
       "      <td>0.903339</td>\n",
       "      <td>0.908773</td>\n",
       "      <td>0.906056</td>\n",
       "      <td>0.904115</td>\n",
       "      <td>0.906522</td>\n",
       "      <td>0.002672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.353061</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.073017</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.0001}</td>\n",
       "      <td>0.770186</td>\n",
       "      <td>0.802795</td>\n",
       "      <td>0.791925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786025</td>\n",
       "      <td>0.015322</td>\n",
       "      <td>12</td>\n",
       "      <td>0.789208</td>\n",
       "      <td>0.779503</td>\n",
       "      <td>0.785326</td>\n",
       "      <td>0.791925</td>\n",
       "      <td>0.788820</td>\n",
       "      <td>0.786957</td>\n",
       "      <td>0.004277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.142673</td>\n",
       "      <td>0.016584</td>\n",
       "      <td>0.022736</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.012266</td>\n",
       "      <td>3</td>\n",
       "      <td>0.966227</td>\n",
       "      <td>0.966615</td>\n",
       "      <td>0.967003</td>\n",
       "      <td>0.961568</td>\n",
       "      <td>0.962345</td>\n",
       "      <td>0.964752</td>\n",
       "      <td>0.002308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.147678</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.026830</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>0.917702</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.916149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928261</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>7</td>\n",
       "      <td>0.937112</td>\n",
       "      <td>0.932453</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.935171</td>\n",
       "      <td>0.931289</td>\n",
       "      <td>0.934472</td>\n",
       "      <td>0.002242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.216125</td>\n",
       "      <td>0.007608</td>\n",
       "      <td>0.044482</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001}</td>\n",
       "      <td>0.883540</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>0.899068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.013749</td>\n",
       "      <td>11</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.908773</td>\n",
       "      <td>0.905280</td>\n",
       "      <td>0.902562</td>\n",
       "      <td>0.905745</td>\n",
       "      <td>0.003158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.158987</td>\n",
       "      <td>0.012783</td>\n",
       "      <td>0.020741</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>0.010159</td>\n",
       "      <td>4</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.979814</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.981910</td>\n",
       "      <td>0.001059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>0.022540</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001}</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933851</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>1</td>\n",
       "      <td>0.950311</td>\n",
       "      <td>0.949534</td>\n",
       "      <td>0.948758</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.939829</td>\n",
       "      <td>0.946817</td>\n",
       "      <td>0.003835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.159766</td>\n",
       "      <td>0.011812</td>\n",
       "      <td>0.028922</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.0001}</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.917702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>8</td>\n",
       "      <td>0.934006</td>\n",
       "      <td>0.931289</td>\n",
       "      <td>0.934006</td>\n",
       "      <td>0.930901</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.931910</td>\n",
       "      <td>0.001831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.223795</td>\n",
       "      <td>0.015395</td>\n",
       "      <td>0.018357</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.01}</td>\n",
       "      <td>0.908385</td>\n",
       "      <td>0.922360</td>\n",
       "      <td>0.920807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918323</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>9</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.992624</td>\n",
       "      <td>0.992624</td>\n",
       "      <td>0.993012</td>\n",
       "      <td>0.992236</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>0.000527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.223386</td>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.018750</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.001}</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933851</td>\n",
       "      <td>0.009033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966615</td>\n",
       "      <td>0.966227</td>\n",
       "      <td>0.966615</td>\n",
       "      <td>0.963121</td>\n",
       "      <td>0.966227</td>\n",
       "      <td>0.965761</td>\n",
       "      <td>0.001331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.156992</td>\n",
       "      <td>0.018021</td>\n",
       "      <td>0.022145</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.0001}</td>\n",
       "      <td>0.920807</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929193</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>6</td>\n",
       "      <td>0.940606</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.937112</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.001753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.161764      0.012859         0.029911        0.000631       1   \n",
       "1        0.214621      0.004288         0.044281        0.001017       1   \n",
       "2        0.353061      0.003748         0.073017        0.001157       1   \n",
       "3        0.142673      0.016584         0.022736        0.001466      10   \n",
       "4        0.147678      0.003944         0.026830        0.000407      10   \n",
       "5        0.216125      0.007608         0.044482        0.000798      10   \n",
       "6        0.158987      0.012783         0.020741        0.001943     100   \n",
       "7        0.154386      0.010015         0.022540        0.001616     100   \n",
       "8        0.159766      0.011812         0.028922        0.002523     100   \n",
       "9        0.223795      0.015395         0.018357        0.000803    1000   \n",
       "10       0.223386      0.013350         0.018750        0.000977    1000   \n",
       "11       0.156992      0.018021         0.022145        0.001321    1000   \n",
       "\n",
       "   param_gamma                        params  split0_test_score  \\\n",
       "0         0.01       {'C': 1, 'gamma': 0.01}           0.917702   \n",
       "1        0.001      {'C': 1, 'gamma': 0.001}           0.886646   \n",
       "2       0.0001     {'C': 1, 'gamma': 0.0001}           0.770186   \n",
       "3         0.01      {'C': 10, 'gamma': 0.01}           0.909938   \n",
       "4        0.001     {'C': 10, 'gamma': 0.001}           0.917702   \n",
       "5       0.0001    {'C': 10, 'gamma': 0.0001}           0.883540   \n",
       "6         0.01     {'C': 100, 'gamma': 0.01}           0.913043   \n",
       "7        0.001    {'C': 100, 'gamma': 0.001}           0.923913   \n",
       "8       0.0001   {'C': 100, 'gamma': 0.0001}           0.919255   \n",
       "9         0.01    {'C': 1000, 'gamma': 0.01}           0.908385   \n",
       "10       0.001   {'C': 1000, 'gamma': 0.001}           0.919255   \n",
       "11      0.0001  {'C': 1000, 'gamma': 0.0001}           0.920807   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  mean_test_score  \\\n",
       "0            0.939441           0.922360  ...         0.929814   \n",
       "1            0.919255           0.899068  ...         0.904037   \n",
       "2            0.802795           0.791925  ...         0.786025   \n",
       "3            0.944099           0.934783  ...         0.933230   \n",
       "4            0.934783           0.916149  ...         0.928261   \n",
       "5            0.914596           0.899068  ...         0.902174   \n",
       "6            0.937888           0.934783  ...         0.931677   \n",
       "7            0.940994           0.925466  ...         0.933851   \n",
       "8            0.934783           0.917702  ...         0.927019   \n",
       "9            0.922360           0.920807  ...         0.918323   \n",
       "10           0.944099           0.930124  ...         0.933851   \n",
       "11           0.936335           0.925466  ...         0.929193   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.008528                5            0.943323            0.940994   \n",
       "1         0.013080               10            0.910326            0.903339   \n",
       "2         0.015322               12            0.789208            0.779503   \n",
       "3         0.012266                3            0.966227            0.966615   \n",
       "4         0.009491                7            0.937112            0.932453   \n",
       "5         0.013749               11            0.909938            0.902174   \n",
       "6         0.010159                4            0.982531            0.979814   \n",
       "7         0.008482                1            0.950311            0.949534   \n",
       "8         0.007349                8            0.934006            0.931289   \n",
       "9         0.005607                9            0.993789            0.992624   \n",
       "10        0.009033                1            0.966615            0.966227   \n",
       "11        0.005777                6            0.940606            0.940994   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             0.945264            0.937112            0.939829   \n",
       "1             0.908773            0.906056            0.904115   \n",
       "2             0.785326            0.791925            0.788820   \n",
       "3             0.967003            0.961568            0.962345   \n",
       "4             0.936335            0.935171            0.931289   \n",
       "5             0.908773            0.905280            0.902562   \n",
       "6             0.982531            0.982143            0.982531   \n",
       "7             0.948758            0.945652            0.939829   \n",
       "8             0.934006            0.930901            0.929348   \n",
       "9             0.992624            0.993012            0.992236   \n",
       "10            0.966615            0.963121            0.966227   \n",
       "11            0.940994            0.937112            0.937500   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.941304         0.002814  \n",
       "1           0.906522         0.002672  \n",
       "2           0.786957         0.004277  \n",
       "3           0.964752         0.002308  \n",
       "4           0.934472         0.002242  \n",
       "5           0.905745         0.003158  \n",
       "6           0.981910         0.001059  \n",
       "7           0.946817         0.003835  \n",
       "8           0.931910         0.001831  \n",
       "9           0.992857         0.000527  \n",
       "10          0.965761         0.001331  \n",
       "11          0.939441         0.001753  \n",
       "\n",
       "[12 rows x 22 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv results\n",
    "cv_results3 = pd.DataFrame(model_cv3.cv_results_)\n",
    "cv_results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# converting C to numeric type for plotting on x-axis\n",
    "cv_results3['param_C'] = cv_results3['param_C'].astype('int')\n",
    "\n",
    "# # plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "# subplot 1/3\n",
    "plt.subplot(131)\n",
    "gamma_01 = cv_results3[cv_results3['param_gamma']==0.01]\n",
    "\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.01\")\n",
    "plt.ylim([0.80, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n",
    "# subplot 2/3\n",
    "plt.subplot(132)\n",
    "gamma_001 = cv_results3[cv_results3['param_gamma']==0.001]\n",
    "\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.001\")\n",
    "plt.ylim([0.80, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "# subplot 3/3\n",
    "plt.subplot(133)\n",
    "gamma_0001 = cv_results3[cv_results3['param_gamma']==0.0001]\n",
    "\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.0001\")\n",
    "plt.ylim([0.80, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot reveals some interesting insights:\n",
    "- **High values of gamma** lead to **overfitting** (especially at high values of C); note that the training accuracy at gamma=0.01 and C=1000 reaches almost 99% \n",
    "- The **training score increases with higher gamma**, though the **test scores are comparable** (at sufficiently high cost, i.e. C > 10)\n",
    "- The least amount of overfitting (i.e. difference between train and test accuracy) occurs at low gamma, i.e. a quite *simple non-linear model*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best test score is 0.9338509316770186 corresponding to hyperparameters {'C': 100, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "best_score = model_cv3.best_score_\n",
    "best_hyperparams = model_cv3.best_params_\n",
    "\n",
    "print(\"The best test score is {0} corresponding to hyperparameters {1}\".format(best_score, best_hyperparams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the same for continuous values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1500 out of 1500 | elapsed:  7.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=4, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'gamma': [0.01, 0.001, 0.0001], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 4)\n",
    "\n",
    "# specify range of hyperparameters\n",
    "# Set the parameters by cross-validation\n",
    "hyper_params3 = [ {'gamma': [1e-2, 1e-3, 1e-4],\n",
    "                     'C': [i for i in range(1,101)]}]\n",
    "\n",
    "\n",
    "# specify model\n",
    "model4 = SVC(kernel=\"rbf\")\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv4 = GridSearchCV(estimator = model4, \n",
    "                        param_grid = hyper_params3, \n",
    "                        scoring= 'accuracy', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv4.fit(X_train, y_train)                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.156591</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>0.030116</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.917702</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.922360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>186</td>\n",
       "      <td>0.943323</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.945264</td>\n",
       "      <td>0.937112</td>\n",
       "      <td>0.939829</td>\n",
       "      <td>0.941304</td>\n",
       "      <td>0.002814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.240164</td>\n",
       "      <td>0.023825</td>\n",
       "      <td>0.045873</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001}</td>\n",
       "      <td>0.886646</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.899068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.904037</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>289</td>\n",
       "      <td>0.910326</td>\n",
       "      <td>0.903339</td>\n",
       "      <td>0.908773</td>\n",
       "      <td>0.906056</td>\n",
       "      <td>0.904115</td>\n",
       "      <td>0.906522</td>\n",
       "      <td>0.002672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.365413</td>\n",
       "      <td>0.022941</td>\n",
       "      <td>0.074602</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.0001}</td>\n",
       "      <td>0.770186</td>\n",
       "      <td>0.802795</td>\n",
       "      <td>0.791925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786025</td>\n",
       "      <td>0.015322</td>\n",
       "      <td>300</td>\n",
       "      <td>0.789208</td>\n",
       "      <td>0.779503</td>\n",
       "      <td>0.785326</td>\n",
       "      <td>0.791925</td>\n",
       "      <td>0.788820</td>\n",
       "      <td>0.786957</td>\n",
       "      <td>0.004277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.170348</td>\n",
       "      <td>0.016048</td>\n",
       "      <td>0.029918</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 2, 'gamma': 0.01}</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934161</td>\n",
       "      <td>0.010044</td>\n",
       "      <td>1</td>\n",
       "      <td>0.949534</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.949922</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.943323</td>\n",
       "      <td>0.947127</td>\n",
       "      <td>0.002411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.224018</td>\n",
       "      <td>0.028661</td>\n",
       "      <td>0.038883</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 2, 'gamma': 0.001}</td>\n",
       "      <td>0.899068</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.905280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912112</td>\n",
       "      <td>0.011137</td>\n",
       "      <td>279</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.914984</td>\n",
       "      <td>0.918866</td>\n",
       "      <td>0.915761</td>\n",
       "      <td>0.916537</td>\n",
       "      <td>0.917081</td>\n",
       "      <td>0.001694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.315155</td>\n",
       "      <td>0.017102</td>\n",
       "      <td>0.064822</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 2, 'gamma': 0.0001}</td>\n",
       "      <td>0.830745</td>\n",
       "      <td>0.854037</td>\n",
       "      <td>0.844720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844410</td>\n",
       "      <td>0.011637</td>\n",
       "      <td>299</td>\n",
       "      <td>0.846661</td>\n",
       "      <td>0.844332</td>\n",
       "      <td>0.845497</td>\n",
       "      <td>0.850932</td>\n",
       "      <td>0.843944</td>\n",
       "      <td>0.846273</td>\n",
       "      <td>0.002516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.157983</td>\n",
       "      <td>0.010788</td>\n",
       "      <td>0.027323</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 3, 'gamma': 0.01}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932609</td>\n",
       "      <td>0.011309</td>\n",
       "      <td>64</td>\n",
       "      <td>0.952640</td>\n",
       "      <td>0.950311</td>\n",
       "      <td>0.954581</td>\n",
       "      <td>0.952252</td>\n",
       "      <td>0.947593</td>\n",
       "      <td>0.951475</td>\n",
       "      <td>0.002368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>0.035505</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 3, 'gamma': 0.001}</td>\n",
       "      <td>0.903727</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918634</td>\n",
       "      <td>0.010874</td>\n",
       "      <td>265</td>\n",
       "      <td>0.928960</td>\n",
       "      <td>0.921972</td>\n",
       "      <td>0.924689</td>\n",
       "      <td>0.921972</td>\n",
       "      <td>0.921584</td>\n",
       "      <td>0.923835</td>\n",
       "      <td>0.002793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.284447</td>\n",
       "      <td>0.016197</td>\n",
       "      <td>0.057851</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 3, 'gamma': 0.0001}</td>\n",
       "      <td>0.840062</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.860248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858075</td>\n",
       "      <td>0.013125</td>\n",
       "      <td>298</td>\n",
       "      <td>0.863742</td>\n",
       "      <td>0.860248</td>\n",
       "      <td>0.860248</td>\n",
       "      <td>0.865295</td>\n",
       "      <td>0.858696</td>\n",
       "      <td>0.861646</td>\n",
       "      <td>0.002463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.134431</td>\n",
       "      <td>0.006005</td>\n",
       "      <td>0.025119</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 4, 'gamma': 0.01}</td>\n",
       "      <td>0.916149</td>\n",
       "      <td>0.942547</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.009572</td>\n",
       "      <td>41</td>\n",
       "      <td>0.957298</td>\n",
       "      <td>0.953416</td>\n",
       "      <td>0.956134</td>\n",
       "      <td>0.953804</td>\n",
       "      <td>0.949922</td>\n",
       "      <td>0.954115</td>\n",
       "      <td>0.002544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.172339</td>\n",
       "      <td>0.012988</td>\n",
       "      <td>0.033506</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 4, 'gamma': 0.001}</td>\n",
       "      <td>0.906832</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.916149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922671</td>\n",
       "      <td>0.010504</td>\n",
       "      <td>252</td>\n",
       "      <td>0.931289</td>\n",
       "      <td>0.925078</td>\n",
       "      <td>0.927407</td>\n",
       "      <td>0.924689</td>\n",
       "      <td>0.926242</td>\n",
       "      <td>0.926941</td>\n",
       "      <td>0.002373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.254123</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.053646</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 4, 'gamma': 0.0001}</td>\n",
       "      <td>0.852484</td>\n",
       "      <td>0.881988</td>\n",
       "      <td>0.866460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870497</td>\n",
       "      <td>0.014913</td>\n",
       "      <td>297</td>\n",
       "      <td>0.874224</td>\n",
       "      <td>0.872283</td>\n",
       "      <td>0.872283</td>\n",
       "      <td>0.873835</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.873525</td>\n",
       "      <td>0.001081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.134435</td>\n",
       "      <td>0.006708</td>\n",
       "      <td>0.024340</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 5, 'gamma': 0.01}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.012068</td>\n",
       "      <td>41</td>\n",
       "      <td>0.960016</td>\n",
       "      <td>0.956134</td>\n",
       "      <td>0.958463</td>\n",
       "      <td>0.958463</td>\n",
       "      <td>0.952252</td>\n",
       "      <td>0.957065</td>\n",
       "      <td>0.002707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.030918</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 5, 'gamma': 0.001}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925155</td>\n",
       "      <td>0.007758</td>\n",
       "      <td>207</td>\n",
       "      <td>0.932065</td>\n",
       "      <td>0.927795</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928804</td>\n",
       "      <td>0.001729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.248534</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.051880</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 5, 'gamma': 0.0001}</td>\n",
       "      <td>0.861801</td>\n",
       "      <td>0.897516</td>\n",
       "      <td>0.875776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880124</td>\n",
       "      <td>0.015509</td>\n",
       "      <td>296</td>\n",
       "      <td>0.888975</td>\n",
       "      <td>0.883929</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.886646</td>\n",
       "      <td>0.885093</td>\n",
       "      <td>0.885016</td>\n",
       "      <td>0.002846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.131432</td>\n",
       "      <td>0.004523</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 6, 'gamma': 0.01}</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>0.947205</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934161</td>\n",
       "      <td>0.012752</td>\n",
       "      <td>1</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>0.958851</td>\n",
       "      <td>0.962345</td>\n",
       "      <td>0.958463</td>\n",
       "      <td>0.954969</td>\n",
       "      <td>0.959317</td>\n",
       "      <td>0.002683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.158994</td>\n",
       "      <td>0.008836</td>\n",
       "      <td>0.030507</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>6</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 6, 'gamma': 0.001}</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>0.008893</td>\n",
       "      <td>202</td>\n",
       "      <td>0.932842</td>\n",
       "      <td>0.928960</td>\n",
       "      <td>0.930512</td>\n",
       "      <td>0.927795</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.929736</td>\n",
       "      <td>0.001787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.238156</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>0.049479</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 6, 'gamma': 0.0001}</td>\n",
       "      <td>0.871118</td>\n",
       "      <td>0.905280</td>\n",
       "      <td>0.881988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888509</td>\n",
       "      <td>0.016059</td>\n",
       "      <td>295</td>\n",
       "      <td>0.895963</td>\n",
       "      <td>0.894798</td>\n",
       "      <td>0.889363</td>\n",
       "      <td>0.888975</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.892081</td>\n",
       "      <td>0.002831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.130244</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>0.023331</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 7, 'gamma': 0.01}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932919</td>\n",
       "      <td>0.010997</td>\n",
       "      <td>54</td>\n",
       "      <td>0.962345</td>\n",
       "      <td>0.960404</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.958851</td>\n",
       "      <td>0.958075</td>\n",
       "      <td>0.960792</td>\n",
       "      <td>0.002277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.153979</td>\n",
       "      <td>0.005745</td>\n",
       "      <td>0.029332</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>7</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 7, 'gamma': 0.001}</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926087</td>\n",
       "      <td>0.009399</td>\n",
       "      <td>200</td>\n",
       "      <td>0.934394</td>\n",
       "      <td>0.930512</td>\n",
       "      <td>0.932453</td>\n",
       "      <td>0.930901</td>\n",
       "      <td>0.930512</td>\n",
       "      <td>0.931755</td>\n",
       "      <td>0.001501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.230749</td>\n",
       "      <td>0.006005</td>\n",
       "      <td>0.047688</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 7, 'gamma': 0.0001}</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.895963</td>\n",
       "      <td>0.014061</td>\n",
       "      <td>294</td>\n",
       "      <td>0.902562</td>\n",
       "      <td>0.900621</td>\n",
       "      <td>0.895186</td>\n",
       "      <td>0.898292</td>\n",
       "      <td>0.895186</td>\n",
       "      <td>0.898370</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.130255</td>\n",
       "      <td>0.005490</td>\n",
       "      <td>0.023546</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 8, 'gamma': 0.01}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933540</td>\n",
       "      <td>0.011171</td>\n",
       "      <td>25</td>\n",
       "      <td>0.963121</td>\n",
       "      <td>0.962345</td>\n",
       "      <td>0.965450</td>\n",
       "      <td>0.960016</td>\n",
       "      <td>0.960016</td>\n",
       "      <td>0.962189</td>\n",
       "      <td>0.002048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.150600</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>0.028323</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>8</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 8, 'gamma': 0.001}</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927640</td>\n",
       "      <td>0.008871</td>\n",
       "      <td>192</td>\n",
       "      <td>0.935559</td>\n",
       "      <td>0.930901</td>\n",
       "      <td>0.933618</td>\n",
       "      <td>0.932842</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>0.932609</td>\n",
       "      <td>0.001943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.226007</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.046879</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 8, 'gamma': 0.0001}</td>\n",
       "      <td>0.883540</td>\n",
       "      <td>0.906832</td>\n",
       "      <td>0.895963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899068</td>\n",
       "      <td>0.011988</td>\n",
       "      <td>293</td>\n",
       "      <td>0.908773</td>\n",
       "      <td>0.901398</td>\n",
       "      <td>0.898680</td>\n",
       "      <td>0.902950</td>\n",
       "      <td>0.899457</td>\n",
       "      <td>0.902252</td>\n",
       "      <td>0.003587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.128658</td>\n",
       "      <td>0.005819</td>\n",
       "      <td>0.023735</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 9, 'gamma': 0.01}</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933540</td>\n",
       "      <td>0.011678</td>\n",
       "      <td>25</td>\n",
       "      <td>0.965450</td>\n",
       "      <td>0.965062</td>\n",
       "      <td>0.966615</td>\n",
       "      <td>0.961180</td>\n",
       "      <td>0.960792</td>\n",
       "      <td>0.963820</td>\n",
       "      <td>0.002373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.147201</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.027336</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>9</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 9, 'gamma': 0.001}</td>\n",
       "      <td>0.916149</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926708</td>\n",
       "      <td>0.009389</td>\n",
       "      <td>194</td>\n",
       "      <td>0.935947</td>\n",
       "      <td>0.931289</td>\n",
       "      <td>0.935947</td>\n",
       "      <td>0.933618</td>\n",
       "      <td>0.930512</td>\n",
       "      <td>0.933463</td>\n",
       "      <td>0.002272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.223608</td>\n",
       "      <td>0.007855</td>\n",
       "      <td>0.044884</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 9, 'gamma': 0.0001}</td>\n",
       "      <td>0.883540</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.900621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900621</td>\n",
       "      <td>0.012305</td>\n",
       "      <td>292</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.901398</td>\n",
       "      <td>0.904891</td>\n",
       "      <td>0.905280</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.904814</td>\n",
       "      <td>0.003343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.128855</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.023143</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.012266</td>\n",
       "      <td>41</td>\n",
       "      <td>0.966227</td>\n",
       "      <td>0.966615</td>\n",
       "      <td>0.967003</td>\n",
       "      <td>0.961568</td>\n",
       "      <td>0.962345</td>\n",
       "      <td>0.964752</td>\n",
       "      <td>0.002308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.145605</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.027556</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>0.917702</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.916149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928261</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>191</td>\n",
       "      <td>0.937112</td>\n",
       "      <td>0.932453</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.935171</td>\n",
       "      <td>0.931289</td>\n",
       "      <td>0.934472</td>\n",
       "      <td>0.002242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.212436</td>\n",
       "      <td>0.004329</td>\n",
       "      <td>0.045078</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001}</td>\n",
       "      <td>0.883540</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>0.899068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.013749</td>\n",
       "      <td>291</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.908773</td>\n",
       "      <td>0.905280</td>\n",
       "      <td>0.902562</td>\n",
       "      <td>0.905745</td>\n",
       "      <td>0.003158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.152393</td>\n",
       "      <td>0.005620</td>\n",
       "      <td>0.020154</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>91</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 91, 'gamma': 0.01}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932298</td>\n",
       "      <td>0.009948</td>\n",
       "      <td>72</td>\n",
       "      <td>0.981755</td>\n",
       "      <td>0.979814</td>\n",
       "      <td>0.981366</td>\n",
       "      <td>0.980978</td>\n",
       "      <td>0.981755</td>\n",
       "      <td>0.981134</td>\n",
       "      <td>0.000720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.134448</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.020747</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>91</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 91, 'gamma': 0.001}</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933851</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>6</td>\n",
       "      <td>0.949146</td>\n",
       "      <td>0.948758</td>\n",
       "      <td>0.947981</td>\n",
       "      <td>0.946040</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.946584</td>\n",
       "      <td>0.002993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.154967</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>0.027949</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>91</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 91, 'gamma': 0.0001}</td>\n",
       "      <td>0.916149</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.917702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925776</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>201</td>\n",
       "      <td>0.934394</td>\n",
       "      <td>0.930901</td>\n",
       "      <td>0.934006</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.929736</td>\n",
       "      <td>0.931522</td>\n",
       "      <td>0.002311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.152399</td>\n",
       "      <td>0.012650</td>\n",
       "      <td>0.020344</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>92</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 92, 'gamma': 0.01}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932298</td>\n",
       "      <td>0.009948</td>\n",
       "      <td>72</td>\n",
       "      <td>0.981755</td>\n",
       "      <td>0.979425</td>\n",
       "      <td>0.981755</td>\n",
       "      <td>0.981366</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.981289</td>\n",
       "      <td>0.000963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.135038</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.021944</td>\n",
       "      <td>0.002676</td>\n",
       "      <td>92</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 92, 'gamma': 0.001}</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933851</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>6</td>\n",
       "      <td>0.949146</td>\n",
       "      <td>0.948758</td>\n",
       "      <td>0.947981</td>\n",
       "      <td>0.946040</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.946584</td>\n",
       "      <td>0.002993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.155775</td>\n",
       "      <td>0.007343</td>\n",
       "      <td>0.028516</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>92</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 92, 'gamma': 0.0001}</td>\n",
       "      <td>0.916149</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.917702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>0.007414</td>\n",
       "      <td>202</td>\n",
       "      <td>0.934394</td>\n",
       "      <td>0.931289</td>\n",
       "      <td>0.933618</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.929736</td>\n",
       "      <td>0.931522</td>\n",
       "      <td>0.002218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.149798</td>\n",
       "      <td>0.009719</td>\n",
       "      <td>0.019743</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>93</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 93, 'gamma': 0.01}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932298</td>\n",
       "      <td>0.009948</td>\n",
       "      <td>72</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.979425</td>\n",
       "      <td>0.981755</td>\n",
       "      <td>0.981366</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.981366</td>\n",
       "      <td>0.001012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0.133644</td>\n",
       "      <td>0.006523</td>\n",
       "      <td>0.020750</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>93</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 93, 'gamma': 0.001}</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933851</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>6</td>\n",
       "      <td>0.949146</td>\n",
       "      <td>0.948758</td>\n",
       "      <td>0.947593</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.940606</td>\n",
       "      <td>0.946506</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.152794</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.028727</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>93</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 93, 'gamma': 0.0001}</td>\n",
       "      <td>0.916149</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.917702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>0.007414</td>\n",
       "      <td>202</td>\n",
       "      <td>0.935171</td>\n",
       "      <td>0.931289</td>\n",
       "      <td>0.933618</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.929736</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>0.002431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.153605</td>\n",
       "      <td>0.012206</td>\n",
       "      <td>0.019936</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 94, 'gamma': 0.01}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932298</td>\n",
       "      <td>0.009899</td>\n",
       "      <td>72</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.979814</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.981366</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.981599</td>\n",
       "      <td>0.000970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0.133439</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.020949</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>94</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 94, 'gamma': 0.001}</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933851</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>6</td>\n",
       "      <td>0.949146</td>\n",
       "      <td>0.948758</td>\n",
       "      <td>0.947593</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.940606</td>\n",
       "      <td>0.946506</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.153601</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>0.028134</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>94</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 94, 'gamma': 0.0001}</td>\n",
       "      <td>0.916149</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.917702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>0.007414</td>\n",
       "      <td>202</td>\n",
       "      <td>0.935171</td>\n",
       "      <td>0.930901</td>\n",
       "      <td>0.933618</td>\n",
       "      <td>0.928960</td>\n",
       "      <td>0.929736</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>0.002355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0.153008</td>\n",
       "      <td>0.007509</td>\n",
       "      <td>0.020739</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 95, 'gamma': 0.01}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932298</td>\n",
       "      <td>0.010140</td>\n",
       "      <td>72</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.979814</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.981366</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.981677</td>\n",
       "      <td>0.001024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.134236</td>\n",
       "      <td>0.004350</td>\n",
       "      <td>0.021146</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>95</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 95, 'gamma': 0.001}</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933851</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>6</td>\n",
       "      <td>0.949534</td>\n",
       "      <td>0.948758</td>\n",
       "      <td>0.947593</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.940606</td>\n",
       "      <td>0.946584</td>\n",
       "      <td>0.003169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0.153802</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.028315</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>95</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 95, 'gamma': 0.0001}</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926398</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>195</td>\n",
       "      <td>0.935171</td>\n",
       "      <td>0.930901</td>\n",
       "      <td>0.933618</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.929736</td>\n",
       "      <td>0.931755</td>\n",
       "      <td>0.002269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.153805</td>\n",
       "      <td>0.013854</td>\n",
       "      <td>0.019726</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>96</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 96, 'gamma': 0.01}</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>0.010713</td>\n",
       "      <td>112</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.979814</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.981366</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.981755</td>\n",
       "      <td>0.001070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.133577</td>\n",
       "      <td>0.005930</td>\n",
       "      <td>0.020551</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>96</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 96, 'gamma': 0.001}</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933851</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>6</td>\n",
       "      <td>0.949534</td>\n",
       "      <td>0.949146</td>\n",
       "      <td>0.947593</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.940606</td>\n",
       "      <td>0.946661</td>\n",
       "      <td>0.003226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.156018</td>\n",
       "      <td>0.007942</td>\n",
       "      <td>0.027518</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 96, 'gamma': 0.0001}</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926398</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>195</td>\n",
       "      <td>0.935171</td>\n",
       "      <td>0.930901</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.931599</td>\n",
       "      <td>0.002282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.153011</td>\n",
       "      <td>0.012252</td>\n",
       "      <td>0.019739</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 97, 'gamma': 0.01}</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>0.010713</td>\n",
       "      <td>112</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.979814</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.981755</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.981832</td>\n",
       "      <td>0.001053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.135237</td>\n",
       "      <td>0.008131</td>\n",
       "      <td>0.020733</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>97</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 97, 'gamma': 0.001}</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933851</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>6</td>\n",
       "      <td>0.949534</td>\n",
       "      <td>0.949146</td>\n",
       "      <td>0.947593</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.946584</td>\n",
       "      <td>0.003372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.151986</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.027529</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>97</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 97, 'gamma': 0.0001}</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926398</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>195</td>\n",
       "      <td>0.935171</td>\n",
       "      <td>0.931289</td>\n",
       "      <td>0.934006</td>\n",
       "      <td>0.929736</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.931910</td>\n",
       "      <td>0.002311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.154594</td>\n",
       "      <td>0.010630</td>\n",
       "      <td>0.019755</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 98, 'gamma': 0.01}</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931366</td>\n",
       "      <td>0.010731</td>\n",
       "      <td>135</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.979814</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.981910</td>\n",
       "      <td>0.001059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.137839</td>\n",
       "      <td>0.010129</td>\n",
       "      <td>0.020738</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>98</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 98, 'gamma': 0.001}</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933851</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>6</td>\n",
       "      <td>0.949922</td>\n",
       "      <td>0.949146</td>\n",
       "      <td>0.947593</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.946661</td>\n",
       "      <td>0.003443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0.152372</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.027535</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 98, 'gamma': 0.0001}</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926398</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>195</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.931289</td>\n",
       "      <td>0.934006</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.931755</td>\n",
       "      <td>0.002282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0.164379</td>\n",
       "      <td>0.021343</td>\n",
       "      <td>0.021715</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 99, 'gamma': 0.01}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>0.010159</td>\n",
       "      <td>112</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.979814</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.981910</td>\n",
       "      <td>0.001059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.139691</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.020927</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>99</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 99, 'gamma': 0.001}</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933851</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>6</td>\n",
       "      <td>0.949922</td>\n",
       "      <td>0.949534</td>\n",
       "      <td>0.948758</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.939829</td>\n",
       "      <td>0.946739</td>\n",
       "      <td>0.003767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.157969</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.028116</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 99, 'gamma': 0.0001}</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926398</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>195</td>\n",
       "      <td>0.934006</td>\n",
       "      <td>0.931289</td>\n",
       "      <td>0.933618</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>0.001854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.161379</td>\n",
       "      <td>0.022864</td>\n",
       "      <td>0.020735</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>0.010159</td>\n",
       "      <td>112</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.979814</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.981910</td>\n",
       "      <td>0.001059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.135051</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>0.020744</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001}</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933851</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>6</td>\n",
       "      <td>0.950311</td>\n",
       "      <td>0.949534</td>\n",
       "      <td>0.948758</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.939829</td>\n",
       "      <td>0.946817</td>\n",
       "      <td>0.003835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.156575</td>\n",
       "      <td>0.009405</td>\n",
       "      <td>0.028121</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.0001}</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.917702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>193</td>\n",
       "      <td>0.934006</td>\n",
       "      <td>0.931289</td>\n",
       "      <td>0.934006</td>\n",
       "      <td>0.930901</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.931910</td>\n",
       "      <td>0.001831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0         0.156591      0.001688         0.030116        0.000759       1   \n",
       "1         0.240164      0.023825         0.045873        0.002609       1   \n",
       "2         0.365413      0.022941         0.074602        0.001717       1   \n",
       "3         0.170348      0.016048         0.029918        0.002271       2   \n",
       "4         0.224018      0.028661         0.038883        0.001095       2   \n",
       "5         0.315155      0.017102         0.064822        0.002082       2   \n",
       "6         0.157983      0.010788         0.027323        0.001033       3   \n",
       "7         0.174118      0.004819         0.035505        0.000784       3   \n",
       "8         0.284447      0.016197         0.057851        0.000632       3   \n",
       "9         0.134431      0.006005         0.025119        0.000969       4   \n",
       "10        0.172339      0.012988         0.033506        0.001852       4   \n",
       "11        0.254123      0.003133         0.053646        0.000748       4   \n",
       "12        0.134435      0.006708         0.024340        0.000795       5   \n",
       "13        0.160964      0.003791         0.030918        0.000889       5   \n",
       "14        0.248534      0.002569         0.051880        0.002539       5   \n",
       "15        0.131432      0.004523         0.023950        0.001084       6   \n",
       "16        0.158994      0.008836         0.030507        0.001742       6   \n",
       "17        0.238156      0.005412         0.049479        0.001006       6   \n",
       "18        0.130244      0.006327         0.023331        0.001012       7   \n",
       "19        0.153979      0.005745         0.029332        0.001009       7   \n",
       "20        0.230749      0.006005         0.047688        0.001156       7   \n",
       "21        0.130255      0.005490         0.023546        0.000798       8   \n",
       "22        0.150600      0.003845         0.028323        0.000797       8   \n",
       "23        0.226007      0.001967         0.046879        0.001664       8   \n",
       "24        0.128658      0.005819         0.023735        0.001694       9   \n",
       "25        0.147201      0.004520         0.027336        0.000791       9   \n",
       "26        0.223608      0.007855         0.044884        0.000892       9   \n",
       "27        0.128855      0.005454         0.023143        0.001325      10   \n",
       "28        0.145605      0.003841         0.027556        0.000479      10   \n",
       "29        0.212436      0.004329         0.045078        0.002624      10   \n",
       "..             ...           ...              ...             ...     ...   \n",
       "270       0.152393      0.005620         0.020154        0.000746      91   \n",
       "271       0.134448      0.002216         0.020747        0.000779      91   \n",
       "272       0.154967      0.007013         0.027949        0.000614      91   \n",
       "273       0.152399      0.012650         0.020344        0.001623      92   \n",
       "274       0.135038      0.008700         0.021944        0.002676      92   \n",
       "275       0.155775      0.007343         0.028516        0.001015      92   \n",
       "276       0.149798      0.009719         0.019743        0.001459      93   \n",
       "277       0.133644      0.006523         0.020750        0.000400      93   \n",
       "278       0.152794      0.005332         0.028727        0.001828      93   \n",
       "279       0.153605      0.012206         0.019936        0.001098      94   \n",
       "280       0.133439      0.003962         0.020949        0.001087      94   \n",
       "281       0.153601      0.006643         0.028134        0.001167      94   \n",
       "282       0.153008      0.007509         0.020739        0.000754      95   \n",
       "283       0.134236      0.004350         0.021146        0.001465      95   \n",
       "284       0.153802      0.002645         0.028315        0.000492      95   \n",
       "285       0.153805      0.013854         0.019726        0.001476      96   \n",
       "286       0.133577      0.005930         0.020551        0.001019      96   \n",
       "287       0.156018      0.007942         0.027518        0.000791      96   \n",
       "288       0.153011      0.012252         0.019739        0.001464      97   \n",
       "289       0.135237      0.008131         0.020733        0.001160      97   \n",
       "290       0.151986      0.003639         0.027529        0.000494      97   \n",
       "291       0.154594      0.010630         0.019755        0.001472      98   \n",
       "292       0.137839      0.010129         0.020738        0.000736      98   \n",
       "293       0.152372      0.003308         0.027535        0.000484      98   \n",
       "294       0.164379      0.021343         0.021715        0.002209      99   \n",
       "295       0.139691      0.005500         0.020927        0.000639      99   \n",
       "296       0.157969      0.006196         0.028116        0.001171      99   \n",
       "297       0.161379      0.022864         0.020735        0.002307     100   \n",
       "298       0.135051      0.006314         0.020744        0.001163     100   \n",
       "299       0.156575      0.009405         0.028121        0.001470     100   \n",
       "\n",
       "    param_gamma                       params  split0_test_score  \\\n",
       "0          0.01      {'C': 1, 'gamma': 0.01}           0.917702   \n",
       "1         0.001     {'C': 1, 'gamma': 0.001}           0.886646   \n",
       "2        0.0001    {'C': 1, 'gamma': 0.0001}           0.770186   \n",
       "3          0.01      {'C': 2, 'gamma': 0.01}           0.919255   \n",
       "4         0.001     {'C': 2, 'gamma': 0.001}           0.899068   \n",
       "5        0.0001    {'C': 2, 'gamma': 0.0001}           0.830745   \n",
       "6          0.01      {'C': 3, 'gamma': 0.01}           0.913043   \n",
       "7         0.001     {'C': 3, 'gamma': 0.001}           0.903727   \n",
       "8        0.0001    {'C': 3, 'gamma': 0.0001}           0.840062   \n",
       "9          0.01      {'C': 4, 'gamma': 0.01}           0.916149   \n",
       "10        0.001     {'C': 4, 'gamma': 0.001}           0.906832   \n",
       "11       0.0001    {'C': 4, 'gamma': 0.0001}           0.852484   \n",
       "12         0.01      {'C': 5, 'gamma': 0.01}           0.913043   \n",
       "13        0.001     {'C': 5, 'gamma': 0.001}           0.913043   \n",
       "14       0.0001    {'C': 5, 'gamma': 0.0001}           0.861801   \n",
       "15         0.01      {'C': 6, 'gamma': 0.01}           0.911491   \n",
       "16        0.001     {'C': 6, 'gamma': 0.001}           0.914596   \n",
       "17       0.0001    {'C': 6, 'gamma': 0.0001}           0.871118   \n",
       "18         0.01      {'C': 7, 'gamma': 0.01}           0.913043   \n",
       "19        0.001     {'C': 7, 'gamma': 0.001}           0.914596   \n",
       "20       0.0001    {'C': 7, 'gamma': 0.0001}           0.880435   \n",
       "21         0.01      {'C': 8, 'gamma': 0.01}           0.913043   \n",
       "22        0.001     {'C': 8, 'gamma': 0.001}           0.919255   \n",
       "23       0.0001    {'C': 8, 'gamma': 0.0001}           0.883540   \n",
       "24         0.01      {'C': 9, 'gamma': 0.01}           0.911491   \n",
       "25        0.001     {'C': 9, 'gamma': 0.001}           0.916149   \n",
       "26       0.0001    {'C': 9, 'gamma': 0.0001}           0.883540   \n",
       "27         0.01     {'C': 10, 'gamma': 0.01}           0.909938   \n",
       "28        0.001    {'C': 10, 'gamma': 0.001}           0.917702   \n",
       "29       0.0001   {'C': 10, 'gamma': 0.0001}           0.883540   \n",
       "..          ...                          ...                ...   \n",
       "270        0.01     {'C': 91, 'gamma': 0.01}           0.913043   \n",
       "271       0.001    {'C': 91, 'gamma': 0.001}           0.923913   \n",
       "272      0.0001   {'C': 91, 'gamma': 0.0001}           0.916149   \n",
       "273        0.01     {'C': 92, 'gamma': 0.01}           0.913043   \n",
       "274       0.001    {'C': 92, 'gamma': 0.001}           0.923913   \n",
       "275      0.0001   {'C': 92, 'gamma': 0.0001}           0.916149   \n",
       "276        0.01     {'C': 93, 'gamma': 0.01}           0.913043   \n",
       "277       0.001    {'C': 93, 'gamma': 0.001}           0.923913   \n",
       "278      0.0001   {'C': 93, 'gamma': 0.0001}           0.916149   \n",
       "279        0.01     {'C': 94, 'gamma': 0.01}           0.913043   \n",
       "280       0.001    {'C': 94, 'gamma': 0.001}           0.923913   \n",
       "281      0.0001   {'C': 94, 'gamma': 0.0001}           0.916149   \n",
       "282        0.01     {'C': 95, 'gamma': 0.01}           0.913043   \n",
       "283       0.001    {'C': 95, 'gamma': 0.001}           0.923913   \n",
       "284      0.0001   {'C': 95, 'gamma': 0.0001}           0.919255   \n",
       "285        0.01     {'C': 96, 'gamma': 0.01}           0.911491   \n",
       "286       0.001    {'C': 96, 'gamma': 0.001}           0.923913   \n",
       "287      0.0001   {'C': 96, 'gamma': 0.0001}           0.919255   \n",
       "288        0.01     {'C': 97, 'gamma': 0.01}           0.911491   \n",
       "289       0.001    {'C': 97, 'gamma': 0.001}           0.923913   \n",
       "290      0.0001   {'C': 97, 'gamma': 0.0001}           0.919255   \n",
       "291        0.01     {'C': 98, 'gamma': 0.01}           0.911491   \n",
       "292       0.001    {'C': 98, 'gamma': 0.001}           0.923913   \n",
       "293      0.0001   {'C': 98, 'gamma': 0.0001}           0.919255   \n",
       "294        0.01     {'C': 99, 'gamma': 0.01}           0.913043   \n",
       "295       0.001    {'C': 99, 'gamma': 0.001}           0.923913   \n",
       "296      0.0001   {'C': 99, 'gamma': 0.0001}           0.919255   \n",
       "297        0.01    {'C': 100, 'gamma': 0.01}           0.913043   \n",
       "298       0.001   {'C': 100, 'gamma': 0.001}           0.923913   \n",
       "299      0.0001  {'C': 100, 'gamma': 0.0001}           0.919255   \n",
       "\n",
       "     split1_test_score  split2_test_score  ...  mean_test_score  \\\n",
       "0             0.939441           0.922360  ...         0.929814   \n",
       "1             0.919255           0.899068  ...         0.904037   \n",
       "2             0.802795           0.791925  ...         0.786025   \n",
       "3             0.945652           0.925466  ...         0.934161   \n",
       "4             0.919255           0.905280  ...         0.912112   \n",
       "5             0.854037           0.844720  ...         0.844410   \n",
       "6             0.944099           0.927019  ...         0.932609   \n",
       "7             0.923913           0.909938  ...         0.918634   \n",
       "8             0.869565           0.860248  ...         0.858075   \n",
       "9             0.942547           0.930124  ...         0.933230   \n",
       "10            0.933230           0.916149  ...         0.922671   \n",
       "11            0.881988           0.866460  ...         0.870497   \n",
       "12            0.945652           0.927019  ...         0.933230   \n",
       "13            0.933230           0.919255  ...         0.925155   \n",
       "14            0.897516           0.875776  ...         0.880124   \n",
       "15            0.947205           0.930124  ...         0.934161   \n",
       "16            0.933230           0.914596  ...         0.925466   \n",
       "17            0.905280           0.881988  ...         0.888509   \n",
       "18            0.944099           0.930124  ...         0.932919   \n",
       "19            0.934783           0.914596  ...         0.926087   \n",
       "20            0.909938           0.892857  ...         0.895963   \n",
       "21            0.944099           0.931677  ...         0.933540   \n",
       "22            0.934783           0.914596  ...         0.927640   \n",
       "23            0.906832           0.895963  ...         0.899068   \n",
       "24            0.944099           0.934783  ...         0.933540   \n",
       "25            0.934783           0.914596  ...         0.926708   \n",
       "26            0.909938           0.900621  ...         0.900621   \n",
       "27            0.944099           0.934783  ...         0.933230   \n",
       "28            0.934783           0.916149  ...         0.928261   \n",
       "29            0.914596           0.899068  ...         0.902174   \n",
       "..                 ...                ...  ...              ...   \n",
       "270           0.937888           0.936335  ...         0.932298   \n",
       "271           0.940994           0.925466  ...         0.933851   \n",
       "272           0.934783           0.917702  ...         0.925776   \n",
       "273           0.937888           0.936335  ...         0.932298   \n",
       "274           0.940994           0.925466  ...         0.933851   \n",
       "275           0.934783           0.917702  ...         0.925466   \n",
       "276           0.937888           0.936335  ...         0.932298   \n",
       "277           0.940994           0.925466  ...         0.933851   \n",
       "278           0.934783           0.917702  ...         0.925466   \n",
       "279           0.937888           0.934783  ...         0.932298   \n",
       "280           0.940994           0.925466  ...         0.933851   \n",
       "281           0.934783           0.917702  ...         0.925466   \n",
       "282           0.937888           0.934783  ...         0.932298   \n",
       "283           0.940994           0.925466  ...         0.933851   \n",
       "284           0.934783           0.919255  ...         0.926398   \n",
       "285           0.937888           0.934783  ...         0.931677   \n",
       "286           0.940994           0.925466  ...         0.933851   \n",
       "287           0.934783           0.919255  ...         0.926398   \n",
       "288           0.937888           0.934783  ...         0.931677   \n",
       "289           0.940994           0.925466  ...         0.933851   \n",
       "290           0.934783           0.919255  ...         0.926398   \n",
       "291           0.937888           0.934783  ...         0.931366   \n",
       "292           0.940994           0.925466  ...         0.933851   \n",
       "293           0.934783           0.919255  ...         0.926398   \n",
       "294           0.937888           0.934783  ...         0.931677   \n",
       "295           0.940994           0.925466  ...         0.933851   \n",
       "296           0.934783           0.919255  ...         0.926398   \n",
       "297           0.937888           0.934783  ...         0.931677   \n",
       "298           0.940994           0.925466  ...         0.933851   \n",
       "299           0.934783           0.917702  ...         0.927019   \n",
       "\n",
       "     std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0          0.008528              186            0.943323            0.940994   \n",
       "1          0.013080              289            0.910326            0.903339   \n",
       "2          0.015322              300            0.789208            0.779503   \n",
       "3          0.010044                1            0.949534            0.946429   \n",
       "4          0.011137              279            0.919255            0.914984   \n",
       "5          0.011637              299            0.846661            0.844332   \n",
       "6          0.011309               64            0.952640            0.950311   \n",
       "7          0.010874              265            0.928960            0.921972   \n",
       "8          0.013125              298            0.863742            0.860248   \n",
       "9          0.009572               41            0.957298            0.953416   \n",
       "10         0.010504              252            0.931289            0.925078   \n",
       "11         0.014913              297            0.874224            0.872283   \n",
       "12         0.012068               41            0.960016            0.956134   \n",
       "13         0.007758              207            0.932065            0.927795   \n",
       "14         0.015509              296            0.888975            0.883929   \n",
       "15         0.012752                1            0.961957            0.958851   \n",
       "16         0.008893              202            0.932842            0.928960   \n",
       "17         0.016059              295            0.895963            0.894798   \n",
       "18         0.010997               54            0.962345            0.960404   \n",
       "19         0.009399              200            0.934394            0.930512   \n",
       "20         0.014061              294            0.902562            0.900621   \n",
       "21         0.011171               25            0.963121            0.962345   \n",
       "22         0.008871              192            0.935559            0.930901   \n",
       "23         0.011988              293            0.908773            0.901398   \n",
       "24         0.011678               25            0.965450            0.965062   \n",
       "25         0.009389              194            0.935947            0.931289   \n",
       "26         0.012305              292            0.910714            0.901398   \n",
       "27         0.012266               41            0.966227            0.966615   \n",
       "28         0.009491              191            0.937112            0.932453   \n",
       "29         0.013749              291            0.909938            0.902174   \n",
       "..              ...              ...                 ...                 ...   \n",
       "270        0.009948               72            0.981755            0.979814   \n",
       "271        0.008482                6            0.949146            0.948758   \n",
       "272        0.007695              201            0.934394            0.930901   \n",
       "273        0.009948               72            0.981755            0.979425   \n",
       "274        0.008482                6            0.949146            0.948758   \n",
       "275        0.007414              202            0.934394            0.931289   \n",
       "276        0.009948               72            0.982143            0.979425   \n",
       "277        0.008482                6            0.949146            0.948758   \n",
       "278        0.007414              202            0.935171            0.931289   \n",
       "279        0.009899               72            0.982143            0.979814   \n",
       "280        0.008482                6            0.949146            0.948758   \n",
       "281        0.007414              202            0.935171            0.930901   \n",
       "282        0.010140               72            0.982531            0.979814   \n",
       "283        0.008482                6            0.949534            0.948758   \n",
       "284        0.006334              195            0.935171            0.930901   \n",
       "285        0.010713              112            0.982531            0.979814   \n",
       "286        0.008482                6            0.949534            0.949146   \n",
       "287        0.006334              195            0.935171            0.930901   \n",
       "288        0.010713              112            0.982531            0.979814   \n",
       "289        0.008482                6            0.949534            0.949146   \n",
       "290        0.006334              195            0.935171            0.931289   \n",
       "291        0.010731              135            0.982531            0.979814   \n",
       "292        0.008482                6            0.949922            0.949146   \n",
       "293        0.006334              195            0.934783            0.931289   \n",
       "294        0.010159              112            0.982531            0.979814   \n",
       "295        0.008482                6            0.949922            0.949534   \n",
       "296        0.006334              195            0.934006            0.931289   \n",
       "297        0.010159              112            0.982531            0.979814   \n",
       "298        0.008482                6            0.950311            0.949534   \n",
       "299        0.007349              193            0.934006            0.931289   \n",
       "\n",
       "     split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0              0.945264            0.937112            0.939829   \n",
       "1              0.908773            0.906056            0.904115   \n",
       "2              0.785326            0.791925            0.788820   \n",
       "3              0.949922            0.946429            0.943323   \n",
       "4              0.918866            0.915761            0.916537   \n",
       "5              0.845497            0.850932            0.843944   \n",
       "6              0.954581            0.952252            0.947593   \n",
       "7              0.924689            0.921972            0.921584   \n",
       "8              0.860248            0.865295            0.858696   \n",
       "9              0.956134            0.953804            0.949922   \n",
       "10             0.927407            0.924689            0.926242   \n",
       "11             0.872283            0.873835            0.875000   \n",
       "12             0.958463            0.958463            0.952252   \n",
       "13             0.928571            0.927019            0.928571   \n",
       "14             0.880435            0.886646            0.885093   \n",
       "15             0.962345            0.958463            0.954969   \n",
       "16             0.930512            0.927795            0.928571   \n",
       "17             0.889363            0.888975            0.891304   \n",
       "18             0.964286            0.958851            0.958075   \n",
       "19             0.932453            0.930901            0.930512   \n",
       "20             0.895186            0.898292            0.895186   \n",
       "21             0.965450            0.960016            0.960016   \n",
       "22             0.933618            0.932842            0.930124   \n",
       "23             0.898680            0.902950            0.899457   \n",
       "24             0.966615            0.961180            0.960792   \n",
       "25             0.935947            0.933618            0.930512   \n",
       "26             0.904891            0.905280            0.901786   \n",
       "27             0.967003            0.961568            0.962345   \n",
       "28             0.936335            0.935171            0.931289   \n",
       "29             0.908773            0.905280            0.902562   \n",
       "..                  ...                 ...                 ...   \n",
       "270            0.981366            0.980978            0.981755   \n",
       "271            0.947981            0.946040            0.940994   \n",
       "272            0.934006            0.928571            0.929736   \n",
       "273            0.981755            0.981366            0.982143   \n",
       "274            0.947981            0.946040            0.940994   \n",
       "275            0.933618            0.928571            0.929736   \n",
       "276            0.981755            0.981366            0.982143   \n",
       "277            0.947593            0.946429            0.940606   \n",
       "278            0.933618            0.928571            0.929736   \n",
       "279            0.982143            0.981366            0.982531   \n",
       "280            0.947593            0.946429            0.940606   \n",
       "281            0.933618            0.928960            0.929736   \n",
       "282            0.982143            0.981366            0.982531   \n",
       "283            0.947593            0.946429            0.940606   \n",
       "284            0.933618            0.929348            0.929736   \n",
       "285            0.982531            0.981366            0.982531   \n",
       "286            0.947593            0.946429            0.940606   \n",
       "287            0.933230            0.929348            0.929348   \n",
       "288            0.982531            0.981755            0.982531   \n",
       "289            0.947593            0.946429            0.940217   \n",
       "290            0.934006            0.929736            0.929348   \n",
       "291            0.982531            0.982143            0.982531   \n",
       "292            0.947593            0.946429            0.940217   \n",
       "293            0.934006            0.929348            0.929348   \n",
       "294            0.982531            0.982143            0.982531   \n",
       "295            0.948758            0.945652            0.939829   \n",
       "296            0.933618            0.930124            0.929348   \n",
       "297            0.982531            0.982143            0.982531   \n",
       "298            0.948758            0.945652            0.939829   \n",
       "299            0.934006            0.930901            0.929348   \n",
       "\n",
       "     mean_train_score  std_train_score  \n",
       "0            0.941304         0.002814  \n",
       "1            0.906522         0.002672  \n",
       "2            0.786957         0.004277  \n",
       "3            0.947127         0.002411  \n",
       "4            0.917081         0.001694  \n",
       "5            0.846273         0.002516  \n",
       "6            0.951475         0.002368  \n",
       "7            0.923835         0.002793  \n",
       "8            0.861646         0.002463  \n",
       "9            0.954115         0.002544  \n",
       "10           0.926941         0.002373  \n",
       "11           0.873525         0.001081  \n",
       "12           0.957065         0.002707  \n",
       "13           0.928804         0.001729  \n",
       "14           0.885016         0.002846  \n",
       "15           0.959317         0.002683  \n",
       "16           0.929736         0.001787  \n",
       "17           0.892081         0.002831  \n",
       "18           0.960792         0.002277  \n",
       "19           0.931755         0.001501  \n",
       "20           0.898370         0.002930  \n",
       "21           0.962189         0.002048  \n",
       "22           0.932609         0.001943  \n",
       "23           0.902252         0.003587  \n",
       "24           0.963820         0.002373  \n",
       "25           0.933463         0.002272  \n",
       "26           0.904814         0.003343  \n",
       "27           0.964752         0.002308  \n",
       "28           0.934472         0.002242  \n",
       "29           0.905745         0.003158  \n",
       "..                ...              ...  \n",
       "270          0.981134         0.000720  \n",
       "271          0.946584         0.002993  \n",
       "272          0.931522         0.002311  \n",
       "273          0.981289         0.000963  \n",
       "274          0.946584         0.002993  \n",
       "275          0.931522         0.002218  \n",
       "276          0.981366         0.001012  \n",
       "277          0.946506         0.003100  \n",
       "278          0.931677         0.002431  \n",
       "279          0.981599         0.000970  \n",
       "280          0.946506         0.003100  \n",
       "281          0.931677         0.002355  \n",
       "282          0.981677         0.001024  \n",
       "283          0.946584         0.003169  \n",
       "284          0.931755         0.002269  \n",
       "285          0.981755         0.001070  \n",
       "286          0.946661         0.003226  \n",
       "287          0.931599         0.002282  \n",
       "288          0.981832         0.001053  \n",
       "289          0.946584         0.003372  \n",
       "290          0.931910         0.002311  \n",
       "291          0.981910         0.001059  \n",
       "292          0.946661         0.003443  \n",
       "293          0.931755         0.002282  \n",
       "294          0.981910         0.001059  \n",
       "295          0.946739         0.003767  \n",
       "296          0.931677         0.001854  \n",
       "297          0.981910         0.001059  \n",
       "298          0.946817         0.003835  \n",
       "299          0.931910         0.001831  \n",
       "\n",
       "[300 rows x 22 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv results\n",
    "cv_results4 = pd.DataFrame(model_cv4.cv_results_)\n",
    "cv_results4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# converting C to numeric type for plotting on x-axis\n",
    "cv_results4['param_C'] = cv_results4['param_C'].astype('int')\n",
    "\n",
    "# # plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "# subplot 1/3\n",
    "plt.subplot(131)\n",
    "gamma_012 = cv_results4[cv_results4['param_gamma']==0.01]\n",
    "\n",
    "plt.plot(gamma_012[\"param_C\"], gamma_012[\"mean_test_score\"])\n",
    "plt.plot(gamma_012[\"param_C\"], gamma_012[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.01\")\n",
    "plt.ylim([0.80, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n",
    "# subplot 2/3\n",
    "plt.subplot(132)\n",
    "gamma_0012 = cv_results4[cv_results4['param_gamma']==0.001]\n",
    "\n",
    "plt.plot(gamma_0012[\"param_C\"], gamma_0012[\"mean_test_score\"])\n",
    "plt.plot(gamma_0012[\"param_C\"], gamma_0012[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.001\")\n",
    "plt.ylim([0.80, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "# subplot 3/3\n",
    "plt.subplot(133)\n",
    "gamma_00012 = cv_results4[cv_results4['param_gamma']==0.0001]\n",
    "\n",
    "plt.plot(gamma_00012[\"param_C\"], gamma_00012[\"mean_test_score\"])\n",
    "plt.plot(gamma_00012[\"param_C\"], gamma_00012[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.0001\")\n",
    "plt.ylim([0.80, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best test score is 0.9341614906832298 corresponding to hyperparameters {'C': 2, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "best_score2 = model_cv4.best_score_\n",
    "best_hyperparams2 = model_cv4.best_params_\n",
    "\n",
    "print(\"The best test score is {0} corresponding to hyperparameters {1}\".format(best_score2, best_hyperparams2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though sklearn suggests the optimal scores mentioned above (gamma=0.001, C=100), one could argue that it is better to choose a simpler, more non-linear model with gamma=0.0001. This is because the optimal values mentioned here are calculated based on the average test accuracy (but not considering subjective parameters such as model complexity).\n",
    "\n",
    "We can achieve comparable average test accuracy (~92.5%) with gamma=0.0001 as well, though we'll have to increase the cost C for that. So to achieve high accuracy, there's a tradeoff between:\n",
    "- High gamma (i.e. high non-linearity) and average value of C\n",
    "- Low gamma (i.e. less non-linearity) and high value of C\n",
    "\n",
    "We argue that the model will be simpler if it has as less non-linearity as possible, so we choose gamma=0.0001 and a high C=100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and Evaluating the Final Model\n",
    "\n",
    "Let's now build and evaluate the final model, i.e. the model with highest test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[810  39]\n",
      " [ 60 472]] \n",
      "\n",
      "accuracy 0.9283128167994207\n",
      "precision 0.923679060665362\n",
      "sensitivity/recall 0.8872180451127819\n"
     ]
    }
   ],
   "source": [
    "# specify optimal hyperparameters\n",
    "best_params = {\"C\": 100, \"gamma\": 0.0001, \"kernel\":\"rbf\"}\n",
    "\n",
    "# model\n",
    "model3 = SVC(C=100, gamma=0.0001, kernel=\"rbf\")\n",
    "\n",
    "model3.fit(X_train, y_train)\n",
    "y_pred3 = model3.predict(X_test)\n",
    "\n",
    "# metrics\n",
    "print(metrics.confusion_matrix(y_test, y_pred3), \"\\n\")\n",
    "print(\"accuracy\", metrics.accuracy_score(y_test, y_pred3))\n",
    "print(\"precision\", metrics.precision_score(y_test, y_pred3))\n",
    "print(\"sensitivity/recall\", metrics.recall_score(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[810  39]\n",
      " [ 57 475]] \n",
      "\n",
      "accuracy 0.9304851556842868\n",
      "precision 0.9241245136186771\n",
      "sensitivity/recall 0.8928571428571429\n"
     ]
    }
   ],
   "source": [
    "# specify optimal hyperparameters\n",
    "best_params2 = {\"C\": 2, \"gamma\": 0.01, \"kernel\":\"rbf\"}\n",
    "\n",
    "# model\n",
    "model4 = SVC(C=2, gamma=0.01, kernel=\"rbf\")\n",
    "\n",
    "model4.fit(X_train, y_train)\n",
    "y_pred4 = model.predict(X_test)\n",
    "\n",
    "# metrics\n",
    "print(metrics.confusion_matrix(y_test, y_pred4), \"\\n\")\n",
    "print(\"accuracy\", metrics.accuracy_score(y_test, y_pred4))\n",
    "print(\"precision\", metrics.precision_score(y_test, y_pred4))\n",
    "print(\"sensitivity/recall\", metrics.recall_score(y_test, y_pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The accuracy achieved using a non-linear kernel is comparable to that of a linear one. Thus, it turns out that for this problem, **you do not really need a non-linear kernel**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE STUDY 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Letter Recognition Using SVM\n",
    "\n",
    "Let's now tackle a slightly more complex problem - letter recognition. We'll first explore the dataset a bit, prepare it (scale etc.) and then experiment with linear and non-linear SVMs with various hyperparameters.\n",
    "\n",
    "\n",
    "### Data Understanding \n",
    "\n",
    "Let's first understand the shape, attributes etc. of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# dataset\n",
    "letters = pd.read_csv(\"Datasets/letter-recognition.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions:  (20000, 17) \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 17 columns):\n",
      "letter    20000 non-null object\n",
      "xbox      20000 non-null int64\n",
      "ybox      20000 non-null int64\n",
      "width     20000 non-null int64\n",
      "height    20000 non-null int64\n",
      "onpix     20000 non-null int64\n",
      "xbar      20000 non-null int64\n",
      "ybar      20000 non-null int64\n",
      "x2bar     20000 non-null int64\n",
      "y2bar     20000 non-null int64\n",
      "xybar     20000 non-null int64\n",
      "x2ybar    20000 non-null int64\n",
      "xy2bar    20000 non-null int64\n",
      "xedge     20000 non-null int64\n",
      "xedgey    20000 non-null int64\n",
      "yedge     20000 non-null int64\n",
      "yedgex    20000 non-null int64\n",
      "dtypes: int64(16), object(1)\n",
      "memory usage: 2.6+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  xbox   ybox   width   height  onpix   xbar   ybar   x2bar  y2bar   \\\n",
       "0      T      2      8       3       5       1      8     13      0       6   \n",
       "1      I      5     12       3       7       2     10      5      5       4   \n",
       "2      D      4     11       6       8       6     10      6      2       6   \n",
       "3      N      7     11       6       6       3      5      9      4       6   \n",
       "4      G      2      1       3       1       1      8      6      6       6   \n",
       "\n",
       "   xybar   x2ybar  xy2bar  xedge   xedgey  yedge   yedgex  \n",
       "0       6      10       8       0       8       0       8  \n",
       "1      13       3       9       2       8       4      10  \n",
       "2      10       3       7       3       7       3       9  \n",
       "3       4       4      10       6      10       2       8  \n",
       "4       6       5       9       1       7       5      10  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# about the dataset\n",
    "\n",
    "# dimensions\n",
    "print(\"Dimensions: \", letters.shape, \"\\n\")\n",
    "\n",
    "# data types\n",
    "print(letters.info())\n",
    "\n",
    "# head\n",
    "letters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>J</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>X</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>O</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>R</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>F</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>J</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>J</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>H</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>O</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>J</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>C</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>M</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>W</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>H</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>G</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19970</th>\n",
       "      <td>F</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19971</th>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19972</th>\n",
       "      <td>V</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19973</th>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19974</th>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19975</th>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19976</th>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19977</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19978</th>\n",
       "      <td>K</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19979</th>\n",
       "      <td>M</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19980</th>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19981</th>\n",
       "      <td>S</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19982</th>\n",
       "      <td>Y</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19983</th>\n",
       "      <td>V</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19984</th>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19985</th>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19986</th>\n",
       "      <td>O</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19987</th>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19988</th>\n",
       "      <td>D</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19989</th>\n",
       "      <td>P</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19990</th>\n",
       "      <td>W</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19991</th>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19992</th>\n",
       "      <td>E</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19993</th>\n",
       "      <td>J</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>T</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      letter  xbox   ybox   width   height  onpix   xbar   ybar   x2bar  \\\n",
       "0          T      2      8       3       5       1      8     13      0   \n",
       "1          I      5     12       3       7       2     10      5      5   \n",
       "2          D      4     11       6       8       6     10      6      2   \n",
       "3          N      7     11       6       6       3      5      9      4   \n",
       "4          G      2      1       3       1       1      8      6      6   \n",
       "5          S      4     11       5       8       3      8      8      6   \n",
       "6          B      4      2       5       4       4      8      7      6   \n",
       "7          A      1      1       3       2       1      8      2      2   \n",
       "8          J      2      2       4       4       2     10      6      2   \n",
       "9          M     11     15      13       9       7     13      2      6   \n",
       "10         X      3      9       5       7       4      8      7      3   \n",
       "11         O      6     13       4       7       4      6      7      6   \n",
       "12         G      4      9       6       7       6      7      8      6   \n",
       "13         M      6      9       8       6       9      7      8      6   \n",
       "14         R      5      9       5       7       6      6     11      7   \n",
       "15         F      6      9       5       4       3     10      6      3   \n",
       "16         O      3      4       4       3       2      8      7      7   \n",
       "17         C      7     10       5       5       2      6      8      6   \n",
       "18         T      6     11       6       8       5      6     11      5   \n",
       "19         J      2      2       3       3       1     10      6      3   \n",
       "20         J      1      3       2       2       1      8      8      2   \n",
       "21         H      4      5       5       4       4      7      7      6   \n",
       "22         S      3      2       3       3       2      8      8      7   \n",
       "23         O      6     11       7       8       5      7      6      9   \n",
       "24         J      3      6       4       4       2      6      6      4   \n",
       "25         C      6     11       7       8       3      7      8      7   \n",
       "26         M      7     11      11       8       9      3      8      4   \n",
       "27         W     12     14      12       8       5      9     10      4   \n",
       "28         H      6      9       8       7       6      8      6      6   \n",
       "29         G      3      6       4       4       2      6      6      5   \n",
       "...      ...    ...    ...     ...     ...     ...    ...    ...    ...   \n",
       "19970      F      7     10       9       8       7      9      7      2   \n",
       "19971      C      5     10       7       9       8      5      6      4   \n",
       "19972      V      4      7       6       5       6      8      6      4   \n",
       "19973      T      4      4       5       3       2      5     12      2   \n",
       "19974      N      5      9       5       4       2      9     11      5   \n",
       "19975      E      1      0       1       0       0      5      8      5   \n",
       "19976      L      3      8       3       6       2      0      2      4   \n",
       "19977      A      3      9       5       6       2      6      5      3   \n",
       "19978      K      5     11       5       8       5      3      8      7   \n",
       "19979      M      6      9      10       7      12      7      5      3   \n",
       "19980      R      2      3       3       2       2      7      7      5   \n",
       "19981      S      6     12       6       7       3      6      8      3   \n",
       "19982      Y      3      9       5       6       3      7      9      1   \n",
       "19983      V      7     10       5       5       2      6     11      5   \n",
       "19984      S      2      0       2       1       1      8      7      4   \n",
       "19985      M      5      6       8       4       5      9      6      2   \n",
       "19986      O      9     15       6       8       5      5      7      7   \n",
       "19987      L      3      7       3       5       1      0      1      6   \n",
       "19988      D      6      9       8       8       8      7      6      5   \n",
       "19989      P      2      1       3       2       1      4     10      3   \n",
       "19990      W      3      8       5       6       5     11     11      2   \n",
       "19991      O      4      3       5       4       2      7      6      8   \n",
       "19992      E      4      9       5       6       3      5      9      2   \n",
       "19993      J      2     11       3       8       2     15      4      4   \n",
       "19994      T      5      8       7       7       7      7      9      4   \n",
       "19995      D      2      2       3       3       2      7      7      7   \n",
       "19996      C      7     10       8       8       4      4      8      6   \n",
       "19997      T      6      9       6       7       5      6     11      3   \n",
       "19998      S      2      3       4       2       1      8      7      2   \n",
       "19999      A      4      9       6       6       2      9      5      3   \n",
       "\n",
       "       y2bar   xybar   x2ybar  xy2bar  xedge   xedgey  yedge   yedgex  \n",
       "0           6       6      10       8       0       8       0       8  \n",
       "1           4      13       3       9       2       8       4      10  \n",
       "2           6      10       3       7       3       7       3       9  \n",
       "3           6       4       4      10       6      10       2       8  \n",
       "4           6       6       5       9       1       7       5      10  \n",
       "5           9       5       6       6       0       8       9       7  \n",
       "6           6       7       6       6       2       8       7      10  \n",
       "7           2       8       2       8       1       6       2       7  \n",
       "8           6      12       4       8       1       6       1       7  \n",
       "9           2      12       1       9       8       1       1       8  \n",
       "10          8       5       6       8       2       8       6       7  \n",
       "11          3      10       7       9       5       9       5       8  \n",
       "12          2       6       5      11       4       8       7       8  \n",
       "13          5       7       5       8       8       9       8       6  \n",
       "14          3       7       3       9       2       7       5      11  \n",
       "15          5      10       5       7       3       9       6       9  \n",
       "16          5       7       6       8       2       8       3       8  \n",
       "17          8      11       7      11       2       8       5       9  \n",
       "18          6      11       9       4       3      12       2       4  \n",
       "19          6      12       4       9       0       7       1       7  \n",
       "20          5      14       5       8       0       7       0       7  \n",
       "21          6       7       6       8       3       8       3       8  \n",
       "22          5       7       5       7       2       8       9       8  \n",
       "23          6       7       5       9       4       8       5       5  \n",
       "24          4      14       8      12       1       6       1       6  \n",
       "25         11       4       7      14       1       7       4       8  \n",
       "26          5      10      11      10      10       9       5       7  \n",
       "27          3       5      10       7      10      12       2       6  \n",
       "28          7       7       7       9       6       8       4       8  \n",
       "29          5       6       6       9       2       8       4       8  \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...  \n",
       "19970       6      12       4       6       5       9       4       9  \n",
       "19971       4       7       6      11       5      11       8      10  \n",
       "19972       2       7       8       8       7       9       4       6  \n",
       "19973       8      11       9       4       0      10       2       4  \n",
       "19974       3       5       6       9       5      11       2       6  \n",
       "19975       7       7       6      12       0       8       6      10  \n",
       "19976       6       1       0       8       0       8       0       8  \n",
       "19977       1       6       1       8       2       7       2       7  \n",
       "19978       3       6       4      11       3       8       2      11  \n",
       "19979       2       7       5       8      15       7       4       6  \n",
       "19980       5       7       5       6       2       7       4       8  \n",
       "19981       6      13       7       7       2       9       3       7  \n",
       "19982       6       6      11       8       2      11       2       7  \n",
       "19983       4      11       9       4       4      11       3      10  \n",
       "19984       6       5       6       8       0       8       7       8  \n",
       "19985       4       9       5       7       8       6       2       8  \n",
       "19986       4      10       7      10       5       9       5       8  \n",
       "19987       6       0       0       6       0       8       0       8  \n",
       "19988       7       7       5       9       6       5      10       3  \n",
       "19989       5      10       8       5       0       9       3       7  \n",
       "19990       2       5       8       7       7      12       1       7  \n",
       "19991       8       6       5       7       3       8       4       8  \n",
       "19992      10      10       8       9       2       8       5       5  \n",
       "19993       5      13       1       8       0       7       0       8  \n",
       "19994       8       7       7       8       3      10       8       6  \n",
       "19995       6       6       6       4       2       8       3       7  \n",
       "19996       9      12       9      13       2       9       3       7  \n",
       "19997       7      11       9       5       2      12       2       4  \n",
       "19998       6      10       6       8       1       9       5       8  \n",
       "19999       1       8       1       8       2       7       2       8  \n",
       "\n",
       "[20000 rows x 17 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['letter', 'xbox ', 'ybox ', 'width ', 'height', 'onpix ', 'xbar ',\n",
      "       'ybar ', 'x2bar', 'y2bar ', 'xybar ', 'x2ybar', 'xy2bar', 'xedge ',\n",
      "       'xedgey', 'yedge ', 'yedgex'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# a quirky bug: the column names have a space, e.g. 'xbox ', which throws and error when indexed\n",
    "print(letters.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['letter', 'xbox', 'ybox', 'width', 'height', 'onpix', 'xbar', 'ybar',\n",
      "       'x2bar', 'y2bar', 'xybar', 'x2ybar', 'xy2bar', 'xedge', 'xedgey',\n",
      "       'yedge', 'yedgex'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# let's 'reindex' the column names\n",
    "letters.columns = ['letter', 'xbox', 'ybox', 'width', 'height', 'onpix', 'xbar',\n",
    "       'ybar', 'x2bar', 'y2bar', 'xybar', 'x2ybar', 'xy2bar', 'xedge',\n",
    "       'xedgey', 'yedge', 'yedgex']\n",
    "print(letters.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "order = list(np.sort(letters['letter'].unique()))\n",
    "print(order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bdb6507240>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# basic plots: How do various attributes vary with the letters\n",
    "\n",
    "\n",
    "plt.figure(figsize= (20,10))\n",
    "\n",
    "sns.barplot(x= 'letter',\n",
    "            y = 'xbox',\n",
    "            data = letters,\n",
    "            order = order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>letter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>3.337136</td>\n",
       "      <td>6.975919</td>\n",
       "      <td>5.128010</td>\n",
       "      <td>5.178707</td>\n",
       "      <td>2.991128</td>\n",
       "      <td>8.851711</td>\n",
       "      <td>3.631179</td>\n",
       "      <td>2.755387</td>\n",
       "      <td>2.043093</td>\n",
       "      <td>7.802281</td>\n",
       "      <td>2.338403</td>\n",
       "      <td>8.465146</td>\n",
       "      <td>2.771863</td>\n",
       "      <td>6.321926</td>\n",
       "      <td>2.875792</td>\n",
       "      <td>7.468948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>3.985640</td>\n",
       "      <td>6.962141</td>\n",
       "      <td>5.088773</td>\n",
       "      <td>5.169713</td>\n",
       "      <td>4.596606</td>\n",
       "      <td>7.671018</td>\n",
       "      <td>7.062663</td>\n",
       "      <td>5.366841</td>\n",
       "      <td>5.571802</td>\n",
       "      <td>7.954308</td>\n",
       "      <td>5.506527</td>\n",
       "      <td>6.652742</td>\n",
       "      <td>3.117493</td>\n",
       "      <td>7.919060</td>\n",
       "      <td>6.612272</td>\n",
       "      <td>9.100522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>4.031250</td>\n",
       "      <td>7.063859</td>\n",
       "      <td>4.701087</td>\n",
       "      <td>5.296196</td>\n",
       "      <td>2.775815</td>\n",
       "      <td>5.437500</td>\n",
       "      <td>7.627717</td>\n",
       "      <td>5.927989</td>\n",
       "      <td>7.177989</td>\n",
       "      <td>8.773098</td>\n",
       "      <td>7.494565</td>\n",
       "      <td>11.947011</td>\n",
       "      <td>1.991848</td>\n",
       "      <td>8.876359</td>\n",
       "      <td>4.080163</td>\n",
       "      <td>8.555707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>4.023602</td>\n",
       "      <td>7.244720</td>\n",
       "      <td>5.170186</td>\n",
       "      <td>5.288199</td>\n",
       "      <td>4.026087</td>\n",
       "      <td>7.539130</td>\n",
       "      <td>6.806211</td>\n",
       "      <td>5.921739</td>\n",
       "      <td>6.508075</td>\n",
       "      <td>8.166460</td>\n",
       "      <td>5.111801</td>\n",
       "      <td>5.750311</td>\n",
       "      <td>3.365217</td>\n",
       "      <td>7.813665</td>\n",
       "      <td>3.971429</td>\n",
       "      <td>7.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>3.727865</td>\n",
       "      <td>6.944010</td>\n",
       "      <td>4.756510</td>\n",
       "      <td>5.201823</td>\n",
       "      <td>3.679688</td>\n",
       "      <td>5.966146</td>\n",
       "      <td>7.352865</td>\n",
       "      <td>4.223958</td>\n",
       "      <td>7.585938</td>\n",
       "      <td>8.507812</td>\n",
       "      <td>6.242188</td>\n",
       "      <td>10.341146</td>\n",
       "      <td>2.127604</td>\n",
       "      <td>8.298177</td>\n",
       "      <td>6.022135</td>\n",
       "      <td>8.506510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            xbox      ybox     width    height     onpix      xbar      ybar  \\\n",
       "letter                                                                         \n",
       "A       3.337136  6.975919  5.128010  5.178707  2.991128  8.851711  3.631179   \n",
       "B       3.985640  6.962141  5.088773  5.169713  4.596606  7.671018  7.062663   \n",
       "C       4.031250  7.063859  4.701087  5.296196  2.775815  5.437500  7.627717   \n",
       "D       4.023602  7.244720  5.170186  5.288199  4.026087  7.539130  6.806211   \n",
       "E       3.727865  6.944010  4.756510  5.201823  3.679688  5.966146  7.352865   \n",
       "\n",
       "           x2bar     y2bar     xybar    x2ybar     xy2bar     xedge    xedgey  \\\n",
       "letter                                                                          \n",
       "A       2.755387  2.043093  7.802281  2.338403   8.465146  2.771863  6.321926   \n",
       "B       5.366841  5.571802  7.954308  5.506527   6.652742  3.117493  7.919060   \n",
       "C       5.927989  7.177989  8.773098  7.494565  11.947011  1.991848  8.876359   \n",
       "D       5.921739  6.508075  8.166460  5.111801   5.750311  3.365217  7.813665   \n",
       "E       4.223958  7.585938  8.507812  6.242188  10.341146  2.127604  8.298177   \n",
       "\n",
       "           yedge    yedgex  \n",
       "letter                      \n",
       "A       2.875792  7.468948  \n",
       "B       6.612272  9.100522  \n",
       "C       4.080163  8.555707  \n",
       "D       3.971429  7.628571  \n",
       "E       6.022135  8.506510  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_means = letters.groupby('letter').mean()\n",
    "letter_means.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bdb6502a90>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18, 10))\n",
    "sns.heatmap(letter_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Let's conduct some data preparation steps before modeling. Firstly, let's see if it is important to **rescale** the features, since they may have varying ranges. For example, here are the average values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xbox      4.02\n",
       "ybox      7.04\n",
       "width     5.12\n",
       "height    5.37\n",
       "onpix     3.51\n",
       "xbar      6.90\n",
       "ybar      7.50\n",
       "x2bar     4.63\n",
       "y2bar     5.18\n",
       "xybar     8.28\n",
       "x2ybar    6.45\n",
       "xy2bar    7.93\n",
       "xedge     3.05\n",
       "xedgey    8.34\n",
       "yedge     3.69\n",
       "yedgex    7.80\n",
       "dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average feature values\n",
    "round(letters.drop('letter', axis=1).mean(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the average values do not vary a lot (e.g. having a diff of an order of magnitude). Nevertheless, it is better to rescale them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into X and y\n",
    "X = letters.drop(\"letter\", axis = 1)\n",
    "y = letters['letter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the features\n",
    "X_scaled = scale(X)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building\n",
    "\n",
    "Let's fist build two basic models - linear and non-linear with default hyperparameters, and compare the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model\n",
    "\n",
    "model_linear = SVC(kernel='linear')\n",
    "model_linear.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = model_linear.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8523333333333334 \n",
      "\n",
      "[[198   0   0   0   0   0   1   1   0   1   1   1   0   0   0   0   0   1\n",
      "    0   1   1   0   0   0   3   0]\n",
      " [  0 188   0   3   0   1   3   3   1   0   1   0   0   2   0   1   1   9\n",
      "    3   0   0   1   0   1   0   0]\n",
      " [  1   0 200   0   7   0  12   1   0   0   5   0   0   0   3   0   0   0\n",
      "    0   0   1   0   0   0   0   0]\n",
      " [  1  15   0 210   0   1   2   2   1   0   1   0   1   5   3   0   0   5\n",
      "    0   1   0   0   0   0   0   0]\n",
      " [  0   1   3   0 204   2   6   1   0   0   1   5   0   0   0   0   2   2\n",
      "    1   2   0   0   0   1   0   3]\n",
      " [  0   0   0   1   1 201   1   2   1   1   0   0   0   2   0   2   0   0\n",
      "    3   7   1   0   1   0   1   0]\n",
      " [  0   1   9   4   2   2 167   1   0   1   4   3   1   0   1   0   9   1\n",
      "    8   0   0   2   3   0   0   0]\n",
      " [  0   7   3  11   0   4   3 141   0   2   4   1   2   0  12   0   4  12\n",
      "    0   0   4   2   0   4   1   0]\n",
      " [  0   0   2   3   0   6   0   0 184   9   0   0   0   0   1   0   0   0\n",
      "    3   0   0   0   0   4   0   3]\n",
      " [  2   0   0   3   0   2   0   2  10 187   0   0   0   1   2   0   0   1\n",
      "    5   0   1   0   0   0   0   4]\n",
      " [  0   1   5   2   0   0   1   3   0   0 198   2   2   0   0   0   0  19\n",
      "    0   0   0   0   0  12   0   0]\n",
      " [  2   1   3   2   5   0   8   1   0   0   1 206   0   0   0   0   5   0\n",
      "    2   1   0   0   0   0   0   0]\n",
      " [  0   3   0   0   0   0   0   3   0   0   0   0 222   1   0   0   0   2\n",
      "    0   0   0   0   3   0   0   0]\n",
      " [  1   0   0   4   0   0   0   6   0   0   0   0   1 235   1   1   0   0\n",
      "    0   0   0   1   1   0   0   0]\n",
      " [  3   0   4   7   0   0   0  21   0   0   0   0   2   0 163   3   2   3\n",
      "    0   0   3   0  10   0   0   0]\n",
      " [  0   2   0   2   0  16   5   1   0   1   3   0   0   0   1 225   0   0\n",
      "    0   0   0   1   0   0   8   0]\n",
      " [  3   1   0   0   4   0   9   0   0   2   0   1   0   0   6   0 198   0\n",
      "    8   0   0   0   1   0   0   2]\n",
      " [ 11  11   0   2   0   1   6   3   0   0  10   0   0   3   4   0   2 188\n",
      "    0   1   0   0   0   1   0   0]\n",
      " [  1  13   0   0   9   5   8   0   7   1   0   2   0   0   0   1   6   1\n",
      "  155   6   0   0   0   3   0  10]\n",
      " [  0   0   0   1   1   4   2   4   1   0   0   0   0   0   0   0   0   1\n",
      "    3 214   0   0   0   1   1   6]\n",
      " [  2   0   1   2   0   0   0   2   0   0   0   0   1   1   3   0   0   0\n",
      "    0   0 211   0   1   0   0   0]\n",
      " [  2   2   0   0   0   0   1   3   0   0   0   0   0   1   0   1   0   3\n",
      "    0   0   0 190   6   0   2   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   0   6   1   2   0   0   0\n",
      "    0   0   0   0 212   0   0   0]\n",
      " [  0   2   0   4   5   0   1   0   2   3   3   3   0   0   1   0   0   1\n",
      "    2   2   1   0   0 212   1   1]\n",
      " [  2   0   0   0   0   2   0   1   0   0   0   0   1   0   0   0   3   0\n",
      "    0   4   1  10   0   2 211   0]\n",
      " [  1   0   0   0   3   0   0   0   0   6   0   0   0   0   0   0   5   0\n",
      "   18   1   0   0   0   1   0 194]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix and accuracy\n",
    "\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "\n",
    "# cm\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear model gives approx. 85% accuracy. Let's look at a sufficiently non-linear model with randomly chosen hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-linear model\n",
    "# using rbf kernel, C=1, default value of gamma\n",
    "\n",
    "# model\n",
    "non_linear_model = SVC(kernel='rbf')\n",
    "\n",
    "# fit\n",
    "non_linear_model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = non_linear_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9383333333333334 \n",
      "\n",
      "[[205   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   2   0]\n",
      " [  0 205   0   3   1   0   1   0   0   0   0   0   0   0   0   0   0   6\n",
      "    1   0   0   0   0   1   0   0]\n",
      " [  0   0 213   0   5   0   7   1   0   0   0   0   0   0   4   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   4   0 234   0   0   1   3   0   0   0   0   0   3   1   0   0   2\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 221   1   9   0   0   0   0   0   0   0   0   0   0   1\n",
      "    0   0   0   0   0   0   0   2]\n",
      " [  0   0   0   1   0 215   1   1   1   0   0   0   0   1   0   1   0   0\n",
      "    1   3   0   0   0   0   0   0]\n",
      " [  0   0   3   4   1   1 202   0   0   0   0   1   1   0   2   0   0   1\n",
      "    0   0   0   1   2   0   0   0]\n",
      " [  0   7   0   5   0   0   4 177   0   0   2   0   1   0   3   0   4  13\n",
      "    0   0   1   0   0   0   0   0]\n",
      " [  0   0   1   1   0   3   0   0 194  11   0   0   0   0   0   1   0   0\n",
      "    2   0   0   0   0   2   0   0]\n",
      " [  1   0   0   1   0   0   0   0   6 206   0   0   0   1   2   0   0   0\n",
      "    2   0   0   0   0   1   0   0]\n",
      " [  0   4   0   2   0   0   0   4   0   0 217   0   1   0   0   0   0  14\n",
      "    0   0   0   0   0   3   0   0]\n",
      " [  0   0   1   0   2   0   6   0   0   0   1 222   0   0   0   0   0   3\n",
      "    0   0   0   0   0   2   0   0]\n",
      " [  0   5   0   0   0   0   0   2   0   0   0   0 225   0   0   0   0   0\n",
      "    0   0   0   0   2   0   0   0]\n",
      " [  0   2   0   1   0   0   0   2   0   0   0   0   1 239   3   0   0   2\n",
      "    0   0   0   0   0   0   1   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0 209   0   1   1\n",
      "    0   0   1   0   8   0   0   0]\n",
      " [  0   2   0   3   3  11   1   1   0   0   0   0   0   0   1 237   1   0\n",
      "    0   0   0   0   0   0   5   0]\n",
      " [  0   0   0   0   2   0   2   0   0   0   0   0   0   0   6   0 222   0\n",
      "    1   0   0   0   2   0   0   0]\n",
      " [  0  10   0   2   0   0   0   0   0   0   1   0   0   4   0   0   2 224\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   3   0   0   2   3   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  220   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   2   0   2   0   0   0   0   0   0   0   1   0   1\n",
      "    0 228   0   0   0   3   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   1   0   0   0\n",
      "    0   0 222   0   0   0   0   0]\n",
      " [  0   7   0   0   0   0   0   1   0   0   0   0   1   4   0   1   0   0\n",
      "    0   0   0 193   1   0   3   0]\n",
      " [  0   1   0   0   0   0   1   1   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0   1   0 217   0   0   0]\n",
      " [  0   2   0   3   2   0   0   0   1   0   2   0   0   0   0   0   0   1\n",
      "    0   0   0   0   0 233   0   0]\n",
      " [  2   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   1   0\n",
      "    0   1   2   2   0   0 228   0]\n",
      " [  0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   4   0\n",
      "    1   0   0   0   0   0   0 222]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix and accuracy\n",
    "\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "\n",
    "# cm\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GridSearchCV in module sklearn.model_selection._search:\n",
      "\n",
      "class GridSearchCV(BaseSearchCV)\n",
      " |  Exhaustive search over specified parameter values for an estimator.\n",
      " |  \n",
      " |  Important members are fit, predict.\n",
      " |  \n",
      " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      " |  It also implements \"predict\", \"predict_proba\", \"decision_function\",\n",
      " |  \"transform\" and \"inverse_transform\" if they are implemented in the\n",
      " |  estimator used.\n",
      " |  \n",
      " |  The parameters of the estimator used to apply these methods are optimized\n",
      " |  by cross-validated grid-search over a parameter grid.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <grid_search>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object.\n",
      " |      This is assumed to implement the scikit-learn estimator interface.\n",
      " |      Either estimator needs to provide a ``score`` function,\n",
      " |      or ``scoring`` must be passed.\n",
      " |  \n",
      " |  param_grid : dict or list of dictionaries\n",
      " |      Dictionary with parameters names (string) as keys and lists of\n",
      " |      parameter settings to try as values, or a list of such\n",
      " |      dictionaries, in which case the grids spanned by each dictionary\n",
      " |      in the list are explored. This enables searching over any sequence\n",
      " |      of parameter settings.\n",
      " |  \n",
      " |  scoring : string, callable, list/tuple, dict or None, default: None\n",
      " |      A single string (see :ref:`scoring_parameter`) or a callable\n",
      " |      (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
      " |  \n",
      " |      For evaluating multiple metrics, either give a list of (unique) strings\n",
      " |      or a dict with names as keys and callables as values.\n",
      " |  \n",
      " |      NOTE that when using custom scorers, each scorer should return a single\n",
      " |      value. Metric functions returning a list/array of values can be wrapped\n",
      " |      into multiple scorers that return one value each.\n",
      " |  \n",
      " |      See :ref:`multimetric_grid_search` for an example.\n",
      " |  \n",
      " |      If None, the estimator's default scorer (if available) is used.\n",
      " |  \n",
      " |  fit_params : dict, optional\n",
      " |      Parameters to pass to the fit method.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``fit_params`` as a constructor argument was deprecated in version\n",
      " |         0.19 and will be removed in version 0.21. Pass fit parameters to\n",
      " |         the ``fit`` method instead.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      Number of jobs to run in parallel.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |  pre_dispatch : int, or string, optional\n",
      " |      Controls the number of jobs that get dispatched during parallel\n",
      " |      execution. Reducing this number can be useful to avoid an\n",
      " |      explosion of memory consumption when more jobs get dispatched\n",
      " |      than CPUs can process. This parameter can be:\n",
      " |  \n",
      " |          - None, in which case all the jobs are immediately\n",
      " |            created and spawned. Use this for lightweight and\n",
      " |            fast-running jobs, to avoid delays due to on-demand\n",
      " |            spawning of the jobs\n",
      " |  \n",
      " |          - An int, giving the exact number of total jobs that are\n",
      " |            spawned\n",
      " |  \n",
      " |          - A string, giving an expression as a function of n_jobs,\n",
      " |            as in '2*n_jobs'\n",
      " |  \n",
      " |  iid : boolean, default='warn'\n",
      " |      If True, return the average score across folds, weighted by the number\n",
      " |      of samples in each test set. In this case, the data is assumed to be\n",
      " |      identically distributed across the folds, and the loss minimized is\n",
      " |      the total loss per sample, and not the mean loss across the folds. If\n",
      " |      False, return the average score across folds. Default is True, but\n",
      " |      will change to False in version 0.21, to correspond to the standard\n",
      " |      definition of cross-validation.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          Parameter ``iid`` will change from True to False by default in\n",
      " |          version 0.22, and will be removed in 0.24.\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, optional\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |  \n",
      " |      - None, to use the default 3-fold cross validation,\n",
      " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      " |      - :term:`CV splitter`,\n",
      " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |  \n",
      " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      " |      other cases, :class:`KFold` is used.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          ``cv`` default value if None will change from 3-fold to 5-fold\n",
      " |          in v0.22.\n",
      " |  \n",
      " |  refit : boolean, or string, default=True\n",
      " |      Refit an estimator using the best found parameters on the whole\n",
      " |      dataset.\n",
      " |  \n",
      " |      For multiple metric evaluation, this needs to be a string denoting the\n",
      " |      scorer is used to find the best parameters for refitting the estimator\n",
      " |      at the end.\n",
      " |  \n",
      " |      The refitted estimator is made available at the ``best_estimator_``\n",
      " |      attribute and permits using ``predict`` directly on this\n",
      " |      ``GridSearchCV`` instance.\n",
      " |  \n",
      " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      " |      ``best_score_`` and ``best_params_`` will only be available if\n",
      " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      " |      scorer.\n",
      " |  \n",
      " |      See ``scoring`` parameter to know more about multiple metric\n",
      " |      evaluation.\n",
      " |  \n",
      " |  verbose : integer\n",
      " |      Controls the verbosity: the higher, the more messages.\n",
      " |  \n",
      " |  error_score : 'raise' or numeric\n",
      " |      Value to assign to the score if an error occurs in estimator fitting.\n",
      " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      " |      step, which will always raise the error. Default is 'raise' but from\n",
      " |      version 0.22 it will change to np.nan.\n",
      " |  \n",
      " |  return_train_score : boolean, optional\n",
      " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      " |      scores.\n",
      " |  \n",
      " |      Current default is ``'warn'``, which behaves as ``True`` in addition\n",
      " |      to raising a warning when a training score is looked up.\n",
      " |      That default will be changed to ``False`` in 0.21.\n",
      " |      Computing training scores is used to get insights on how different\n",
      " |      parameter settings impact the overfitting/underfitting trade-off.\n",
      " |      However computing the scores on the training set can be computationally\n",
      " |      expensive and is not strictly required to select the parameters that\n",
      " |      yield the best generalization performance.\n",
      " |  \n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import svm, datasets\n",
      " |  >>> from sklearn.model_selection import GridSearchCV\n",
      " |  >>> iris = datasets.load_iris()\n",
      " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      " |  >>> svc = svm.SVC(gamma=\"scale\")\n",
      " |  >>> clf = GridSearchCV(svc, parameters, cv=5)\n",
      " |  >>> clf.fit(iris.data, iris.target)\n",
      " |  ...                             # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n",
      " |  GridSearchCV(cv=5, error_score=...,\n",
      " |         estimator=SVC(C=1.0, cache_size=..., class_weight=..., coef0=...,\n",
      " |                       decision_function_shape='ovr', degree=..., gamma=...,\n",
      " |                       kernel='rbf', max_iter=-1, probability=False,\n",
      " |                       random_state=None, shrinking=True, tol=...,\n",
      " |                       verbose=False),\n",
      " |         fit_params=None, iid=..., n_jobs=None,\n",
      " |         param_grid=..., pre_dispatch=..., refit=..., return_train_score=...,\n",
      " |         scoring=..., verbose=...)\n",
      " |  >>> sorted(clf.cv_results_.keys())\n",
      " |  ...                             # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n",
      " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      " |   'mean_train_score', 'param_C', 'param_kernel', 'params',...\n",
      " |   'rank_test_score', 'split0_test_score',...\n",
      " |   'split0_train_score', 'split1_test_score', 'split1_train_score',...\n",
      " |   'split2_test_score', 'split2_train_score',...\n",
      " |   'std_fit_time', 'std_score_time', 'std_test_score', 'std_train_score'...]\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cv_results_ : dict of numpy (masked) ndarrays\n",
      " |      A dict with keys as column headers and values as columns, that can be\n",
      " |      imported into a pandas ``DataFrame``.\n",
      " |  \n",
      " |      For instance the below given table\n",
      " |  \n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
      " |      +============+===========+============+=================+===+=========+\n",
      " |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |  \n",
      " |      will be represented by a ``cv_results_`` dict of::\n",
      " |  \n",
      " |          {\n",
      " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      " |                                       mask = [False False False False]...)\n",
      " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      " |                                      mask = [ True  True False False]...),\n",
      " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      " |                                       mask = [False False  True  True]...),\n",
      " |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
      " |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
      " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
      " |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
      " |          'rank_test_score'    : [2, 4, 3, 1],\n",
      " |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
      " |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
      " |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
      " |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
      " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      " |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
      " |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
      " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      " |          }\n",
      " |  \n",
      " |      NOTE\n",
      " |  \n",
      " |      The key ``'params'`` is used to store a list of parameter\n",
      " |      settings dicts for all the parameter candidates.\n",
      " |  \n",
      " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      " |      ``std_score_time`` are all in seconds.\n",
      " |  \n",
      " |      For multi-metric evaluation, the scores for all the scorers are\n",
      " |      available in the ``cv_results_`` dict at the keys ending with that\n",
      " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      " |  \n",
      " |  best_estimator_ : estimator or dict\n",
      " |      Estimator that was chosen by the search, i.e. estimator\n",
      " |      which gave highest score (or smallest loss if specified)\n",
      " |      on the left out data. Not available if ``refit=False``.\n",
      " |  \n",
      " |      See ``refit`` parameter for more information on allowed values.\n",
      " |  \n",
      " |  best_score_ : float\n",
      " |      Mean cross-validated score of the best_estimator\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  best_params_ : dict\n",
      " |      Parameter setting that gave the best results on the hold out data.\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  best_index_ : int\n",
      " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      " |      candidate parameter setting.\n",
      " |  \n",
      " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      " |      the parameter setting for the best model, that gives the highest\n",
      " |      mean score (``search.best_score_``).\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  scorer_ : function or a dict\n",
      " |      Scorer function used on the held out data to choose the best\n",
      " |      parameters for the model.\n",
      " |  \n",
      " |      For multi-metric evaluation, this attribute holds the validated\n",
      " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      " |  \n",
      " |  n_splits_ : int\n",
      " |      The number of cross-validation splits (folds/iterations).\n",
      " |  \n",
      " |  refit_time_ : float\n",
      " |      Seconds used for refitting the best model on the whole dataset.\n",
      " |  \n",
      " |      This is present only if ``refit`` is not False.\n",
      " |  \n",
      " |  Notes\n",
      " |  ------\n",
      " |  The parameters selected are those that maximize the score of the left out\n",
      " |  data, unless an explicit score is passed in which case it is used instead.\n",
      " |  \n",
      " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      " |  reasons if individual jobs take very little time, but may raise errors if\n",
      " |  the dataset is large and not enough memory is available.  A workaround in\n",
      " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      " |  n_jobs`.\n",
      " |  \n",
      " |  See Also\n",
      " |  ---------\n",
      " |  :class:`ParameterGrid`:\n",
      " |      generates all the combinations of a hyperparameter grid.\n",
      " |  \n",
      " |  :func:`sklearn.model_selection.train_test_split`:\n",
      " |      utility function to split the data into a development set usable\n",
      " |      for fitting a GridSearchCV instance and an evaluation set for\n",
      " |      its final evaluation.\n",
      " |  \n",
      " |  :func:`sklearn.metrics.make_scorer`:\n",
      " |      Make a scorer from a performance metric or loss function.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GridSearchCV\n",
      " |      BaseSearchCV\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, param_grid, scoring=None, fit_params=None, n_jobs=None, iid='warn', refit=True, cv='warn', verbose=0, pre_dispatch='2*n_jobs', error_score='raise-deprecating', return_train_score='warn')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSearchCV:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Call decision_function on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``decision_function``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  fit(self, X, y=None, groups=None, **fit_params)\n",
      " |      Run fit with all sets of parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      groups : array-like, with shape (n_samples,), optional\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set.\n",
      " |      \n",
      " |      **fit_params : dict of string -> object\n",
      " |          Parameters passed to the ``fit`` method of the estimator\n",
      " |  \n",
      " |  inverse_transform(self, Xt)\n",
      " |      Call inverse_transform on the estimator with the best found params.\n",
      " |      \n",
      " |      Only available if the underlying estimator implements\n",
      " |      ``inverse_transform`` and ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      Xt : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Call predict on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Call predict_log_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_log_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Call predict_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Returns the score on the given data, if the estimator has been refit.\n",
      " |      \n",
      " |      This uses the score defined by ``scoring`` where provided, and the\n",
      " |      ``best_estimator_.score`` method otherwise.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |          Input data, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Call transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator supports ``transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseSearchCV:\n",
      " |  \n",
      " |  classes_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GridSearchCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non-linear model gives approx. 93% accuracy. Thus, going forward, let's choose hyperparameters corresponding to non-linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search: Hyperparameter Tuning\n",
    "\n",
    "Let's now tune the model to find the optimal values of C and gamma corresponding to an RBF kernel. We'll use 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=101, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'gamma': [0.01, 0.001, 0.0001], 'C': [1, 10, 100, 1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 101)\n",
    "\n",
    "# specify range of hyperparameters\n",
    "# Set the parameters by cross-validation\n",
    "hyper_params = [ {'gamma': [1e-2, 1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "\n",
    "# specify model\n",
    "model = SVC(kernel=\"rbf\")\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = model, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'accuracy', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train, y_train)                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.971702</td>\n",
       "      <td>0.029962</td>\n",
       "      <td>1.228749</td>\n",
       "      <td>0.101741</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.826429</td>\n",
       "      <td>0.834643</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832714</td>\n",
       "      <td>0.006221</td>\n",
       "      <td>7</td>\n",
       "      <td>0.843929</td>\n",
       "      <td>0.844196</td>\n",
       "      <td>0.847679</td>\n",
       "      <td>0.843571</td>\n",
       "      <td>0.844018</td>\n",
       "      <td>0.844679</td>\n",
       "      <td>0.001514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.223899</td>\n",
       "      <td>0.088557</td>\n",
       "      <td>1.610377</td>\n",
       "      <td>0.107407</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001}</td>\n",
       "      <td>0.684643</td>\n",
       "      <td>0.672500</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677214</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>10</td>\n",
       "      <td>0.682054</td>\n",
       "      <td>0.683125</td>\n",
       "      <td>0.687946</td>\n",
       "      <td>0.679554</td>\n",
       "      <td>0.686429</td>\n",
       "      <td>0.683821</td>\n",
       "      <td>0.003021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.033128</td>\n",
       "      <td>0.202611</td>\n",
       "      <td>1.674175</td>\n",
       "      <td>0.182793</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.0001}</td>\n",
       "      <td>0.203929</td>\n",
       "      <td>0.207143</td>\n",
       "      <td>0.206429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217571</td>\n",
       "      <td>0.014490</td>\n",
       "      <td>12</td>\n",
       "      <td>0.212679</td>\n",
       "      <td>0.217589</td>\n",
       "      <td>0.228393</td>\n",
       "      <td>0.240625</td>\n",
       "      <td>0.240625</td>\n",
       "      <td>0.227982</td>\n",
       "      <td>0.011507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.192821</td>\n",
       "      <td>0.015985</td>\n",
       "      <td>0.789247</td>\n",
       "      <td>0.021506</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.914643</td>\n",
       "      <td>0.908571</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911214</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>3</td>\n",
       "      <td>0.929643</td>\n",
       "      <td>0.929464</td>\n",
       "      <td>0.930357</td>\n",
       "      <td>0.928929</td>\n",
       "      <td>0.928125</td>\n",
       "      <td>0.929304</td>\n",
       "      <td>0.000746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.951559</td>\n",
       "      <td>0.042951</td>\n",
       "      <td>1.224537</td>\n",
       "      <td>0.054149</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>0.805714</td>\n",
       "      <td>0.809643</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808929</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>8</td>\n",
       "      <td>0.818125</td>\n",
       "      <td>0.817679</td>\n",
       "      <td>0.819643</td>\n",
       "      <td>0.814375</td>\n",
       "      <td>0.819464</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.001897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.111301</td>\n",
       "      <td>0.012316</td>\n",
       "      <td>1.575593</td>\n",
       "      <td>0.043345</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001}</td>\n",
       "      <td>0.684286</td>\n",
       "      <td>0.671071</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>0.005788</td>\n",
       "      <td>11</td>\n",
       "      <td>0.681875</td>\n",
       "      <td>0.683304</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.680089</td>\n",
       "      <td>0.685446</td>\n",
       "      <td>0.683643</td>\n",
       "      <td>0.002608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.327169</td>\n",
       "      <td>0.005507</td>\n",
       "      <td>0.586225</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>0.946786</td>\n",
       "      <td>0.941429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947786</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>2</td>\n",
       "      <td>0.978482</td>\n",
       "      <td>0.977946</td>\n",
       "      <td>0.978393</td>\n",
       "      <td>0.978661</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.978411</td>\n",
       "      <td>0.000249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.387366</td>\n",
       "      <td>0.030278</td>\n",
       "      <td>0.928304</td>\n",
       "      <td>0.104642</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001}</td>\n",
       "      <td>0.861071</td>\n",
       "      <td>0.866071</td>\n",
       "      <td>0.850357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.863357</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>5</td>\n",
       "      <td>0.879554</td>\n",
       "      <td>0.877143</td>\n",
       "      <td>0.882143</td>\n",
       "      <td>0.875536</td>\n",
       "      <td>0.879464</td>\n",
       "      <td>0.878768</td>\n",
       "      <td>0.002262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.970905</td>\n",
       "      <td>0.028554</td>\n",
       "      <td>1.186857</td>\n",
       "      <td>0.028845</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.0001}</td>\n",
       "      <td>0.801071</td>\n",
       "      <td>0.806429</td>\n",
       "      <td>0.803929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805714</td>\n",
       "      <td>0.006140</td>\n",
       "      <td>9</td>\n",
       "      <td>0.813571</td>\n",
       "      <td>0.812679</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.815357</td>\n",
       "      <td>0.813179</td>\n",
       "      <td>0.001815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.482659</td>\n",
       "      <td>0.020579</td>\n",
       "      <td>0.517893</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.01}</td>\n",
       "      <td>0.953571</td>\n",
       "      <td>0.949643</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951714</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997054</td>\n",
       "      <td>0.997768</td>\n",
       "      <td>0.997411</td>\n",
       "      <td>0.997321</td>\n",
       "      <td>0.997232</td>\n",
       "      <td>0.997357</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.601719</td>\n",
       "      <td>0.015020</td>\n",
       "      <td>0.614490</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.001}</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.895714</td>\n",
       "      <td>0.889643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898357</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>4</td>\n",
       "      <td>0.931339</td>\n",
       "      <td>0.927679</td>\n",
       "      <td>0.931607</td>\n",
       "      <td>0.927589</td>\n",
       "      <td>0.931696</td>\n",
       "      <td>0.929982</td>\n",
       "      <td>0.001921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.455960</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>0.838113</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.0001}</td>\n",
       "      <td>0.844643</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.829286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844357</td>\n",
       "      <td>0.008717</td>\n",
       "      <td>6</td>\n",
       "      <td>0.860982</td>\n",
       "      <td>0.858482</td>\n",
       "      <td>0.864018</td>\n",
       "      <td>0.858304</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>0.860679</td>\n",
       "      <td>0.002125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        1.971702      0.029962         1.228749        0.101741       1   \n",
       "1        4.223899      0.088557         1.610377        0.107407       1   \n",
       "2        8.033128      0.202611         1.674175        0.182793       1   \n",
       "3        1.192821      0.015985         0.789247        0.021506      10   \n",
       "4        1.951559      0.042951         1.224537        0.054149      10   \n",
       "5        4.111301      0.012316         1.575593        0.043345      10   \n",
       "6        1.327169      0.005507         0.586225        0.002706     100   \n",
       "7        1.387366      0.030278         0.928304        0.104642     100   \n",
       "8        1.970905      0.028554         1.186857        0.028845     100   \n",
       "9        1.482659      0.020579         0.517893        0.006527    1000   \n",
       "10       1.601719      0.015020         0.614490        0.003394    1000   \n",
       "11       1.455960      0.012866         0.838113        0.004862    1000   \n",
       "\n",
       "   param_gamma                        params  split0_test_score  \\\n",
       "0         0.01       {'C': 1, 'gamma': 0.01}           0.826429   \n",
       "1        0.001      {'C': 1, 'gamma': 0.001}           0.684643   \n",
       "2       0.0001     {'C': 1, 'gamma': 0.0001}           0.203929   \n",
       "3         0.01      {'C': 10, 'gamma': 0.01}           0.914643   \n",
       "4        0.001     {'C': 10, 'gamma': 0.001}           0.805714   \n",
       "5       0.0001    {'C': 10, 'gamma': 0.0001}           0.684286   \n",
       "6         0.01     {'C': 100, 'gamma': 0.01}           0.948571   \n",
       "7        0.001    {'C': 100, 'gamma': 0.001}           0.861071   \n",
       "8       0.0001   {'C': 100, 'gamma': 0.0001}           0.801071   \n",
       "9         0.01    {'C': 1000, 'gamma': 0.01}           0.953571   \n",
       "10       0.001   {'C': 1000, 'gamma': 0.001}           0.897500   \n",
       "11      0.0001  {'C': 1000, 'gamma': 0.0001}           0.844643   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  mean_test_score  \\\n",
       "0            0.834643           0.828571  ...         0.832714   \n",
       "1            0.672500           0.682500  ...         0.677214   \n",
       "2            0.207143           0.206429  ...         0.217571   \n",
       "3            0.908571           0.902500  ...         0.911214   \n",
       "4            0.809643           0.803571  ...         0.808929   \n",
       "5            0.671071           0.682500  ...         0.677000   \n",
       "6            0.946786           0.941429  ...         0.947786   \n",
       "7            0.866071           0.850357  ...         0.863357   \n",
       "8            0.806429           0.803929  ...         0.805714   \n",
       "9            0.949643           0.948571  ...         0.951714   \n",
       "10           0.895714           0.889643  ...         0.898357   \n",
       "11           0.848214           0.829286  ...         0.844357   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.006221                7            0.843929            0.844196   \n",
       "1         0.005622               10            0.682054            0.683125   \n",
       "2         0.014490               12            0.212679            0.217589   \n",
       "3         0.005654                3            0.929643            0.929464   \n",
       "4         0.006227                8            0.818125            0.817679   \n",
       "5         0.005788               11            0.681875            0.683304   \n",
       "6         0.003742                2            0.978482            0.977946   \n",
       "7         0.008074                5            0.879554            0.877143   \n",
       "8         0.006140                9            0.813571            0.812679   \n",
       "9         0.002183                1            0.997054            0.997768   \n",
       "10        0.006197                4            0.931339            0.927679   \n",
       "11        0.008717                6            0.860982            0.858482   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             0.847679            0.843571            0.844018   \n",
       "1             0.687946            0.679554            0.686429   \n",
       "2             0.228393            0.240625            0.240625   \n",
       "3             0.930357            0.928929            0.928125   \n",
       "4             0.819643            0.814375            0.819464   \n",
       "5             0.687500            0.680089            0.685446   \n",
       "6             0.978393            0.978661            0.978571   \n",
       "7             0.882143            0.875536            0.879464   \n",
       "8             0.814286            0.810000            0.815357   \n",
       "9             0.997411            0.997321            0.997232   \n",
       "10            0.931607            0.927589            0.931696   \n",
       "11            0.864018            0.858304            0.861607   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.844679         0.001514  \n",
       "1           0.683821         0.003021  \n",
       "2           0.227982         0.011507  \n",
       "3           0.929304         0.000746  \n",
       "4           0.817857         0.001897  \n",
       "5           0.683643         0.002608  \n",
       "6           0.978411         0.000249  \n",
       "7           0.878768         0.002262  \n",
       "8           0.813179         0.001815  \n",
       "9           0.997357         0.000237  \n",
       "10          0.929982         0.001921  \n",
       "11          0.860679         0.002125  \n",
       "\n",
       "[12 rows x 22 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# converting C to numeric type for plotting on x-axis\n",
    "cv_results['param_C'] = cv_results['param_C'].astype('int')\n",
    "\n",
    "# # plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "# subplot 1/3\n",
    "plt.subplot(131)\n",
    "gamma_01 = cv_results[cv_results['param_gamma']==0.01]\n",
    "\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.01\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n",
    "# subplot 2/3\n",
    "plt.subplot(132)\n",
    "gamma_001 = cv_results[cv_results['param_gamma']==0.001]\n",
    "\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "# subplot 3/3\n",
    "plt.subplot(133)\n",
    "gamma_0001 = cv_results[cv_results['param_gamma']==0.0001]\n",
    "\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.0001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots above show some useful insights:\n",
    "- Non-linear models (high gamma) perform *much better* than the linear ones\n",
    "- At any value of gamma, a high value of C leads to better performance\n",
    "- None of the models tend to overfit (even the complex ones), since the training and test accuracies closely follow each other\n",
    "\n",
    "This suggests that the problem and the data is **inherently non-linear** in nature, and a complex model will outperform simple, linear models in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now choose the best hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best test score is 0.9517142857142857 corresponding to hyperparameters {'C': 1000, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "best_score = model_cv.best_score_\n",
    "best_hyperparams = model_cv.best_params_\n",
    "\n",
    "print(\"The best test score is {0} corresponding to hyperparameters {1}\".format(best_score, best_hyperparams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and Evaluating the Final Model\n",
    "\n",
    "Let's now build and evaluate the final model, i.e. the model with highest test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9596666666666667 \n",
      "\n",
      "[[206   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   2   0]\n",
      " [  0 211   0   2   1   0   1   0   0   0   0   0   0   0   0   0   0   1\n",
      "    2   0   0   0   0   0   0   0]\n",
      " [  0   0 220   0   3   0   4   1   0   0   0   0   0   0   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   3   0 236   0   1   0   1   0   1   0   0   0   2   2   0   0   1\n",
      "    1   0   0   0   0   0   0   0]\n",
      " [  0   0   1   0 225   1   4   0   0   0   0   0   0   0   0   0   0   0\n",
      "    1   0   0   0   0   0   0   2]\n",
      " [  0   0   0   1   0 217   0   0   1   1   0   0   0   1   0   3   0   0\n",
      "    0   0   0   1   0   0   0   0]\n",
      " [  0   0   2   3   1   0 209   0   0   0   0   0   1   0   1   0   0   0\n",
      "    0   0   0   1   1   0   0   0]\n",
      " [  0   1   3   5   0   0   2 195   1   1   2   1   1   0   1   0   3   1\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   1   0   0 203   8   0   0   0   0   0   0   1   0\n",
      "    0   0   0   0   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   7 209   0   0   0   1   0   0   0   1\n",
      "    0   0   2   0   0   0   0   0]\n",
      " [  0   1   0   0   2   0   0   5   0   0 228   0   0   0   0   0   0   5\n",
      "    0   0   0   0   0   4   0   0]\n",
      " [  0   0   0   0   0   0   1   1   0   0   0 232   0   0   0   1   0   1\n",
      "    0   1   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 230   2   0   0   0   0\n",
      "    0   0   0   0   2   0   0   0]\n",
      " [  0   3   0   1   0   0   0   0   0   0   0   0   1 244   0   0   0   1\n",
      "    0   0   0   0   1   0   0   0]\n",
      " [  0   0   2   0   0   0   2   0   0   1   0   0   2   0 210   0   1   1\n",
      "    0   0   1   0   1   0   0   0]\n",
      " [  0   0   0   0   1   8   0   1   1   0   0   0   0   0   0 252   1   0\n",
      "    0   0   0   0   0   0   1   0]\n",
      " [  0   0   0   0   3   0   1   0   0   0   0   0   0   0   2   1 226   0\n",
      "    0   0   0   0   0   0   0   2]\n",
      " [  0   8   0   1   0   0   1   3   0   0   3   0   0   3   0   0   0 224\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   1   0   0   1   2   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "  223   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   1   0   0   0   0   0   0   0   1   0   0\n",
      "    0 235   0   0   0   1   0   0]\n",
      " [  2   0   0   0   0   0   1   2   0   0   0   0   0   2   0   0   0   0\n",
      "    0   0 217   0   0   0   0   0]\n",
      " [  0   4   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0\n",
      "    0   0   0 203   1   0   1   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0\n",
      "    0   0   0   0 220   0   0   0]\n",
      " [  0   1   0   3   2   0   0   0   0   0   3   1   0   0   0   0   0   1\n",
      "    0   0   0   0   0 232   1   0]\n",
      " [  1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
      "    1   0   1   2   1   0 230   0]\n",
      " [  0   0   0   0   2   1   0   0   0   0   0   0   0   0   0   0   3   0\n",
      "    1   1   0   0   0   0   0 221]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model with optimal hyperparameters\n",
    "\n",
    "# model\n",
    "model = SVC(C=1000, gamma=0.01, kernel=\"rbf\")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# metrics\n",
    "print(\"accuracy\", metrics.accuracy_score(y_test, y_pred), \"\\n\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The accuracy achieved using a non-linear kernel (~0.95) is mush higher than that of a linear one (~0.85). We can conclude that the problem is highly non-linear in nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE STUDY 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Digits - Classification Using SVM\n",
    "\n",
    "In this notebook, we'll explore the popular MNIST dataset and build an SVM model to classify handwritten digits. <a href='http://yann.lecun.com/exdb/mnist/'>Here is a detailed description of the dataset.</a>\n",
    "\n",
    "We'll divide the analysis into the following parts:\n",
    "- Data understanding and cleaning\n",
    "- Data preparation for model building\n",
    "- Building an SVM model - hyperparameter tuning, model evaluation etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding and Cleaning\n",
    " \n",
    " Let's understand the dataset and see if it needs some cleaning etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "# read the dataset\n",
    "digits = pd.read_csv(\"Datasets/train.csv\")\n",
    "digits.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head\n",
    "digits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four = digits.iloc[3, 1:]\n",
    "four.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1bdb5842eb8>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "four = four.values.reshape(28, 28)\n",
    "plt.imshow(four, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Side note: Indexing Recall #####\n",
    "`list =    [0, 4, 2, 10, 22, 101, 10]` <br>\n",
    "`indices = [0, 1, 2, 3, ...,        ]` <br>\n",
    "`reverse = [-n           -3  -2   -1]` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 220 179   6   0   0   0   0   0   0   0   0   9  77   0   0   0   0]\n",
      " [  0  28 247  17   0   0   0   0   0   0   0   0  27 202   0   0   0   0]\n",
      " [  0   0 242 155   0   0   0   0   0   0   0   0  27 254  63   0   0   0]\n",
      " [  0   0 160 207   6   0   0   0   0   0   0   0  27 254  65   0   0   0]\n",
      " [  0   0 127 254  21   0   0   0   0   0   0   0  20 239  65   0   0   0]\n",
      " [  0   0  77 254  21   0   0   0   0   0   0   0   0 195  65   0   0   0]\n",
      " [  0   0  70 254  21   0   0   0   0   0   0   0   0 195 142   0   0   0]\n",
      " [  0   0  56 251  21   0   0   0   0   0   0   0   0 195 227   0   0   0]\n",
      " [  0   0   0 222 153   5   0   0   0   0   0   0   0 120 240  13   0   0]\n",
      " [  0   0   0  67 251  40   0   0   0   0   0   0   0  94 255  69   0   0]\n",
      " [  0   0   0   0 234 184   0   0   0   0   0   0   0  19 245  69   0   0]\n",
      " [  0   0   0   0 234 169   0   0   0   0   0   0   0   3 199 182  10   0]\n",
      " [  0   0   0   0 154 205   4   0   0  26  72 128 203 208 254 254 131   0]\n",
      " [  0   0   0   0  61 254 129 113 186 245 251 189  75  56 136 254  73   0]\n",
      " [  0   0   0   0  15 216 233 233 159 104  52   0   0   0  38 254  73   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  18 254  73   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  18 254  73   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   5 206 106   0]]\n"
     ]
    }
   ],
   "source": [
    "# visualise the array\n",
    "print(four[5:-5, 5:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 220 179   6   0   0   0   0   0   0   0   0   9  77   0   0   0   0]\n",
      " [  0  28 247  17   0   0   0   0   0   0   0   0  27 202   0   0   0   0]\n",
      " [  0   0 242 155   0   0   0   0   0   0   0   0  27 254  63   0   0   0]\n",
      " [  0   0 160 207   6   0   0   0   0   0   0   0  27 254  65   0   0   0]\n",
      " [  0   0 127 254  21   0   0   0   0   0   0   0  20 239  65   0   0   0]\n",
      " [  0   0  77 254  21   0   0   0   0   0   0   0   0 195  65   0   0   0]\n",
      " [  0   0  70 254  21   0   0   0   0   0   0   0   0 195 142   0   0   0]\n",
      " [  0   0  56 251  21   0   0   0   0   0   0   0   0 195 227   0   0   0]\n",
      " [  0   0   0 222 153   5   0   0   0   0   0   0   0 120 240  13   0   0]\n",
      " [  0   0   0  67 251  40   0   0   0   0   0   0   0  94 255  69   0   0]\n",
      " [  0   0   0   0 234 184   0   0   0   0   0   0   0  19 245  69   0   0]\n",
      " [  0   0   0   0 234 169   0   0   0   0   0   0   0   3 199 182  10   0]\n",
      " [  0   0   0   0 154 205   4   0   0  26  72 128 203 208 254 254 131   0]\n",
      " [  0   0   0   0  61 254 129 113 186 245 251 189  75  56 136 254  73   0]\n",
      " [  0   0   0   0  15 216 233 233 159 104  52   0   0   0  38 254  73   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  18 254  73   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  18 254  73   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   5 206 106   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 186 159   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   6 209 101   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(four[:, 5:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarise the counts of 'label' to see how many labels of each digit are present\n",
    "digits.label.astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11.15\n",
       "7    10.48\n",
       "3    10.36\n",
       "9     9.97\n",
       "2     9.95\n",
       "6     9.85\n",
       "0     9.84\n",
       "4     9.70\n",
       "8     9.67\n",
       "5     9.04\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarise count in terms of percentage \n",
    "100*(round(digits.label.astype('category').value_counts()/len(digits.index), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, each digit/label has an approximately 9%-11% fraction in the dataset and the **dataset is balanced**. This is an important factor in considering the choices of models to be used, especially SVM, since **SVMs rarely perform well on imbalanced data** (think about why that might be the case).\n",
    "\n",
    "Let's quickly look at missing values, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label       0\n",
       "pixel0      0\n",
       "pixel1      0\n",
       "pixel2      0\n",
       "pixel3      0\n",
       "pixel4      0\n",
       "pixel5      0\n",
       "pixel6      0\n",
       "pixel7      0\n",
       "pixel8      0\n",
       "pixel9      0\n",
       "pixel10     0\n",
       "pixel11     0\n",
       "pixel12     0\n",
       "pixel13     0\n",
       "pixel14     0\n",
       "pixel15     0\n",
       "pixel16     0\n",
       "pixel17     0\n",
       "pixel18     0\n",
       "pixel19     0\n",
       "pixel20     0\n",
       "pixel21     0\n",
       "pixel22     0\n",
       "pixel23     0\n",
       "pixel24     0\n",
       "pixel25     0\n",
       "pixel26     0\n",
       "pixel27     0\n",
       "pixel28     0\n",
       "           ..\n",
       "pixel754    0\n",
       "pixel755    0\n",
       "pixel756    0\n",
       "pixel757    0\n",
       "pixel758    0\n",
       "pixel759    0\n",
       "pixel760    0\n",
       "pixel761    0\n",
       "pixel762    0\n",
       "pixel763    0\n",
       "pixel764    0\n",
       "pixel765    0\n",
       "pixel766    0\n",
       "pixel767    0\n",
       "pixel768    0\n",
       "pixel769    0\n",
       "pixel770    0\n",
       "pixel771    0\n",
       "pixel772    0\n",
       "pixel773    0\n",
       "pixel774    0\n",
       "pixel775    0\n",
       "pixel776    0\n",
       "pixel777    0\n",
       "pixel778    0\n",
       "pixel779    0\n",
       "pixel780    0\n",
       "pixel781    0\n",
       "pixel782    0\n",
       "pixel783    0\n",
       "Length: 785, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values - there are none\n",
    "digits.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, let's look at the average values of each column, since we'll need to do some rescaling in case the ranges vary too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average values/distributions of features\n",
    "description = digits.describe()\n",
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the max value of the mean and maximum values of some features (pixels) is 139, 255 etc., whereas most features lie in much lower ranges  (look at description of pixel 0, pixel 1 etc. above).\n",
    "\n",
    "Thus, it seems like a good idea to rescale the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation for Model Building\n",
    "\n",
    "Let's now prepare the dataset for building the model. We'll only use a fraction of the data else training will take a long time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8400, 784)\n",
      "(33600, 784)\n",
      "(8400,)\n",
      "(33600,)\n"
     ]
    }
   ],
   "source": [
    "# Creating training and test sets\n",
    "# Splitting the data into train and test\n",
    "X = digits.iloc[:, 1:]\n",
    "Y = digits.iloc[:, 0]\n",
    "\n",
    "# Rescaling the features\n",
    "from sklearn.preprocessing import scale\n",
    "X = scale(X)\n",
    "\n",
    "# train test split with train_size=10% and test size=90%\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.20, random_state=101)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete test set from memory, to avoid a memory error\n",
    "# we'll anyway use CV to evaluate the model, and can use the separate test.csv file as well\n",
    "# to evaluate the model finally\n",
    "\n",
    "# del x_test\n",
    "# del y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building\n",
    "\n",
    "Let's now build the model and tune the hyperparameters. Let's start with a **linear model** first.\n",
    "\n",
    "#### Linear SVM\n",
    "\n",
    "Let's first try building a linear SVM model (i.e. a linear kernel). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "# an initial SVM model with linear kernel   \n",
    "svm_linear = svm.SVC(kernel='linear')\n",
    "\n",
    "# fit\n",
    "svm_linear.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 0, 0, 1, 4, 1, 5, 0, 6], dtype=int64)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "predictions = svm_linear.predict(x_test)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3188,    0,   10,    5,   11,   20,   32,    3,   15,    1],\n",
       "       [   0, 3677,   14,   11,    5,    7,    4,    8,   30,    4],\n",
       "       [  36,   29, 3027,   54,   55,   10,   30,   42,   48,   12],\n",
       "       [  13,   12,  104, 3051,    9,  181,    5,   21,   54,   25],\n",
       "       [   8,   14,   33,    2, 3057,    4,   25,   31,    6,  110],\n",
       "       [  30,   23,   29,  136,   44, 2622,   44,   12,   72,   27],\n",
       "       [  26,   11,   44,    4,   28,   33, 3113,    0,   18,    0],\n",
       "       [   7,   24,   36,   19,   59,    9,    2, 3210,    4,  134],\n",
       "       [  13,   46,   50,  120,   21,  110,   30,   18, 2843,   21],\n",
       "       [  19,   17,   21,   22,  172,   20,    4,  161,   26, 2893]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation: accuracy\n",
    "# C(i, j) represents the number of points known to be in class i \n",
    "# but predicted to be in class j\n",
    "confusion = metrics.confusion_matrix(y_true = y_test, y_pred = predictions)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.913125"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# measure accuracy\n",
    "metrics.accuracy_score(y_true=y_test, y_pred=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      3285\n",
      "           1       0.95      0.98      0.97      3760\n",
      "           2       0.90      0.91      0.90      3343\n",
      "           3       0.89      0.88      0.88      3475\n",
      "           4       0.88      0.93      0.91      3290\n",
      "           5       0.87      0.86      0.87      3039\n",
      "           6       0.95      0.95      0.95      3277\n",
      "           7       0.92      0.92      0.92      3504\n",
      "           8       0.91      0.87      0.89      3272\n",
      "           9       0.90      0.86      0.88      3355\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     33600\n",
      "   macro avg       0.91      0.91      0.91     33600\n",
      "weighted avg       0.91      0.91      0.91     33600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class-wise accuracy\n",
    "class_wise = metrics.classification_report(y_true=y_test, y_pred=predictions)\n",
    "print(class_wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21298"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run gc.collect() (garbage collect) to free up memory\n",
    "# else, since the dataset is large and SVM is computationally heavy,\n",
    "# it'll throw a memory error while training\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Linear SVM\n",
    "\n",
    "Let's now try a non-linear model with the RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rbf kernel with other hyperparameters kept to default \n",
    "svm_rbf = svm.SVC(kernel='rbf')\n",
    "svm_rbf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9396428571428571\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predictions = svm_rbf.predict(x_test)\n",
    "\n",
    "# accuracy \n",
    "print(metrics.accuracy_score(y_true=y_test, y_pred=predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy achieved with a non-linear kernel is slightly higher than a linear one. Let's now do a grid search CV to tune the hyperparameters C and gamma.\n",
    "\n",
    "#### Grid Search Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [1, 10, 100], 'gamma': [0.01, 0.001, 0.0001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conduct (grid search) cross-validation to find the optimal values \n",
    "# of cost C and the choice of kernel\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'C':[1, 10, 100], \n",
    "             'gamma': [1e-2, 1e-3, 1e-4]}\n",
    "\n",
    "# instantiate a model \n",
    "svc_grid_search = svm.SVC(kernel=\"rbf\")\n",
    "\n",
    "# create a classifier to perform grid search\n",
    "clf = GridSearchCV(svc_grid_search, param_grid=parameters, scoring='accuracy')\n",
    "\n",
    "# fit\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.058711</td>\n",
       "      <td>2.112884</td>\n",
       "      <td>12.754331</td>\n",
       "      <td>0.628153</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.729122</td>\n",
       "      <td>0.744020</td>\n",
       "      <td>0.718270</td>\n",
       "      <td>0.730476</td>\n",
       "      <td>0.010554</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.785033</td>\n",
       "      <td>0.165276</td>\n",
       "      <td>7.297521</td>\n",
       "      <td>0.029739</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001}</td>\n",
       "      <td>0.929693</td>\n",
       "      <td>0.938593</td>\n",
       "      <td>0.918127</td>\n",
       "      <td>0.928810</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>3</td>\n",
       "      <td>0.969632</td>\n",
       "      <td>0.971781</td>\n",
       "      <td>0.974299</td>\n",
       "      <td>0.971904</td>\n",
       "      <td>0.001907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.374271</td>\n",
       "      <td>0.229403</td>\n",
       "      <td>10.031959</td>\n",
       "      <td>0.412362</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.0001}</td>\n",
       "      <td>0.903997</td>\n",
       "      <td>0.898251</td>\n",
       "      <td>0.895960</td>\n",
       "      <td>0.899405</td>\n",
       "      <td>0.003381</td>\n",
       "      <td>6</td>\n",
       "      <td>0.912647</td>\n",
       "      <td>0.916056</td>\n",
       "      <td>0.916830</td>\n",
       "      <td>0.915178</td>\n",
       "      <td>0.001817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.640323</td>\n",
       "      <td>0.297844</td>\n",
       "      <td>12.314474</td>\n",
       "      <td>0.037078</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.747680</td>\n",
       "      <td>0.763656</td>\n",
       "      <td>0.738649</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.835754</td>\n",
       "      <td>0.219622</td>\n",
       "      <td>6.725965</td>\n",
       "      <td>0.182704</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>0.937188</td>\n",
       "      <td>0.947162</td>\n",
       "      <td>0.928137</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.007768</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999464</td>\n",
       "      <td>0.999107</td>\n",
       "      <td>0.999465</td>\n",
       "      <td>0.999345</td>\n",
       "      <td>0.000168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.335168</td>\n",
       "      <td>0.122359</td>\n",
       "      <td>6.159134</td>\n",
       "      <td>0.045632</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001}</td>\n",
       "      <td>0.927909</td>\n",
       "      <td>0.929668</td>\n",
       "      <td>0.919557</td>\n",
       "      <td>0.925714</td>\n",
       "      <td>0.004410</td>\n",
       "      <td>4</td>\n",
       "      <td>0.959271</td>\n",
       "      <td>0.958921</td>\n",
       "      <td>0.963056</td>\n",
       "      <td>0.960416</td>\n",
       "      <td>0.001872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49.859832</td>\n",
       "      <td>0.265127</td>\n",
       "      <td>12.288637</td>\n",
       "      <td>0.062682</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>0.747680</td>\n",
       "      <td>0.763656</td>\n",
       "      <td>0.738649</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.918950</td>\n",
       "      <td>0.158477</td>\n",
       "      <td>6.600315</td>\n",
       "      <td>0.021182</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001}</td>\n",
       "      <td>0.935403</td>\n",
       "      <td>0.946448</td>\n",
       "      <td>0.927065</td>\n",
       "      <td>0.936310</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.325445</td>\n",
       "      <td>0.155537</td>\n",
       "      <td>5.116961</td>\n",
       "      <td>0.035032</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.0001}</td>\n",
       "      <td>0.918986</td>\n",
       "      <td>0.929668</td>\n",
       "      <td>0.912406</td>\n",
       "      <td>0.920357</td>\n",
       "      <td>0.007112</td>\n",
       "      <td>5</td>\n",
       "      <td>0.995355</td>\n",
       "      <td>0.994642</td>\n",
       "      <td>0.994289</td>\n",
       "      <td>0.994762</td>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0      50.058711      2.112884        12.754331        0.628153       1   \n",
       "1      12.785033      0.165276         7.297521        0.029739       1   \n",
       "2      18.374271      0.229403        10.031959        0.412362       1   \n",
       "3      49.640323      0.297844        12.314474        0.037078      10   \n",
       "4      10.835754      0.219622         6.725965        0.182704      10   \n",
       "5       8.335168      0.122359         6.159134        0.045632      10   \n",
       "6      49.859832      0.265127        12.288637        0.062682     100   \n",
       "7      10.918950      0.158477         6.600315        0.021182     100   \n",
       "8       6.325445      0.155537         5.116961        0.035032     100   \n",
       "\n",
       "  param_gamma                       params  split0_test_score  \\\n",
       "0        0.01      {'C': 1, 'gamma': 0.01}           0.729122   \n",
       "1       0.001     {'C': 1, 'gamma': 0.001}           0.929693   \n",
       "2      0.0001    {'C': 1, 'gamma': 0.0001}           0.903997   \n",
       "3        0.01     {'C': 10, 'gamma': 0.01}           0.747680   \n",
       "4       0.001    {'C': 10, 'gamma': 0.001}           0.937188   \n",
       "5      0.0001   {'C': 10, 'gamma': 0.0001}           0.927909   \n",
       "6        0.01    {'C': 100, 'gamma': 0.01}           0.747680   \n",
       "7       0.001   {'C': 100, 'gamma': 0.001}           0.935403   \n",
       "8      0.0001  {'C': 100, 'gamma': 0.0001}           0.918986   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.744020           0.718270         0.730476        0.010554   \n",
       "1           0.938593           0.918127         0.928810        0.008377   \n",
       "2           0.898251           0.895960         0.899405        0.003381   \n",
       "3           0.763656           0.738649         0.750000        0.010338   \n",
       "4           0.947162           0.928137         0.937500        0.007768   \n",
       "5           0.929668           0.919557         0.925714        0.004410   \n",
       "6           0.763656           0.738649         0.750000        0.010338   \n",
       "7           0.946448           0.927065         0.936310        0.007938   \n",
       "8           0.929668           0.912406         0.920357        0.007112   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                9            1.000000            1.000000   \n",
       "1                3            0.969632            0.971781   \n",
       "2                6            0.912647            0.916056   \n",
       "3                7            1.000000            1.000000   \n",
       "4                1            0.999464            0.999107   \n",
       "5                4            0.959271            0.958921   \n",
       "6                7            1.000000            1.000000   \n",
       "7                2            1.000000            1.000000   \n",
       "8                5            0.995355            0.994642   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            1.000000          1.000000         0.000000  \n",
       "1            0.974299          0.971904         0.001907  \n",
       "2            0.916830          0.915178         0.001817  \n",
       "3            1.000000          1.000000         0.000000  \n",
       "4            0.999465          0.999345         0.000168  \n",
       "5            0.963056          0.960416         0.001872  \n",
       "6            1.000000          1.000000         0.000000  \n",
       "7            1.000000          1.000000         0.000000  \n",
       "8            0.994289          0.994762         0.000444  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results\n",
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# converting C to numeric type for plotting on x-axis\n",
    "cv_results['param_C'] = cv_results['param_C'].astype('int')\n",
    "\n",
    "# # plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "# subplot 1/3\n",
    "plt.subplot(131)\n",
    "gamma_01 = cv_results[cv_results['param_gamma']==0.01]\n",
    "\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.01\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "# subplot 2/3\n",
    "plt.subplot(132)\n",
    "gamma_001 = cv_results[cv_results['param_gamma']==0.001]\n",
    "\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "# subplot 3/3\n",
    "plt.subplot(133)\n",
    "gamma_0001 = cv_results[cv_results['param_gamma']==0.0001]\n",
    "\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.0001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we can observe that (from higher to lower gamma / left to right):\n",
    "- At very high gamma (0.01), the model is achieving 100% accuracy on the training data, though the test score is quite low (<75%). Thus, the model is overfitting.\n",
    "\n",
    "- At gamma=0.001, the training and test scores are comparable at around C=1, though the model starts to overfit at higher values of C\n",
    "\n",
    "- At gamma=0.0001, the model does not overfit till C=10 but starts showing signs at C=100. Also, the training and test scores are slightly lower than at gamma=0.001.\n",
    "\n",
    "Thus, it seems that the best combination is gamma=0.001 and C=1 (the plot in the middle), which gives the highest test accuracy (~92%) while avoiding overfitting.\n",
    "\n",
    "Let's now build the final model and see the performance on test data.\n",
    "\n",
    "#### Final Model\n",
    "\n",
    "Let's now build the final model with chosen hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimal hyperparameters\n",
    "best_C = 1\n",
    "best_gamma = 0.001\n",
    "\n",
    "# model\n",
    "svm_final = svm.SVC(kernel='rbf', C=best_C, gamma=best_gamma)\n",
    "\n",
    "# fit\n",
    "svm_final.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = svm_final.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9382738095238096 \n",
      "\n",
      "[[3198    0   11    5    4   12   29    9   16    1]\n",
      " [   0 3687   16   12    7    4    7   13    9    5]\n",
      " [  16   15 3109   31   32    5   21   60   48    6]\n",
      " [   6   10   69 3179    5   84    5   45   48   24]\n",
      " [   6    8   41    1 3107    6   17   23    8   73]\n",
      " [  16   11   13   68   15 2775   50   37   35   19]\n",
      " [  22    5   15    1   13   32 3147   27   15    0]\n",
      " [   6   21   32    9   29    5    0 3308    5   89]\n",
      " [  14   29   26   68   15   65   22   30 2984   19]\n",
      " [  12   11   15   44   90    7    0  117   27 3032]]\n"
     ]
    }
   ],
   "source": [
    "# evaluation: CM \n",
    "confusion = metrics.confusion_matrix(y_true = y_test, y_pred = predictions)\n",
    "\n",
    "# measure accuracy\n",
    "test_accuracy = metrics.accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "\n",
    "print(test_accuracy, \"\\n\")\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "The final accuracy on test data is approx. 94%. Note that this can be significantly increased by using the entire training data of 42,000 images (we have used just 20% of that!). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
